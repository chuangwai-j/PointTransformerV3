"""
Point Transformer - V3 Mode1

Author: Xiaoyang Wu (xiaoyang.wu.cs@gmail.com)
Please cite our work if the code is helpful to you.
"""
import os
from functools import partial
from addict import Dict
import logging
import math
import torch
import torch.nn as nn
import spconv.pytorch as spconv
import torch_scatter
from timm.layers import DropPath
from pointcept.utils.misc import offset2bincount
import warnings
from torch.fx import wrap
from spconv.pytorch import SparseConvTensor

try:
    import flash_attn
except ImportError:
    flash_attn = None

from pointcept.models.point_prompt_training import PDNorm
from pointcept.models.builder import MODELS
from pointcept.models.utils.structure import Point
from pointcept.models.modules import PointModule, PointSequential


class RPE(torch.nn.Module):
    def __init__(self, patch_size, num_heads):
        super().__init__()
        self.patch_size = patch_size
        self.num_heads = num_heads
        self.pos_bnd = int((4 * patch_size) ** (1 / 3) * 2)
        self.rpe_num = 2 * self.pos_bnd + 1
        self.rpe_table = torch.nn.Parameter(torch.zeros(3 * self.rpe_num, num_heads))
        torch.nn.init.trunc_normal_(self.rpe_table, std=0.02)

    def forward(self, coord):
        idx = (
            coord.clamp(-self.pos_bnd, self.pos_bnd)  # clamp into bnd
            + self.pos_bnd  # relative position to positive index
            + torch.arange(3, device=coord.device) * self.rpe_num  # x, y, z stride
        )
        out = self.rpe_table.index_select(0, idx.reshape(-1))
        out = out.view(idx.shape + (-1,)).sum(3)
        out = out.permute(0, 3, 1, 2)  # (N, K, K, H) -> (N, H, K, K)
        return out


class SerializedAttention(PointModule):
    def __init__(
        self,
        channels,
        num_heads,
        patch_size,
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        order_index=0,
        enable_rpe=False,
        enable_flash=True,
        upcast_attention=True,
        upcast_softmax=True,
    ):
        super().__init__()
        assert channels % num_heads == 0
        self.channels = channels
        self.num_heads = num_heads
        self.scale = qk_scale or (channels // num_heads) ** -0.5
        self.order_index = order_index
        self.upcast_attention = upcast_attention
        self.upcast_softmax = upcast_softmax
        self.enable_rpe = enable_rpe
        self.enable_flash = enable_flash
        if enable_flash:
            assert (
                enable_rpe is False
            ), "Set enable_rpe to False when enable Flash Attention"
            assert (
                upcast_attention is False
            ), "Set upcast_attention to False when enable Flash Attention"
            assert (
                upcast_softmax is False
            ), "Set upcast_softmax to False when enable Flash Attention"
            assert flash_attn is not None, "Make sure flash_attn is installed."
            self.patch_size = patch_size
            self.attn_drop = attn_drop
        else:
            self.patch_size_max = patch_size
            self.patch_size = 0
            self.attn_drop = torch.nn.Dropout(attn_drop)

        self.qkv = torch.nn.Linear(channels, channels * 3, bias=qkv_bias)
        self.proj = torch.nn.Linear(channels, channels)
        self.proj_drop = torch.nn.Dropout(proj_drop)
        self.softmax = torch.nn.Softmax(dim=-1)
        self.rpe = RPE(patch_size, num_heads) if self.enable_rpe else None

    @torch.no_grad()
    def get_rel_pos(self, point, order):
        K = self.patch_size
        rel_pos_key = f"rel_pos_{self.order_index}"
        if rel_pos_key not in point.keys():
            grid_coord = point.grid_coord[order]
            grid_coord = grid_coord.reshape(-1, K, 3)
            point[rel_pos_key] = grid_coord.unsqueeze(2) - grid_coord.unsqueeze(1)
        return point[rel_pos_key]

    @torch.no_grad()
    def get_padding_and_inverse(self, point):
        pad_key = "pad"
        unpad_key = "unpad"
        cu_seqlens_key = "cu_seqlens_key"

        # ä»…åœ¨é¦–æ¬¡è°ƒç”¨æ—¶è®¡ç®—ï¼Œé¿å…é‡å¤è®¡ç®—
        if (pad_key not in point.keys() or
                unpad_key not in point.keys() or
                cu_seqlens_key not in point.keys()):

            offset = point.offset
            device = offset.device
            bincount = offset2bincount(point.offset,check_padding=False)  # æ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°
            total_original_points = offset[-1].item()  # å½“å‰batchæ€»ç‚¹æ•°
            logging.debug(f"ã€get_paddingã€‘æ€»ç‚¹æ•°={total_original_points}, unpadé•¿åº¦å°†è®¾ä¸º={total_original_points}")

            # 1. è®¡ç®—éœ€è¦paddingåˆ°çš„ç‚¹æ•°ï¼ˆç¡®ä¿æ˜¯patch_sizeçš„å€æ•°ï¼‰
            bincount_pad = (
                    torch.div(bincount + self.patch_size - 1,
                              self.patch_size,
                              rounding_mode="trunc") * self.patch_size
            )
            # åªå¯¹ç‚¹æ•°è¶…è¿‡patch_sizeçš„æ ·æœ¬è¿›è¡Œpadding
            mask_pad = bincount > self.patch_size
            bincount_pad = ~mask_pad * bincount + mask_pad * bincount_pad

            # 2. è®¡ç®—åç§»é‡ï¼ˆå¸¦paddingå’Œä¸å¸¦paddingçš„ï¼‰
            _offset = nn.functional.pad(offset, (1, 0))  # åŸå§‹åç§»é‡ï¼ˆå‰è¡¥0ï¼‰
            _offset_pad = nn.functional.pad(torch.cumsum(bincount_pad, dim=0), (1, 0))  # å¸¦paddingçš„åç§»é‡


            # 3. åˆå§‹åŒ–padå’Œunpadæ•°ç»„ï¼ˆç¡®ä¿ç±»å‹ä¸ºé•¿æ•´æ•°ï¼Œé¿å…ç´¢å¼•é”™è¯¯ï¼‰
            total_padded_points = _offset_pad[-1].item()  # å¸¦paddingçš„æ€»ç‚¹æ•°
            #pad = torch.arange(total_padded_points, device=device, dtype=torch.long)
            #unpad = torch.arange(total_original_points, device=device, dtype=torch.long)
            # ä¿®å¤ï¼šunpadé•¿åº¦å¿…é¡»ç­‰äºæ€»ç‚¹æ•°ï¼Œé¿å…é•¿åº¦ä¸è¶³
            unpad = torch.zeros(total_original_points, dtype=torch.long, device=device)
            pad = torch.arange(total_padded_points, device=device, dtype=torch.long)

            # 4. è®¡ç®—cu_seqlensï¼ˆç”¨äºFlash Attentionçš„åºåˆ—é•¿åº¦ç´¢å¼•ï¼‰
            cu_seqlens = []
            for i in range(len(offset) - 1):
                orig_start, orig_end = offset[i], offset[i + 1]  # åŸå§‹æ ·æœ¬èŒƒå›´
                pad_start, pad_end = _offset_pad[i], _offset_pad[i + 1]  # paddingåæ ·æœ¬èŒƒå›´
                sample_points_orig = orig_end - orig_start
                sample_points_pad = pad_end - pad_start

                # 3.1 æ ¡æ­£unpadï¼šæ˜ å°„åŸå§‹ç´¢å¼•â†’paddingåç´¢å¼•ï¼ˆç¡®ä¿ä¸è¶…ç•Œï¼‰
                if sample_points_orig > 0:
                    offset_val = pad_start - orig_start
                    # é™åˆ¶unpadä¸è¶…è¿‡total_original_points
                    unpad_slice = unpad[orig_start:orig_end] + offset_val
                    unpad[orig_start:orig_end] = torch.clamp(unpad_slice, 0, total_original_points - 1)

                # 3.2 æ ¡æ­£padï¼šå¤„ç†paddingåŒºåŸŸï¼ˆé¿å…å¤åˆ¶è¶Šç•Œï¼‰
                if sample_points_orig != sample_points_pad and sample_points_pad > 0:
                    # å®‰å…¨è®¡ç®—å¤åˆ¶æºèŒƒå›´ï¼ˆé¿å…srcè¶…å‡ºåŸå§‹æ ·æœ¬ï¼‰
                    src_start = max(orig_start, orig_end - self.patch_size)  # å–åŸå§‹æ ·æœ¬æœ€åpatch_sizeä¸ªç‚¹
                    src_end = orig_end
                    src_len = src_end - src_start

                    # å®‰å…¨è®¡ç®—å¤åˆ¶ç›®æ ‡èŒƒå›´
                    dst_start = orig_end
                    dst_end = pad_end
                    dst_len = dst_end - dst_start

                    # ä»…å½“æºå’Œç›®æ ‡éƒ½æœ‰æ•ˆæ—¶å¤åˆ¶
                    if src_len > 0 and dst_len > 0:
                        copy_len = min(src_len, dst_len)
                        # æ˜ å°„srcåˆ°paddingåçš„padç´¢å¼•
                        pad[dst_start:dst_start + copy_len] = pad[src_start:src_start + copy_len]

                # 3.3 æ ¡æ­£padçš„æ ·æœ¬å†…åç§»ï¼ˆç¡®ä¿ä¸åŸå§‹ç´¢å¼•å¯¹é½ï¼‰
                if sample_points_pad > 0:
                    pad_slice = pad[pad_start:pad_end] - (pad_start - orig_start)
                    pad[pad_start:pad_end] = torch.clamp(pad_slice, 0, total_original_points - 1)

                # 3.4 ç”Ÿæˆcu_seqlensï¼ˆç¡®ä¿æ­¥é•¿åˆç†ï¼‰
                step = max(1, self.patch_size)  # é¿å…æ­¥é•¿ä¸º0
                seq = torch.arange(pad_start, pad_end, step, dtype=torch.int32, device=device)
                # ç¡®ä¿åºåˆ—è¦†ç›–åˆ°pad_end
                if len(seq) == 0 or seq[-1] < pad_end - 1:
                    seq = torch.cat([seq, torch.tensor([pad_end - 1], device=device, dtype=torch.int32)])
                cu_seqlens.append(seq)

                # 4. åˆå¹¶cu_seqlensï¼ˆç¡®ä¿æœ€åä¸€ä¸ªå…ƒç´ æ˜¯æ€»é•¿åº¦ï¼‰
            merged_cu_seqlens = torch.cat(cu_seqlens) if cu_seqlens else torch.tensor([0], device=device,
                                                                                      dtype=torch.int32)
            if merged_cu_seqlens[-1] != total_padded_points:
                merged_cu_seqlens = torch.cat(
                    [merged_cu_seqlens, torch.tensor([total_padded_points], device=device, dtype=torch.int32)])

            # æœ€ç»ˆæ ¡éªŒunpadçš„æœ‰æ•ˆæ€§
            if (unpad >= total_original_points).any() or (unpad < 0).any():
                invalid = unpad[(unpad >= total_original_points) | (unpad < 0)]
                warnings.warn(f"unpadä¸­å­˜åœ¨æ— æ•ˆç´¢å¼•ï¼š{invalid[:5]}ï¼ˆå‰5ä¸ªï¼‰ï¼Œå·²è‡ªåŠ¨æˆªæ–­")
                unpad = torch.clamp(unpad, 0, total_original_points - 1)

            # ä¿å­˜ç»“æœ
            point[pad_key] = pad
            point[unpad_key] = unpad
            point[cu_seqlens_key] = merged_cu_seqlens

        return point[pad_key], point[unpad_key], point[cu_seqlens_key]

    def forward(self, point):
        # åœ¨point.serializationå‰æ·»åŠ å­—æ®µæ£€æŸ¥
        logging.debug(
            f"ã€Pointå¯¹è±¡å­—æ®µæ£€æŸ¥ã€‘keys={point.keys()}, åŒ…å«grid_size={('grid_size' in point.keys())}, åŒ…å«coord={('coord' in point.keys())}")

        if not self.enable_flash:
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°ï¼ˆbincountï¼‰
            logging.debug(f"\nã€è°ƒè¯•æ—¥å¿—ã€‘å½“å‰batchçš„offset: {point.offset}")
            bincount = offset2bincount(point.offset, check_padding=False)
            logging.debug(f"ã€è°ƒè¯•æ—¥å¿—ã€‘è®¡ç®—å‡ºçš„æ ·æœ¬ç‚¹æ•°bincount: {bincount}")

            # ç¡®ä¿æ ·æœ¬ç‚¹æ•°æœ‰æ•ˆ
            min_points_per_sample = bincount.min().item()
            if min_points_per_sample <= 0:
                raise ValueError(f"æ ·æœ¬ç‚¹æ•°å¼‚å¸¸ï¼šå­˜åœ¨ç‚¹æ•°â‰¤0çš„æ ·æœ¬ï¼ˆmin_points={min_points_per_sample}ï¼‰")

            # è®¡ç®—åˆç†çš„patch_size
            self.patch_size = min(min_points_per_sample, self.patch_size_max)
            self.patch_size = max(self.patch_size, 1)  # é¿å…patch_sizeä¸º0

        H = self.num_heads
        K = self.patch_size
        logging.debug(
            f"å½“å‰patch_size (K): {K}, é…ç½®patch_size_max: {self.patch_size_max}, æ ·æœ¬æœ€å°ç‚¹æ•°: {min_points_per_sample}")
        assert K >= 1, f"patch_size (K) å¿…é¡»â‰¥1ï¼Œå½“å‰K={K}"
        C = self.channels

        pad, unpad, cu_seqlens = self.get_padding_and_inverse(point)

        # ====================== æ–°å¢ï¼šserialized_orderç´¢å¼•æ ¡éªŒ ======================
        # 1. è·å–å½“å‰order_indexå¯¹åº”çš„serialized_orderåˆ‡ç‰‡
        serialized_order_slice = point.serialized_order[self.order_index]
        serialized_order_len = serialized_order_slice.shape[0]

        # 2. æ ¡éªŒpadçš„ç´¢å¼•æ˜¯å¦è¶…å‡ºserialized_order_sliceçš„é•¿åº¦
        if (pad < 0).any() or (pad >= serialized_order_len).any():
            # æˆªæ–­è¶…ç•Œçš„padç´¢å¼•ï¼ˆå…œåº•ï¼Œé¿å…ç›´æ¥è§¦å‘CUDAæ–­è¨€ï¼‰
            pad = torch.clamp(pad, 0, serialized_order_len - 1)
            # æ‰“å°è­¦å‘Šæ—¥å¿—ï¼Œå®šä½é—®é¢˜æ¥æº
            logging.debug(
                f"padç´¢å¼•è¶…å‡ºserialized_orderèŒƒå›´ï¼serialized_orderé•¿åº¦={serialized_order_len}ï¼Œ"
                f"æ ¡æ­£å‰padèŒƒå›´: [{pad.min()}, {pad.max()}]ï¼Œæ ¡æ­£åèŒƒå›´: [0, {serialized_order_len - 1}]"
            )

        # 3. æ‰§è¡Œç´¢å¼•æ“ä½œï¼ˆæ­¤æ—¶padå·²ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´ï¼‰
        order = serialized_order_slice[pad]
        # =====================================================================

        # ====================== æ–°å¢ï¼šserialized_inverseç´¢å¼•æ ¡éªŒ ======================
        # 1. å…ˆè·å–serialized_inverseç´¢å¼•
        serialized_inverse_idx = point.serialized_inverse[self.order_index]
        unpad_len = unpad.shape[0]  # unpadçš„é•¿åº¦ï¼ˆæœ‰æ•ˆç´¢å¼•èŒƒå›´ï¼š0 ~ unpad_len-1ï¼‰

        # 2. æ ¡éªŒserialized_inverse_idxæ˜¯å¦è¶…å‡ºunpadçš„æœ‰æ•ˆèŒƒå›´
        if (serialized_inverse_idx < 0).any() or (serialized_inverse_idx >= unpad_len).any():
            # æˆªæ–­è¶…ç•Œç´¢å¼•ï¼ˆå…œåº•ï¼Œé¿å…ç›´æ¥æŠ¥é”™ï¼‰
            serialized_inverse_idx = torch.clamp(serialized_inverse_idx, 0, unpad_len - 1)
            # æ‰“å°è­¦å‘Šï¼Œå®šä½é—®é¢˜æ ·æœ¬
            logging.debug(
                f"serialized_inverseç´¢å¼•è¶…å‡ºunpadèŒƒå›´ï¼unpadé•¿åº¦={unpad_len}ï¼Œ"
                f"æ ¡æ­£å‰æœ€å¤§ç´¢å¼•={serialized_inverse_idx.max()}, æœ€å°ç´¢å¼•={serialized_inverse_idx.min()}"
            )

        # 3. æ‰§è¡Œunpadæ˜ å°„ï¼ˆæ­¤æ—¶ç´¢å¼•å·²ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´ï¼‰
        inverse = unpad[serialized_inverse_idx]
        # =====================================================================

        # ====================== æ–°å¢ï¼šæ ·æœ¬å†…ç´¢å¼•æœ€ç»ˆæ ¡æ­£ ======================
        feat_len = point.feat.shape[0]
        offset = point.offset
        # æ ¸å¿ƒä¿®å¤ï¼šä»point.featè·å–è®¾å¤‡ï¼ˆç¡®ä¿ä¸è¾“å…¥æ•°æ®åœ¨åŒä¸€è®¾å¤‡ï¼‰
        device = point.feat.device
        # ç”Ÿæˆæ¯ä¸ªç‚¹çš„æ ·æœ¬å½’å±æ ‡è®°
        sample_id = torch.zeros(feat_len, dtype=torch.int64, device=device)
        for i in range(1, len(offset)):
            sample_id[offset[i - 1]:offset[i]] = i - 1

        # é€æ ·æœ¬æ ¡æ­£inverseï¼šç¡®ä¿æ¯ä¸ªæ ·æœ¬çš„inverseåœ¨è‡ªèº«èŒƒå›´å†…
        for i in range(len(offset) - 1):
            sample_mask = (sample_id == i)
            sample_inverse = inverse[sample_mask]
            # æ ·æœ¬å†…æœ‰æ•ˆèŒƒå›´ï¼š[offset[i], offset[i+1])
            valid_min = offset[i]
            valid_max = offset[i + 1] - 1
            # æˆªæ–­è¶…ç•Œç´¢å¼•ï¼ˆå…œåº•ï¼‰
            sample_inverse_clamped = torch.clamp(sample_inverse, valid_min, valid_max)
            inverse[sample_mask] = sample_inverse_clamped
        # =====================================================================

        # ====================== æ–°å¢ï¼šinverseç´¢å¼•å…³é”®æ ¡éªŒ ======================
        # 1. æ£€æŸ¥inverseä¸featçš„é•¿åº¦åŒ¹é…
        feat_len = point.feat.shape[0]
        inverse_len = inverse.shape[0]
        if inverse_len != feat_len:
            raise ValueError(
                f"inverseé•¿åº¦ä¸featä¸åŒ¹é…ï¼"
                f"inverseé•¿åº¦={inverse_len}, featç‚¹æ•°={feat_len}"
            )

        # 2. æ£€æŸ¥ç´¢å¼•èŒƒå›´ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰
        invalid_mask = (inverse < 0) | (inverse >= feat_len)
        if invalid_mask.any():
            # æ”¶é›†æ— æ•ˆç´¢å¼•ä¿¡æ¯
            invalid_indices = inverse[invalid_mask]
            first_invalid = invalid_indices[:5]  # å–å‰5ä¸ªç¤ºä¾‹
            invalid_count = invalid_indices.numel()
            # æ‰“å°æ ·æœ¬è¾¹ç•Œè¾…åŠ©è°ƒè¯•
            sample_ranges = [f"æ ·æœ¬{i}: [{point.offset[i]}, {point.offset[i + 1]})"
                             for i in range(len(point.offset) - 1)]
            raise ValueError(
                f"inverseç´¢å¼•è¶Šç•Œï¼æœ‰æ•ˆèŒƒå›´åº”åœ¨[0, {feat_len})ï¼Œ"
                f"å…±å‘ç°{invalid_count}ä¸ªæ— æ•ˆç´¢å¼•ï¼Œç¤ºä¾‹: {first_invalid}\n"
                f"æ ·æœ¬è¾¹ç•Œ: {sample_ranges}"
            )
        # =====================================================================

        # æ ·æœ¬ç‚¹æ•°ä¸æ³¨æ„åŠ›å¤´æ•°åŒ¹é…æ£€æŸ¥
        logging.debug("=" * 50)
        logging.debug(f"å½“å‰æ³¨æ„åŠ›å¤´æ•°H: {self.num_heads}")
        logging.debug(f"offset: {point['offset']}")
        sample_points = [point['offset'][i + 1] - point['offset'][i] for i in range(len(point['offset']) - 1)]
        logging.debug(f"æ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°: {sample_points}")
        for i, sp in enumerate(sample_points):
            if sp % self.num_heads != 0:
                logging.debug(f"âŒ æ ·æœ¬{i}ç‚¹æ•°{sp}ä¸èƒ½è¢«å¤´æ•°{self.num_heads}æ•´é™¤ï¼K={sp // self.num_heads}")
            else:
                logging.debug(f"âœ… æ ·æœ¬{i}ç‚¹æ•°{sp}ï¼ŒK={sp // self.num_heads}")

        # ç‰¹å¾ç»´åº¦ä¸€è‡´æ€§æ£€æŸ¥
        logging.debug(f"coordç‚¹æ•°: {point['coord'].shape[0]}")
        logging.debug(f"featç‚¹æ•°: {point['feat'].shape[0]}")
        logging.debug(f"labelç‚¹æ•°: {point['generate_label'].shape[0]}")
        logging.debug(f"beamazç‚¹æ•°: {point['beamaz'].shape[0] if 'beamaz' in point else 'æ— '}")
        logging.debug(f"inverseå½¢çŠ¶: {inverse.shape}, æœ€å¤§ç´¢å¼•: {inverse.max()}, æœ€å°ç´¢å¼•: {inverse.min()}")
        logging.debug("=" * 50)

        # æ³¨æ„åŠ›è®¡ç®—é€»è¾‘
        qkv = self.qkv(point.feat)[order]

        if not self.enable_flash:
            q, k, v = (
                qkv.reshape(-1, K, 3, H, C // H).permute(2, 0, 3, 1, 4).unbind(dim=0)
            )
            if self.upcast_attention:
                q = q.float()
                k = k.float()
            attn = (q * self.scale) @ k.transpose(-2, -1)
            if self.enable_rpe:
                attn = attn + self.rpe(self.get_rel_pos(point, order))
            if self.upcast_softmax:
                attn = attn.float()
            attn = self.softmax(attn)
            attn = self.attn_drop(attn).to(qkv.dtype)
            feat = (attn @ v).transpose(1, 2).reshape(-1, C)
        else:
            feat = flash_attn.flash_attn_varlen_qkvpacked_func(
                qkv.to(torch.bfloat16).reshape(-1, 3, H, C // H),
                cu_seqlens,
                max_seqlen=self.patch_size,
                dropout_p=self.attn_drop if self.training else 0,
                softmax_scale=self.scale,
            ).reshape(-1, C)
            feat = feat.to(qkv.dtype)

        # ä½¿ç”¨ç»è¿‡æ ¡éªŒçš„inverseç´¢å¼•
        feat = feat[inverse]

        # åç»­å¤„ç†
        feat = self.proj(feat)
        feat = self.proj_drop(feat)
        # ğŸŒŸ æ–°å¢ï¼šæ³¨æ„åŠ›å±‚è¾“å‡ºæ•°å€¼æ ¡éªŒï¼ˆé˜²æ­¢nan/infä¼ é€’ï¼‰
        if torch.isnan(feat).any() or torch.isinf(feat).any():
            nan_count = torch.isnan(feat).sum().item()
            inf_count = torch.isinf(feat).sum().item()
            sample_paths = point.get('path', ['æœªçŸ¥è·¯å¾„'])
            logging.error(
                f"SerializedAttentionè¾“å‡ºfeatå¼‚å¸¸ï¼æ ·æœ¬è·¯å¾„={sample_paths[:2]}, "
                f"å«NaN={nan_count}ä¸ª, å«inf={inf_count}ä¸ª, featèŒƒå›´=[{feat.min().item():.4f}, {feat.max().item():.4f}]"
            )
        point.feat = feat
        '''
        # ====================== æ–°å¢ï¼šæ‰“å°åµŒå…¥å±‚åçš„ç‰¹å¾ï¼ˆç»ˆç«¯è¾“å‡ºï¼‰ ======================
        embed_feat = point.feat
        print(f"[æ¨¡å‹é˜¶æ®µ] åµŒå…¥å±‚åç‰¹å¾ç»Ÿè®¡ï¼š")
        print(f"  ç‰¹å¾å½¢çŠ¶: {embed_feat.shape}")
        print(f"  æœ€å°å€¼: {embed_feat.min().cpu().item():.4f}")
        print(f"  æœ€å¤§å€¼: {embed_feat.max().cpu().item():.4f}")
        print(f"  å‡å€¼:   {embed_feat.mean().cpu().item():.4f}")
        print(f"  æ ‡å‡†å·®: {embed_feat.std().cpu().item():.4f}")
        # ==============================================================================
        '''
        logging.debug(f"SerializedAttentionè¾“å‡ºpoint.featå½¢çŠ¶: {point.feat.shape}")
        return point

class MLP(nn.Module):
    def __init__(
        self,
        in_channels,
        hidden_channels=None,
        out_channels=None,
        act_layer=nn.GELU,
        drop=0.0,
    ):
        super().__init__()
        out_channels = out_channels or in_channels
        hidden_channels = hidden_channels or in_channels
        self.fc1 = nn.Linear(in_channels, hidden_channels)
        self.act = act_layer()
        self.fc2 = nn.Linear(hidden_channels, out_channels)
        self.drop = nn.Dropout(drop)

    def forward(self, x):
        # ğŸŒŸ æ–°å¢ï¼šMLPè¾“å…¥æ•°å€¼æ ¡éªŒ
        if torch.isnan(x).any() or torch.isinf(x).any():
            logging.error(f"MLPè¾“å…¥å¼‚å¸¸ï¼šå«NaN={torch.isnan(x).any().item()}, å«inf={torch.isinf(x).any().item()}")

        x = self.fc1(x)
        x = self.act(x)
        x = self.drop(x)
        x = self.fc2(x)
        x = self.drop(x)

        # ğŸŒŸ æ–°å¢ï¼šMLPè¾“å‡ºæ•°å€¼æ ¡éªŒ
        if torch.isnan(x).any() or torch.isinf(x).any():
            logging.error(f"MLPè¾“å‡ºå¼‚å¸¸ï¼šå«NaN={torch.isnan(x).any().item()}, å«inf={torch.isinf(x).any().item()}")

        return x


class Block(PointModule):
    def __init__(
        self,
        channels,
        num_heads,
        patch_size=48,
        mlp_ratio=4.0,
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        drop_path=0.0,
        norm_layer=nn.LayerNorm,
        act_layer=nn.GELU,
        pre_norm=True,
        order_index=0,
        cpe_indice_key=None,
        enable_rpe=False,
        enable_flash=True,
        upcast_attention=True,
        upcast_softmax=True,
    ):
        super().__init__()
        self.channels = channels
        self.pre_norm = pre_norm

        self.cpe = PointSequential(
            spconv.SubMConv3d(
                channels,
                channels,
                kernel_size=3,
                bias=True,
                indice_key=cpe_indice_key,
            ),
            nn.Linear(channels, channels),
            norm_layer(channels),
        )

        self.norm1 = PointSequential(norm_layer(channels))
        self.attn = SerializedAttention(
            channels=channels,
            patch_size=patch_size,
            num_heads=num_heads,
            qkv_bias=qkv_bias,
            qk_scale=qk_scale,
            attn_drop=attn_drop,
            proj_drop=proj_drop,
            order_index=order_index,
            enable_rpe=enable_rpe,
            enable_flash=enable_flash,
            upcast_attention=upcast_attention,
            upcast_softmax=upcast_softmax,
        )
        self.norm2 = PointSequential(norm_layer(channels))
        self.mlp = PointSequential(
            MLP(
                in_channels=channels,
                hidden_channels=int(channels * mlp_ratio),
                out_channels=channels,
                act_layer=act_layer,
                drop=proj_drop,
            )
        )
        '''self.drop_path = PointSequential(
            DropPath(drop_path) if drop_path > 0.0 else nn.Identity()
        )'''
        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()
        # æ–°å¢ï¼šæ³¨æ„åŠ›å±‚åæ·»åŠ LayerNorm
        self.attn_norm = PointSequential(nn.LayerNorm(channels))
        # æ–°å¢ï¼šMLPå±‚åæ·»åŠ LayerNorm
        self.mlp_norm = PointSequential(nn.LayerNorm(channels))

    def forward(self, point: Point):
        logging.debug(f"Blockè¾“å…¥pointç±»å‹: {type(point)}")  # åº”è¾“å‡º <class 'pointcept.models.utils.structure.Point'>
        shortcut = point.feat  # ä¿å­˜åŸå§‹featï¼ˆç”¨äºæ®‹å·®è¿æ¥ï¼‰
        # 1. CPEå±‚ï¼šæ­£å¸¸å¤„ç†Pointå¯¹è±¡
        point = self.cpe(point)

        # ğŸŒŸ æ–°å¢ï¼šCPEå±‚è¾“å‡ºæ ¡éªŒ
        if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
            sample_paths = point.get('path', ['æœªçŸ¥è·¯å¾„'])
            logging.error(
                f"Block-CPEå±‚è¾“å‡ºå¼‚å¸¸ï¼æ ·æœ¬è·¯å¾„={sample_paths[:2]}, featå«NaN={torch.isnan(point.feat).any().item()}")

        point.feat = shortcut + point.feat  # æ®‹å·®è¿æ¥
        shortcut = point.feat  # æ›´æ–°shortcutä¸ºCPEå¤„ç†åçš„feat

        # 2. æ³¨æ„åŠ›å±‚ + DropPathï¼šæ‰‹åŠ¨å¤„ç†Pointå¯¹è±¡ï¼Œä¸ç ´åç»“æ„
        if self.pre_norm:
            point = self.norm1(point)
        # å…³é”®ä¿®æ”¹ï¼šå…ˆè·å–attnå¤„ç†åçš„Pointå¯¹è±¡ï¼Œå†å•ç‹¬å¯¹featåº”ç”¨drop_path
        point_attn = self.attn(point)  # å¾—åˆ°Pointå¯¹è±¡
        point_attn = self.attn_norm(point_attn)  # æ–°å¢ï¼šç¨³å®šæ³¨æ„åŠ›å±‚è¾“å‡º
        # åªå¯¹featåº”ç”¨drop_pathï¼Œä¿ç•™Pointå¯¹è±¡å…¶ä»–å­—æ®µ
        point_attn.feat = self.drop_path(point_attn.feat)
        # æ®‹å·®è¿æ¥ï¼šæ›´æ–°feat
        point_attn.feat = shortcut + point_attn.feat
        # ä¼ é€’æ›´æ–°åçš„Pointå¯¹è±¡
        point = point_attn
        if not self.pre_norm:
            point = self.norm1(point)

        # 3. MLPå±‚ + DropPathï¼šåŒæ ·æ‰‹åŠ¨å¤„ç†ï¼Œä¿ç•™Pointå¯¹è±¡
        shortcut = point.feat
        if self.pre_norm:
            point = self.norm2(point)
        # å…³é”®ä¿®æ”¹ï¼šå…ˆè·å–mlpå¤„ç†åçš„Pointå¯¹è±¡ï¼Œå†å¯¹featåº”ç”¨drop_path
        point_mlp = self.mlp(point)  # å¾—åˆ°Pointå¯¹è±¡
        point_mlp = self.mlp_norm(point_mlp)  # æ–°å¢ï¼šç¨³å®šMLPå±‚è¾“å‡º
        point_mlp.feat = self.drop_path(point_mlp.feat)
        # æ®‹å·®è¿æ¥
        point_mlp.feat = shortcut + point_mlp.feat
        point = point_mlp
        if not self.pre_norm:
            point = self.norm2(point)

        # ğŸŒŸ æ–°å¢ï¼šBlockè¾“å‡ºæ ¡éªŒ
        if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
            sample_paths = point.get('path', ['æœªçŸ¥è·¯å¾„'])
            logging.error(
                f"Blockæœ€ç»ˆè¾“å‡ºå¼‚å¸¸ï¼æ ·æœ¬è·¯å¾„={sample_paths[:2]}, featå«NaN={torch.isnan(point.feat).any().item()}")

        # 4. æ›´æ–°sparse_conv_featï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
        point.sparse_conv_feat = point.sparse_conv_feat.replace_feature(point.feat)
        return point  # ç¡®ä¿è¿”å›çš„æ˜¯Pointå¯¹è±¡


class SerializedPooling(PointModule):
    def __init__(
        self,
        in_channels,
        out_channels,
        stride=2,
        norm_layer=None,
        act_layer=None,
        reduce="max",
        shuffle_orders=True,
        traceable=True,  # record parent and cluster
    ):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels

        assert stride == 2 ** (math.ceil(stride) - 1).bit_length()  # 2, 4, 8
        # TODO: add support to grid pool (any stride)
        self.stride = stride
        assert reduce in ["sum", "mean", "min", "max"]
        self.reduce = reduce
        self.shuffle_orders = shuffle_orders
        self.traceable = traceable

        self.proj = nn.Linear(in_channels, out_channels)
        if norm_layer is not None:
            self.norm = PointSequential(norm_layer(out_channels))
        if act_layer is not None:
            self.act = PointSequential(act_layer())

    def forward(self, point: Point):
        pooling_depth = (math.ceil(self.stride) - 1).bit_length()
        if pooling_depth > point.serialized_depth:
            pooling_depth = 0
        assert {
            "serialized_code",
            "serialized_order",
            "serialized_inverse",
            "serialized_depth",
        }.issubset(
            point.keys()
        ), "Run point.serialization() point cloud before SerializedPooling"

        # -------------------------- æ–°å¢ï¼šè®¡ç®—ä¸‹é‡‡æ ·åçš„offset --------------------------
        # 1. ä»åŸå§‹pointè·å–æ­£ç¡®çš„offsetï¼Œè®¡ç®—åŸå§‹æ ·æœ¬ç‚¹æ•°
        orig_offset = point.offset  # åŸå§‹offsetï¼ˆå¦‚[0,1920,3840]ï¼‰
        orig_bincount = offset2bincount(orig_offset, check_padding=False)  # åŸå§‹æ ·æœ¬ç‚¹æ•°ï¼ˆå¦‚[1920,1920]ï¼‰
        # 2. è®¡ç®—ä¸‹é‡‡æ ·åçš„æ¯ä¸ªæ ·æœ¬ç‚¹æ•°ï¼ˆåŸå§‹ç‚¹æ•° // ä¸‹é‡‡æ ·æ¯”ä¾‹strideï¼‰
        downsampled_bincount = orig_bincount // self.stride  # å¦‚[960,960]ï¼ˆstride=2æ—¶ï¼‰
        # 3. ç”Ÿæˆä¸‹é‡‡æ ·åçš„æ–°offsetï¼ˆç´¯åŠ ä¸‹é‡‡æ ·åçš„ç‚¹æ•°ï¼‰
        new_offset = torch.cat(
            [torch.tensor([0], device=orig_offset.device),
             torch.cumsum(downsampled_bincount, dim=0)],
            dim=0
        )  # æ–°offsetå¦‚[0,960,1920]
        # -------------------------- æ–°å¢ç»“æŸ --------------------------

        code = point.serialized_code >> pooling_depth * 3
        code_, cluster, counts = torch.unique(
            code[0],
            sorted=True,
            return_inverse=True,
            return_counts=True,
        )
        # indices of point sorted by cluster, for torch_scatter.segment_csr
        _, indices = torch.sort(cluster)
        # index pointer for sorted point, for torch_scatter.segment_csr
        idx_ptr = torch.cat([counts.new_zeros(1), torch.cumsum(counts, dim=0)])
        # head_indices of each cluster, for reduce attr e.g. code, batch
        head_indices = indices[idx_ptr[:-1]]
        # generate down code, order, inverse
        code = code[:, head_indices]
        order = torch.argsort(code)
        inverse = torch.zeros_like(order).scatter_(
            dim=1,
            index=order,
            src=torch.arange(0, code.shape[1], device=order.device).repeat(
                code.shape[0], 1
            ),
        )

        if self.shuffle_orders:
            perm = torch.randperm(code.shape[0])
            code = code[perm]
            order = order[perm]
            inverse = inverse[perm]

        # collect information
        point_dict = Dict(
            feat=torch_scatter.segment_csr(
                self.proj(point.feat)[indices], idx_ptr, reduce=self.reduce
            ),
            coord=torch_scatter.segment_csr(
                point.coord[indices], idx_ptr, reduce="mean"
            ),
            grid_coord=point.grid_coord[head_indices] >> pooling_depth,
            serialized_code=code,
            serialized_order=order,
            serialized_inverse=inverse,
            serialized_depth=point.serialized_depth - pooling_depth,
            batch=point.batch[head_indices],
            offset=new_offset,  # å…³é”®ï¼šæ·»åŠ ä¸‹é‡‡æ ·åçš„æ­£ç¡®offset
            path = point.get('path', ['æœªçŸ¥è·¯å¾„'])  # ğŸŒŸ æ–°å¢ï¼šä¿ç•™æ ·æœ¬è·¯å¾„ï¼Œç”¨äºå¼‚å¸¸å®šä½
        )

        if "condition" in point.keys():
            point_dict["condition"] = point.condition
        if "context" in point.keys():
            point_dict["context"] = point.context

        if self.traceable:
            point_dict["pooling_inverse"] = cluster
            point_dict["pooling_parent"] = point
        point = Point(point_dict)

        # ğŸŒŸ æ–°å¢ï¼šPoolingè¾“å‡ºæ ¡éªŒ
        if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
            logging.error(
                f"SerializedPoolingè¾“å‡ºå¼‚å¸¸ï¼æ ·æœ¬è·¯å¾„={point['path'][:2]}, featå«NaN={torch.isnan(point.feat).any().item()}")

        if self.norm is not None:
            point = self.norm(point)
        if self.act is not None:
            point = self.act(point)
        point.sparsify()
        return point


class SerializedUnpooling(PointModule):
    def __init__(
        self,
        in_channels,
        skip_channels,
        out_channels,
        norm_layer=None,
        act_layer=None,
        traceable=False,  # record parent and cluster
    ):
        super().__init__()
        self.proj = PointSequential(nn.Linear(in_channels, out_channels))
        self.proj_skip = PointSequential(nn.Linear(skip_channels, out_channels))

        if norm_layer is not None:
            self.proj.add(norm_layer(out_channels))
            self.proj_skip.add(norm_layer(out_channels))

        if act_layer is not None:
            self.proj.add(act_layer())
            self.proj_skip.add(act_layer())

        self.traceable = traceable

    def forward(self, point):
        assert "pooling_parent" in point.keys()
        assert "pooling_inverse" in point.keys()
        parent = point.pop("pooling_parent")
        inverse = point.pop("pooling_inverse")

        # ğŸŒŸ æ–°å¢ï¼šUnpoolingè¾“å…¥æ ¡éªŒ
        if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
            logging.error(f"SerializedUnpoolingè¾“å…¥å¼‚å¸¸ï¼point.featå«NaN={torch.isnan(point.feat).any().item()}")
        if torch.isnan(parent.feat).any() or torch.isinf(parent.feat).any():
            logging.error(f"SerializedUnpoolingçˆ¶æ ·æœ¬å¼‚å¸¸ï¼parent.featå«NaN={torch.isnan(parent.feat).any().item()}")

        point = self.proj(point)
        parent = self.proj_skip(parent)
        parent.feat = parent.feat + point.feat[inverse]

        # ğŸŒŸ æ–°å¢ï¼šUnpoolingè¾“å‡ºæ ¡éªŒ
        if torch.isnan(parent.feat).any() or torch.isinf(parent.feat).any():
            sample_paths = parent.get('path', ['æœªçŸ¥è·¯å¾„'])
            logging.error(
                f"SerializedUnpoolingè¾“å‡ºå¼‚å¸¸ï¼æ ·æœ¬è·¯å¾„={sample_paths[:2]}, featå«NaN={torch.isnan(parent.feat).any().item()}")

        if self.traceable:
            parent["unpooling_parent"] = point
        return parent


class Embedding(PointModule):
    def __init__(
        self,
        in_channels,
        embed_channels,
        norm_layer=None,
        act_layer=None,
    ):
        super().__init__()
        self.in_channels = in_channels
        self.embed_channels = embed_channels

        # TODO: check remove spconv
        self.stem = PointSequential(
            conv=spconv.SubMConv3d(
                in_channels,
                embed_channels,
                kernel_size=5,
                padding=1,
                bias=False,
                indice_key="stem",
            )
        )
        if norm_layer is not None:
            self.stem.add(norm_layer(embed_channels), name="norm")
        if act_layer is not None:
            self.stem.add(act_layer(), name="act")

    def forward(self, point: Point):
        # ğŸŒŸ æ–°å¢ï¼šåµŒå…¥å±‚è¾“å…¥æ ¡éªŒ
        if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
            sample_paths = point.get('path', ['æœªçŸ¥è·¯å¾„'])
            logging.error(
                f"Embeddingè¾“å…¥å¼‚å¸¸ï¼æ ·æœ¬è·¯å¾„={sample_paths[:2]}, featå«NaN={torch.isnan(point.feat).any().item()}")

        point = self.stem(point)

        # ğŸŒŸ æ–°å¢ï¼šåµŒå…¥å±‚è¾“å‡ºæ ¡éªŒ
        if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
            sample_paths = point.get('path', ['æœªçŸ¥è·¯å¾„'])
            logging.error(
                f"Embeddingè¾“å‡ºå¼‚å¸¸ï¼æ ·æœ¬è·¯å¾„={sample_paths[:2]}, featå«NaN={torch.isnan(point.feat).any().item()}")

        return point


@MODELS.register_module('PT-v3m1')
class PointTransformerV3(PointModule):
    def __init__(
        self,
        num_classes=5,  # æ˜ç¡®ä¸º5åˆ†ç±»ï¼ˆ0-4ï¼‰
        in_channels=6,
        order=("z", "z-trans"),
        stride=(2, 2, 2),
        enc_depths=(1, 1, 3, 1),
        enc_channels=(32, 64, 128, 256),
        enc_num_head=(2, 4, 8, 16),
        enc_patch_size=(48, 48, 48, 48),
        dec_depths=(1, 1, 1),
        dec_channels=(64, 64, 128),
        dec_num_head=(4, 4, 8),
        dec_patch_size=(48, 48, 48),
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        drop_path=0.5,
        pre_norm=True,
        shuffle_orders=True,
        enable_rpe=False,
        enable_flash=True,  # ä¿®æ­£ï¼šç”¨æˆ·æœªå®‰è£…flash_attnï¼Œè®¾ä¸ºFalse
        upcast_attention=False,
        upcast_softmax=False,
        cls_mode=False,
        pdnorm_bn=False,
        pdnorm_ln=False,
        pdnorm_decouple=True,
        pdnorm_adaptive=False,
        pdnorm_affine=True,
        pdnorm_conditions=("ScanNet", "S3DIS", "Structured3D"),
    ):
        super().__init__()
        self.num_classes = num_classes  # ä¿å­˜ç±»åˆ«æ•°
        self.num_stages = len(enc_depths)
        self.order = [order] if isinstance(order, str) else order
        self.cls_mode = cls_mode
        self.shuffle_orders = shuffle_orders

        # æ ¡éªŒå‚æ•°é•¿åº¦ï¼ˆç¡®ä¿ç¼–ç å™¨/è§£ç å™¨å‚æ•°åŒ¹é…ï¼‰
        assert self.num_stages == len(stride) + 1
        assert self.num_stages == len(enc_depths) == len(enc_channels) == len(enc_num_head) == len(enc_patch_size)
        if not self.cls_mode:
            assert self.num_stages == len(dec_depths) + 1 == len(dec_channels) + 1 == len(dec_num_head) + 1 == len(
                dec_patch_size) + 1

        # å½’ä¸€åŒ–å±‚é…ç½®
        if pdnorm_bn:
            bn_layer = partial(
                PDNorm,
                norm_layer=partial(
                    nn.BatchNorm1d, eps=1e-3, momentum=0.01, affine=pdnorm_affine
                ),
                conditions=pdnorm_conditions,
                decouple=pdnorm_decouple,
                adaptive=pdnorm_adaptive,
            )
        else:
            bn_layer = partial(nn.BatchNorm1d, eps=1e-3, momentum=0.01)
        if pdnorm_ln:
            ln_layer = partial(
                PDNorm,
                norm_layer=partial(nn.LayerNorm, elementwise_affine=pdnorm_affine),
                conditions=pdnorm_conditions,
                decouple=pdnorm_decouple,
                adaptive=pdnorm_adaptive,
            )
        else:
            ln_layer = nn.LayerNorm
        # activation layers
        act_layer = nn.GELU

        # åµŒå…¥å±‚
        self.embedding = Embedding(
            in_channels=in_channels,
            embed_channels=enc_channels[0],
            norm_layer=bn_layer,
            act_layer=act_layer,
        )

        # ç¼–ç å™¨
        enc_drop_path = [
            x.item() for x in torch.linspace(0, drop_path, sum(enc_depths))
        ]
        self.enc = PointSequential()
        for s in range(self.num_stages):
            enc_drop_path_ = enc_drop_path[
                sum(enc_depths[:s]) : sum(enc_depths[: s + 1])
            ]
            enc = PointSequential()
            if s > 0:
                enc.add(
                    SerializedPooling(
                        in_channels=enc_channels[s - 1],
                        out_channels=enc_channels[s],
                        stride=stride[s - 1],
                        norm_layer=bn_layer,
                        act_layer=act_layer,
                    ),
                    name="down",
                )
            for i in range(enc_depths[s]):
                enc.add(
                    Block(
                        channels=enc_channels[s],
                        num_heads=enc_num_head[s],
                        patch_size=enc_patch_size[s],
                        mlp_ratio=mlp_ratio,
                        qkv_bias=qkv_bias,
                        qk_scale=qk_scale,
                        attn_drop=attn_drop,
                        proj_drop=proj_drop,
                        drop_path=enc_drop_path_[i],
                        norm_layer=ln_layer,
                        act_layer=act_layer,
                        pre_norm=pre_norm,
                        order_index=i % len(self.order),
                        cpe_indice_key=f"stage{s}",
                        enable_rpe=enable_rpe,
                        enable_flash=enable_flash,
                        upcast_attention=upcast_attention,
                        upcast_softmax=upcast_softmax,
                    ),
                    name=f"block{i}",
                )
            if len(enc) != 0:
                self.enc.add(module=enc, name=f"enc{s}")

        # è§£ç å™¨
        self.dec = None
        self.original_dec_channels = dec_channels  # ä¿å­˜åŸå§‹è§£ç å™¨é€šé“é…ç½®
        if not self.cls_mode:
            dec_drop_path = [
                x.item() for x in torch.linspace(0, drop_path, sum(dec_depths))
            ]
            self.dec = PointSequential()
            # æ³¨æ„ï¼šè¿™é‡Œæ‹¼æ¥äº†ç¼–ç å™¨æœ€åä¸€å±‚é€šé“ï¼Œä½†ä»…ç”¨äºè§£ç å™¨å†…éƒ¨è®¡ç®—
            dec_channels = list(dec_channels) + [enc_channels[-1]]
            for s in reversed(range(self.num_stages - 1)):
                dec_drop_path_ = dec_drop_path[
                    sum(dec_depths[:s]) : sum(dec_depths[: s + 1][::-1])
                ]
                dec = PointSequential()
                dec.add(
                    SerializedUnpooling(
                        in_channels=dec_channels[s + 1],
                        skip_channels=enc_channels[s],
                        out_channels=dec_channels[s],
                        norm_layer=bn_layer,
                        act_layer=act_layer,
                    ),
                    name="up",
                )
                for i in range(dec_depths[s]):
                    dec.add(
                        Block(
                            channels=dec_channels[s],
                            num_heads=dec_num_head[s],
                            patch_size=dec_patch_size[s],
                            mlp_ratio=mlp_ratio,
                            qkv_bias=qkv_bias,
                            qk_scale=qk_scale,
                            attn_drop=attn_drop,
                            proj_drop=proj_drop,
                            drop_path=dec_drop_path_[i],
                            norm_layer=ln_layer,
                            act_layer=act_layer,
                            pre_norm=pre_norm,
                            order_index=i % len(self.order),
                            cpe_indice_key=f"stage{s}",
                            enable_rpe=enable_rpe,
                            enable_flash=enable_flash,
                            upcast_attention=upcast_attention,
                            upcast_softmax=upcast_softmax,
                        ),
                        name=f"block{i}",
                    )
                self.dec.add(module=dec, name=f"dec{s}")

        # åˆ†ç±»å¤´ï¼ˆå¤šåˆ†ç±»ï¼Œ0-4å…±5ç±»ï¼‰
        if not self.cls_mode:
            self.head = nn.Linear(self.original_dec_channels[0], self.num_classes)  # è¾“å‡º5ä¸ªé€šé“ï¼ˆå¯¹åº”5ç±»ï¼‰
        else:
            self.head = nn.Linear(enc_channels[-1], self.num_classes)  # è¾“å‡º5ä¸ªé€šé“ï¼ˆå¯¹åº”5ç±»ï¼‰

    def forward(self, data_dict):
        # ğŸŒŸ æ–°å¢ï¼šæ‰“å°æ¥æ”¶çš„å­—æ®µï¼Œç¡®è®¤pathæ˜¯å¦å­˜åœ¨
        #print(f"æ¨¡å‹æ¥æ”¶çš„data_dictå­—æ®µï¼š{list(data_dict.keys())}")  # å…³é”®è°ƒè¯•
        # ğŸŒŸ é¦–å…ˆæ£€æŸ¥pathæ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
        if 'path' not in data_dict or data_dict['path'][0] == 'æœªçŸ¥è·¯å¾„':
            raise ValueError(f"æ ·æœ¬pathä¸¢å¤±ï¼å½“å‰data_dictä¸­çš„path: {data_dict.get('path', 'æ— ')}")
        # ğŸŒŸ å…³é”®1ï¼šä¿ç•™æ ·æœ¬è·¯å¾„ï¼Œç”¨äºå¼‚å¸¸å®šä½
        sample_paths = data_dict.get('path', ['æœªçŸ¥è·¯å¾„'])
        # æ‰“å°å‰1ä¸ªæ ·æœ¬çš„pathï¼Œç¡®è®¤æœ‰æ•ˆ
        logging.info(f"å½“å‰batchæ ·æœ¬è·¯å¾„: {[os.path.basename(p) for p in sample_paths[:1]]}")
        # ğŸŒŸ å…³é”®2ï¼šè®¡ç®—å¹¶æ‰“å°spatial_shapeï¼ˆéªŒè¯é›†æ ¸å¿ƒè°ƒè¯•ä¿¡æ¯ï¼‰
        coord = data_dict['coord']
        spatial_shape = [
            int(coord[:, 2].max().item()) + 1,  # zè½´ï¼ˆspconvé»˜è®¤z/y/xé¡ºåºï¼Œå¿…é¡»å¯¹åº”ï¼‰
            int(coord[:, 1].max().item()) + 1,  # yè½´
            int(coord[:, 0].max().item()) + 1  # xè½´ï¼ˆæ³¨æ„ï¼šcoordæ˜¯[x,y,z]ï¼Œéœ€è°ƒæ•´é¡ºåºï¼‰
        ]
        # åŒºåˆ†è®­ç»ƒ/éªŒè¯æ¨¡å¼ï¼Œæ‰“å°spatial_shapeï¼ˆå…³é”®ï¼šéªŒè¯æ˜¯å¦è¿‡å¤§ï¼‰
        mode = "è®­ç»ƒé›†" if self.training else "éªŒè¯é›†"
        logging.info(
            f"ã€{mode}ã€‘æ ·æœ¬è·¯å¾„={[os.path.basename(p) for p in sample_paths[:2]]}, "
            f"æ€»ç‚¹æ•°={coord.shape[0]}, spatial_shape={spatial_shape}ï¼ˆz/y/xï¼‰"
        )
        # æ£€æŸ¥spatial_shapeæ˜¯å¦è¿‡å¤§ï¼ˆè¶…è¿‡2000è§†ä¸ºå¼‚å¸¸ï¼Œéœ€åç»­è£å‰ªcoordï¼‰
        #TODO
        '''
        if any(dim > 2000 for dim in spatial_shape):
            logging.warning(
                f"âš ï¸ {mode} spatial_shapeè¿‡å¤§ï¼å„ç»´åº¦åº”â‰¤2000ï¼Œå½“å‰={spatial_shape}ï¼Œå¯èƒ½å¯¼è‡´logits=nan"
            )
        '''
        # 1. æ„å»ºPointå¯¹è±¡ï¼ˆä¿ç•™pathå­—æ®µï¼‰
        data_dict['path'] = sample_paths  # ç¡®ä¿pathä¼ å…¥Pointå¯¹è±¡
        point = Point(data_dict)
        # 2. ä¿ç•™åºåˆ—åŒ–é€»è¾‘ï¼ˆåŸæœ‰ä»£ç ï¼Œå¤„ç†ç‚¹äº‘é¡ºåºï¼‰
        point.serialization(order=self.order, shuffle_orders=self.shuffle_orders)
        # ğŸŒŸ å…³é”®3ï¼šæ›¿æ¢point.sparsify()ï¼Œæ‰‹åŠ¨æ„å»ºSparseConvTensorï¼ˆå¸¦allow_empty=Trueï¼‰
        # 3.1 ç”Ÿæˆæ ·æœ¬ç´¢å¼•ï¼ˆbatch_idxï¼‰ï¼šæ¯ä¸ªç‚¹å±äºå“ªä¸ªæ ·æœ¬
        batch_size = len(point.offset) - 1  # offseté•¿åº¦=æ ·æœ¬æ•°+1ï¼Œå¦‚[0,1920,3840]å¯¹åº”2ä¸ªæ ·æœ¬
        batch_idx = []
        for i in range(batch_size):
            start = point.offset[i].item()  # ç¬¬iä¸ªæ ·æœ¬çš„èµ·å§‹ç‚¹ç´¢å¼•
            end = point.offset[i + 1].item()  # ç¬¬iä¸ªæ ·æœ¬çš„ç»“æŸç‚¹ç´¢å¼•
            batch_idx.extend([i] * (end - start))  # ä¸ºæ¯ä¸ªç‚¹åˆ†é…æ ·æœ¬ç´¢å¼•
        # è½¬æ¢ä¸ºå¼ é‡å¹¶è°ƒæ•´å½¢çŠ¶ï¼ˆ[N,1]ï¼ŒNä¸ºæ€»ç‚¹æ•°ï¼‰
        batch_idx = torch.tensor(batch_idx, device=point.coord.device, dtype=torch.int32).unsqueeze(1)

        # 3.2 æ„å»ºindicesï¼ˆspconvè¦æ±‚æ ¼å¼ï¼š[z, y, x, batch_idx]ï¼Œå…±4åˆ—ï¼‰
        # æ³¨æ„ï¼šcoordåŸå§‹æ ¼å¼æ˜¯[x,y,z]ï¼Œéœ€è°ƒæ•´ä¸º[z,y,x]
        z_coord = point.coord[:, 2].unsqueeze(1).to(torch.int32)  # ç¬¬3åˆ—æ˜¯z
        y_coord = point.coord[:, 1].unsqueeze(1).to(torch.int32)  # ç¬¬2åˆ—æ˜¯y
        x_coord = point.coord[:, 0].unsqueeze(1).to(torch.int32)  # ç¬¬1åˆ—æ˜¯x
        indices = torch.cat([z_coord, y_coord, x_coord, batch_idx], dim=1)  # æ‹¼æ¥ä¸º[N,4]

        #point.sparsify()

        # 3.3 æ‰‹åŠ¨åˆ›å»ºSparseConvTensorï¼Œæ˜¾å¼è®¾ç½®allow_empty=True
        # æ­¥éª¤1ï¼šå…ˆåˆ›å»ºç©ºçš„SparseConvTensorï¼ˆç”¨é»˜è®¤å‚æ•°ï¼‰
        sparse_tensor = spconv.SparseConvTensor(
            features=point.feat,  # ç‚¹äº‘ç‰¹å¾ï¼ˆ[N, C]ï¼‰
            indices=indices,  # åæ ‡+æ ·æœ¬ç´¢å¼•ï¼ˆ[N,4]ï¼‰
            spatial_shape=spatial_shape,  # ä½“ç´ ç½‘æ ¼å¤§å°ï¼ˆz/y/xï¼‰
            batch_size=batch_size,  # æ‰¹æ¬¡å¤§å°
        )
        # æ­¥éª¤2ï¼šæ‰‹åŠ¨è®¾ç½®allow_empty=Trueï¼ˆç»•è¿‡fxå¯¹__init__çš„è¿½è¸ªï¼‰
        sparse_tensor.allow_empty = True  # ç›´æ¥ä¿®æ”¹å±æ€§ï¼Œè€Œéé€šè¿‡__init__å‚æ•°

        # èµ‹å€¼ç»™point.sparse_conv_feat
        point.sparse_conv_feat = sparse_tensor

        # 4.åµŒå…¥å±‚
        point = self.embedding(point)
        # 5.ç¼–ç å™¨
        point = self.enc(point)
        # 6.è§£ç å™¨ï¼ˆåˆ†å‰²æ¨¡å¼ï¼‰
        if not self.cls_mode and self.dec is not None:
            point = self.dec(point)

        # 7.åˆ†ç±»å¤´è®¡ç®—logits
        logits = self.head(point.feat)

        # 8.logitsæ•°å€¼æ ¡éªŒï¼ˆæœ€ç»ˆè¾“å‡ºæ£€æŸ¥ï¼‰
        if torch.isnan(logits).any() or torch.isinf(logits).any():
            nan_count = torch.isnan(logits).sum().item()
            inf_count = torch.isinf(logits).sum().item()
            logging.error(
                f"âŒ {mode} logitså¼‚å¸¸ï¼æ ·æœ¬è·¯å¾„={sample_paths[:2]}, "
                f"å«NaN={nan_count}ä¸ª, å«inf={inf_count}ä¸ª, logitsèŒƒå›´=[{logits.min().item():.4f}, {logits.max().item():.4f}]"
            )
        else:
            logging.info(
                f"âœ… {mode} logitsæ­£å¸¸ï¼èŒƒå›´=[{logits.min().item():.4f}, {logits.max().item():.4f}], å½¢çŠ¶={logits.shape}"
            )

        return logits  # è¿”å›å¯¹è±¡ï¼Œè€Œéå¼ é‡
