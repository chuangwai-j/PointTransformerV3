"""
Point Transformer - V3 Mode1

Author: Xiaoyang Wu (xiaoyang.wu.cs@gmail.com)
Please cite our work if the code is helpful to you.
"""
import os
from functools import partial
from addict import Dict
import logging
import math
import torch
import torch.nn as nn
import spconv.pytorch as spconv
import torch_scatter
from timm.layers import DropPath
from pointcept.utils.misc import offset2bincount
import warnings
from torch.fx import wrap
from spconv.pytorch import SparseConvTensor

try:
    import flash_attn
except ImportError:
    flash_attn = None

from pointcept.models.point_prompt_training import PDNorm
from pointcept.models.builder import MODELS
from pointcept.models.utils.structure import Point
from pointcept.models.modules import PointModule, PointSequential


class RPE(torch.nn.Module):
    def __init__(self, patch_size, num_heads):
        super().__init__()
        self.patch_size = patch_size
        self.num_heads = num_heads
        self.pos_bnd = int((4 * patch_size) ** (1 / 3) * 2)
        self.rpe_num = 2 * self.pos_bnd + 1
        self.rpe_table = torch.nn.Parameter(torch.zeros(3 * self.rpe_num, num_heads))
        torch.nn.init.trunc_normal_(self.rpe_table, std=0.02)

    def forward(self, coord):
        idx = (
            coord.clamp(-self.pos_bnd, self.pos_bnd)  # clamp into bnd
            + self.pos_bnd  # relative position to positive index
            + torch.arange(3, device=coord.device) * self.rpe_num  # x, y, z stride
        )
        out = self.rpe_table.index_select(0, idx.reshape(-1))
        out = out.view(idx.shape + (-1,)).sum(3)
        out = out.permute(0, 3, 1, 2)  # (N, K, K, H) -> (N, H, K, K)
        return out


class SerializedAttention(PointModule):
    def __init__(
        self,
        channels,
        num_heads,
        patch_size=16,  # é‚»åŸŸç‚¹æ•°kï¼ˆåŸä½œè€…ç”¨patch_sizeè¡¨ç¤ºkï¼‰
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        order_index=0,
        enable_rpe=False,
        enable_flash=False,
        upcast_attention=True,
        upcast_softmax=True,
    ):
        super().__init__()
        assert channels % num_heads == 0
        self.channels = channels
        self.num_heads = num_heads
        self.scale = qk_scale or (channels // num_heads) ** -0.5
        self.order_index = order_index
        self.upcast_attention = upcast_attention
        self.upcast_softmax = upcast_softmax
        self.enable_rpe = enable_rpe
        self.enable_flash = enable_flash

        # åŸä½œè€…æ ¸å¿ƒå‚æ•°ï¼šé‚»åŸŸç‚¹æ•°k=patch_sizeï¼Œå‰åå„å–k_halfä¸ª
        self.patch_size = patch_size
        self.k_half = self.patch_size // 2  # å¦‚k=16â†’k_half=8

        # ç§»é™¤flashç›¸å…³é€»è¾‘ï¼ˆå› æ˜¾å¼é‚»åŸŸæ— éœ€flashä¼˜åŒ–ï¼‰
        self.attn_drop = torch.nn.Dropout(attn_drop)
        self.qkv = torch.nn.Linear(channels, channels * 3, bias=qkv_bias)
        self.proj = torch.nn.Linear(channels, channels)
        self.proj_drop = torch.nn.Dropout(proj_drop)
        self.softmax = torch.nn.Softmax(dim=-1)
        self.rpe = RPE(patch_size, num_heads) if self.enable_rpe else None

    def forward(self, point):
        # ğŸŒŸ 1.1 è·å–åŸä½œè€…ä¾èµ–çš„æ ¸å¿ƒå­—æ®µï¼ˆz-orderæ’åºç»“æœï¼‰
        sorted_order = point["serialized_order"][self.order_index]  # [N]ï¼šæ’åºåçš„åŸå§‹ç‚¹ç´¢å¼•
        N = sorted_order.shape[0]  # å½“å‰é˜¶æ®µæ€»ç‚¹æ•°
        device = sorted_order.device

        # ğŸŒŸ 1.2 å‘é‡åŒ–è®¡ç®—â€œç‚¹â†’æ’åºä½ç½®â€çš„æ˜ å°„ï¼ˆå¿«é€Ÿåå‘ç´¢å¼•ï¼‰
        sorted_pos = torch.zeros(N, dtype=torch.long, device=device)
        sorted_pos[sorted_order] = torch.arange(N, device=device)  # [N]ï¼šæ¯ä¸ªåŸå§‹ç‚¹åœ¨æ’åºä¸­çš„ä½ç½®

        # ğŸŒŸ 1.3 å®æ—¶åˆ‡ç‰‡ç”Ÿæˆé‚»åŸŸï¼ˆåŸä½œè€…æ ¸å¿ƒé€»è¾‘ï¼Œè¿ç»­å†…å­˜è®¿é—®ï¼‰
        # è®¡ç®—æ¯ä¸ªç‚¹çš„é‚»åŸŸèŒƒå›´ï¼ˆè¾¹ç•Œè£å‰ªï¼Œé¿å…è¶Šç•Œï¼‰
        start = torch.clamp(sorted_pos - self.k_half, min=0, max=N)  # [N]ï¼šé‚»åŸŸèµ·å§‹ä½ç½®
        end = torch.clamp(sorted_pos + self.k_half + 1, min=0, max=N)  # [N]ï¼šé‚»åŸŸç»“æŸä½ç½®ï¼ˆ+1æ˜¯åˆ‡ç‰‡å³å¼€åŒºé—´ï¼‰
        # å‘é‡åŒ–ç”Ÿæˆé‚»åŸŸä½ç½®ï¼ˆ0~k-1ï¼‰
        pos_range = torch.arange(self.patch_size, device=device).unsqueeze(0)  # [1, 16]
        neighbor_pos = start.unsqueeze(1) + pos_range  # [N, 16]ï¼šæ¯ä¸ªç‚¹çš„é‚»åŸŸåœ¨sorted_orderä¸­çš„ä½ç½®
        neighbor_pos = torch.min(neighbor_pos, end.unsqueeze(1) - 1)  # æˆªæ–­è¶Šç•Œä½ç½®
        # æå–é‚»åŸŸç´¢å¼•ï¼ˆè¿ç»­å†…å­˜è®¿é—®ï¼ŒGPUæå¿«ï¼‰
        neighbor_indices = sorted_order[neighbor_pos]  # [N, 16]ï¼šæœ€ç»ˆé‚»åŸŸç´¢å¼•

        # ğŸŒŸ 1.4 ï¼ˆå¯é€‰ï¼‰è·¨æ ·æœ¬æ ¡éªŒï¼ˆå¦‚éœ€åˆ†æ ·æœ¬è®­ç»ƒï¼Œä¿ç•™æ­¤æ®µï¼›å¦åˆ™å¯æ³¨é‡Šï¼‰
        if "offset" in point:
            offsets = point["offset"]
            num_samples = len(offsets) - 1
            # æ¯ä¸ªç‚¹çš„æ ·æœ¬ID
            point_sample_id = torch.searchsorted(offsets[1:], torch.arange(N, device=device))
            # æ¯ä¸ªæ ·æœ¬çš„è¾¹ç•Œ
            sample_starts = offsets[:-1][point_sample_id].unsqueeze(1)  # [N, 1]
            sample_ends = offsets[1:][point_sample_id].unsqueeze(1)  # [N, 1]
            # è·¨æ ·æœ¬æ©ç ï¼šé‚»åŸŸç´¢å¼•è¶…å‡ºå½“å‰æ ·æœ¬èŒƒå›´
            cross_mask = (neighbor_indices < sample_starts) | (neighbor_indices >= sample_ends)
            # è·¨æ ·æœ¬ç´¢å¼•æ›¿æ¢ä¸ºå½“å‰ç‚¹è‡ªèº«ï¼ˆé¿å…å¹²æ‰°ï¼‰
            self_indices = torch.arange(N, device=device).unsqueeze(1)  # [N, 1]
            neighbor_indices = torch.where(cross_mask, self_indices, neighbor_indices)

        # ğŸŒŸ 1.5 åç»­æ³¨æ„åŠ›è®¡ç®—ï¼ˆä¸åŸé€»è¾‘ä¸€è‡´ï¼Œæ— å†—ä½™ï¼‰
        feat = point.feat  # [N, C]
        qkv = self.qkv(feat)  # [N, 3*C]
        q, k, v = qkv.chunk(3, dim=-1)  # [N, C] Ã—3

        # æå–é‚»åŸŸçš„kå’Œvï¼ˆè¿ç»­å†…å­˜è®¿é—®ï¼Œå¿«ï¼‰
        k_neighbor = k[neighbor_indices]  # [N, 16, C]
        v_neighbor = v[neighbor_indices]  # [N, 16, C]

        # å¤šå¤´ç»´åº¦è°ƒæ•´
        H = self.num_heads
        C_head = self.channels // H
        q = q.reshape(N, H, C_head).unsqueeze(2)  # [N, H, 1, C_head]
        k_neighbor = k_neighbor.reshape(N, self.patch_size, H, C_head).permute(0, 2, 1, 3)  # [N, H, 16, C_head]
        v_neighbor = v_neighbor.reshape(N, self.patch_size, H, C_head).permute(0, 2, 1, 3)  # [N, H, 16, C_head]

        # æ³¨æ„åŠ›åˆ†æ•°è®¡ç®—
        if self.upcast_attention:
            q = q.float()
            k_neighbor = k_neighbor.float()
        attn = (q * self.scale) @ k_neighbor.transpose(-2, -1)  # [N, H, 1, 16]

        # å¯é€‰RPE
        if self.enable_rpe:
            grid_coord = point.grid_coord  # [N, 3]
            neighbor_grid = grid_coord[neighbor_indices]  # [N, 16, 3]
            rel_pos = grid_coord.unsqueeze(1) - neighbor_grid  # [N, 16, 3]
            rpe = self.rpe(rel_pos)  # [N, H, 1, 16]
            attn += rpe

        # å½’ä¸€åŒ–ä¸dropout
        if self.upcast_softmax:
            attn = attn.float()
        attn = self.softmax(attn)
        attn = self.attn_drop(attn).to(qkv.dtype)

        # åŠ æƒæ±‚å’Œä¸æŠ•å½±
        feat_attn = (attn @ v_neighbor).squeeze(2).reshape(N, self.channels)  # [N, C]
        feat_attn = self.proj(feat_attn)
        feat_attn = self.proj_drop(feat_attn)

        # å¼‚å¸¸å€¼æ ¡éªŒï¼ˆä¿ç•™æ ¸å¿ƒï¼Œç²¾ç®€æ—¥å¿—ï¼‰
        #if torch.isnan(feat_attn).any() or torch.isinf(feat_attn).any():
        #    sample_paths = point.get('path', ['æœªçŸ¥è·¯å¾„'])
        #    logging.error(
        #        f"SerializedAttentionå¼‚å¸¸ï¼æ ·æœ¬={sample_paths[:1]}, NaN={torch.isnan(feat_attn).any()}"
        #    )

        # æ›´æ–°ç‰¹å¾
        point.feat = feat_attn
        return point

class MLP(nn.Module):
    def __init__(
        self,
        in_channels,
        hidden_channels=None,
        out_channels=None,
        act_layer=nn.GELU,
        drop=0.0,
    ):
        super().__init__()
        out_channels = out_channels or in_channels
        hidden_channels = hidden_channels or in_channels
        self.fc1 = nn.Linear(in_channels, hidden_channels)
        self.act = act_layer()
        self.fc2 = nn.Linear(hidden_channels, out_channels)
        self.drop = nn.Dropout(drop)

    def forward(self, x):
        # MLPè¾“å…¥æ•°å€¼æ ¡éªŒ
        if torch.isnan(x).any() or torch.isinf(x).any():
            logging.error(f"MLPè¾“å…¥å¼‚å¸¸ï¼šå«NaN={torch.isnan(x).any().item()}, å«inf={torch.isinf(x).any().item()}")

        x = self.fc1(x)
        x = self.act(x)
        x = self.drop(x)
        x = self.fc2(x)
        x = self.drop(x)
        return x


class Block(PointModule):
    def __init__(
        self,
        channels,
        num_heads,
        patch_size=48,
        mlp_ratio=4.0,
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        drop_path=0.0,
        norm_layer=nn.LayerNorm,
        act_layer=nn.GELU,
        pre_norm=True,
        order_index=0,
        cpe_indice_key=None,
        enable_rpe=False,
        enable_flash=False,
        upcast_attention=True,
        upcast_softmax=True,
    ):
        super().__init__()
        self.channels = channels
        self.pre_norm = pre_norm

        self.cpe = PointSequential(
            spconv.SubMConv3d(
                channels,
                channels,
                kernel_size=3,
                bias=True,
                indice_key=cpe_indice_key,
            ),
            nn.Linear(channels, channels),
            norm_layer(channels),
        )

        self.norm1 = PointSequential(norm_layer(channels))
        self.attn = SerializedAttention(
            channels=channels,
            num_heads=num_heads,
            patch_size=patch_size, # å®é™…è¢«kæ›¿ä»£
            qkv_bias=qkv_bias,
            qk_scale=qk_scale,
            attn_drop=attn_drop,
            proj_drop=proj_drop,
            order_index=order_index,
            enable_rpe=enable_rpe,
            enable_flash=enable_flash,
            upcast_attention=upcast_attention,
            upcast_softmax=upcast_softmax,
        )
        self.norm2 = PointSequential(norm_layer(channels))
        self.mlp = PointSequential(
            MLP(
                in_channels=channels,
                hidden_channels=int(channels * mlp_ratio),
                out_channels=channels,
                act_layer=act_layer,
                drop=proj_drop,
            )
        )
        # DropPathï¼ˆç²¾ç®€å®ç°ï¼‰
        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()

    def forward(self, point: Point):
        shortcut = point.feat  # ä¿å­˜åŸå§‹featï¼ˆç”¨äºæ®‹å·®è¿æ¥ï¼‰

        # 1. CPEå±‚ï¼šæ­£å¸¸å¤„ç†Pointå¯¹è±¡
        point = self.cpe(point)
        point.feat = shortcut + point.feat  # æ®‹å·®è¿æ¥
        shortcut = point.feat  # æ›´æ–°shortcutä¸ºCPEå¤„ç†åçš„feat

        # 2. æ³¨æ„åŠ›å±‚ + DropPathï¼šæ‰‹åŠ¨å¤„ç†Pointå¯¹è±¡ï¼Œä¸ç ´åç»“æ„
        if self.pre_norm:
            point = self.norm1(point)
        # å…³é”®ä¿®æ”¹ï¼šå…ˆè·å–attnå¤„ç†åçš„Pointå¯¹è±¡ï¼Œå†å•ç‹¬å¯¹featåº”ç”¨drop_path
        point = self.attn(point)  # å¾—åˆ°Pointå¯¹è±¡
        point.feat = shortcut + self.drop_path(point.feat)

        # 3. MLPå±‚ + DropPathï¼šåŒæ ·æ‰‹åŠ¨å¤„ç†ï¼Œä¿ç•™Pointå¯¹è±¡
        shortcut = point.feat
        if self.pre_norm:
            point = self.norm2(point)
        point = self.mlp(point)
        point.feat = shortcut + self.drop_path(point.feat)
        '''
        # å…³é”®ä¿®æ”¹ï¼šå…ˆè·å–mlpå¤„ç†åçš„Pointå¯¹è±¡ï¼Œå†å¯¹featåº”ç”¨drop_path
        point_mlp = self.mlp(point)  # å¾—åˆ°Pointå¯¹è±¡
        point_mlp = self.mlp_norm(point_mlp)  # æ–°å¢ï¼šç¨³å®šMLPå±‚è¾“å‡º
        point_mlp.feat = self.drop_path(point_mlp.feat)
        # æ®‹å·®è¿æ¥
        point_mlp.feat = shortcut + point_mlp.feat
        point = point_mlp
        if not self.pre_norm:
            point = self.norm2(point)
        '''

        # 4. æ›´æ–°sparse_conv_feat
        point.sparse_conv_feat = point.sparse_conv_feat.replace_feature(point.feat)
        return point  # ç¡®ä¿è¿”å›çš„æ˜¯Pointå¯¹è±¡


class SerializedPooling(PointModule):
    def __init__(
        self,
        in_channels,
        out_channels,
        stride=2,
        norm_layer=None,
        act_layer=None,
        reduce="max",
        shuffle_orders=True,
        traceable=True,  # record parent and cluster
    ):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels

        assert stride == 2 ** (math.ceil(stride) - 1).bit_length()  # 2, 4, 8
        # TODO: add support to grid pool (any stride)
        self.stride = stride
        assert reduce in ["sum", "mean", "min", "max"]
        self.reduce = reduce
        self.shuffle_orders = shuffle_orders
        self.traceable = traceable
        self.proj = nn.Linear(in_channels, out_channels)
        self.norm = PointSequential(norm_layer(out_channels)) if norm_layer else None
        self.act = PointSequential(act_layer()) if act_layer else None

    def forward(self, point: Point):
        pooling_depth = (math.ceil(self.stride) - 1).bit_length()
        if pooling_depth > point.serialized_depth:
            pooling_depth = 0
        assert {
            "serialized_code", "serialized_order", "serialized_inverse", "serialized_depth"
        }.issubset(point.keys()), "éœ€å…ˆè°ƒç”¨serialization()"

        code = point.serialized_code >> pooling_depth * 3
        code_, cluster, counts = torch.unique(
            code[0],
            sorted=True,
            return_inverse=True,
            return_counts=True,
        )
        # indices of point sorted by cluster, for torch_scatter.segment_csr
        _, indices = torch.sort(cluster)
        # index pointer for sorted point, for torch_scatter.segment_csr
        idx_ptr = torch.cat([counts.new_zeros(1), torch.cumsum(counts, dim=0)])
        # head_indices of each cluster, for reduce attr e.g. code, batch
        head_indices = indices[idx_ptr[:-1]]
        pooled_batch = point.batch[head_indices]  # æ± åŒ–åæ¯ä¸ªç‚¹çš„æ ·æœ¬IDï¼ˆ0~num_samples-1ï¼‰
        new_total_points = len(head_indices)  # æ± åŒ–åçš„æ€»ç‚¹æ•°ï¼ˆå…³é”®ï¼šç”±èšç±»ç»“æœå†³å®šï¼‰

        # ğŸŒŸ ä¿®å¤ï¼šåŸºäºæ± åŒ–åçš„batchç»Ÿè®¡æ¯ä¸ªæ ·æœ¬çš„å®é™…ç‚¹æ•°ï¼Œç”Ÿæˆæ­£ç¡®çš„new_offset
        num_samples = len(point.offset) - 1  # æ ·æœ¬æ•°é‡ä¸å˜
        # ç»Ÿè®¡æ¯ä¸ªæ ·æœ¬åœ¨æ± åŒ–åçš„ç‚¹æ•°ï¼ˆbincountï¼šç´¢å¼•ä¸ºæ ·æœ¬IDï¼Œå€¼ä¸ºè¯¥æ ·æœ¬çš„ç‚¹æ•°ï¼‰
        downsampled_bincount = torch.bincount(pooled_batch, minlength=num_samples)
        # ç”Ÿæˆæ–°offsetï¼ˆç´¯åŠ å®é™…ç‚¹æ•°ï¼‰
        new_offset = torch.cat([
            torch.tensor([0], device=point.offset.device),
            torch.cumsum(downsampled_bincount, dim=0)
        ], dim=0)
        assert new_offset[-1].item() == new_total_points, "Poolingåoffseté”™è¯¯"

        # generate down code, order, inverseç”Ÿæˆæ± åŒ–åçš„æ’åºç›¸å…³å­—æ®µ
        code = code[:, head_indices]
        order = torch.argsort(code)
        if self.shuffle_orders:
            perm = torch.randperm(code.shape[0])
            code = code[perm]
            order = order[perm]
        inverse = torch.zeros_like(order).scatter_(
            dim=1,
            index=order,
            src=torch.arange(0, code.shape[1], device=order.device).repeat(
                code.shape[0], 1
            ),
        )

        # collect information æ„å»ºæ–°Pointå¯¹è±¡
        point_dict = Dict(
            feat=torch_scatter.segment_csr(
                self.proj(point.feat)[indices], idx_ptr, reduce=self.reduce
            ),
            coord=torch_scatter.segment_csr(
                point.coord[indices], idx_ptr, reduce="mean"
            ),
            grid_coord=point.grid_coord[head_indices] >> pooling_depth,
            serialized_code=code,
            serialized_order=order,
            serialized_inverse=inverse,
            serialized_depth=point.serialized_depth - pooling_depth,
            batch=point.batch[head_indices],
            offset=new_offset,  # å…³é”®ï¼šæ·»åŠ ä¸‹é‡‡æ ·åçš„æ­£ç¡®offset
            path = point.get('path', ['æœªçŸ¥è·¯å¾„'])  # ğŸŒŸ æ–°å¢ï¼šä¿ç•™æ ·æœ¬è·¯å¾„ï¼Œç”¨äºå¼‚å¸¸å®šä½
        )
        if "condition" in point.keys():
            point_dict["condition"] = point.condition
        if self.traceable:
            point_dict["pooling_inverse"] = cluster
            point_dict["pooling_parent"] = point
        point = Point(point_dict)

        # ç²¾ç®€æ ¡éªŒï¼ˆä¿ç•™æ ¸å¿ƒï¼Œå‡å°‘æ—¥å¿—ï¼‰
        #if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
        #    logging.error(f"SerializedPoolingå¼‚å¸¸ï¼æ ·æœ¬={point['path'][:1]}")

        if self.norm is not None:
            point = self.norm(point)
        if self.act is not None:
            point = self.act(point)
        point.sparsify()
        return point


class SerializedUnpooling(PointModule):
    def __init__(
        self,
        in_channels,
        skip_channels,
        out_channels,
        norm_layer=None,
        act_layer=None,
        traceable=False,  # record parent and cluster
    ):
        super().__init__()
        self.proj = PointSequential(nn.Linear(in_channels, out_channels))
        self.proj_skip = PointSequential(nn.Linear(skip_channels, out_channels))

        if norm_layer is not None:
            self.proj.add(norm_layer(out_channels))
            self.proj_skip.add(norm_layer(out_channels))

        if act_layer is not None:
            self.proj.add(act_layer())
            self.proj_skip.add(act_layer())

        self.traceable = traceable

    def forward(self, point):
        assert "pooling_parent" in point.keys() and "pooling_inverse" in point.keys()
        parent = point.pop("pooling_parent")
        inverse = point.pop("pooling_inverse")

        # ç²¾ç®€æ ¡éªŒ
        if torch.isnan(point.feat).any() or torch.isinf(parent.feat).any():
            logging.error(f"SerializedUnpoolingå¼‚å¸¸ï¼")

        point = self.proj(point)
        parent = self.proj_skip(parent)
        parent.feat = parent.feat + point.feat[inverse]

        if self.traceable:
            parent["unpooling_parent"] = point
        return parent


class Embedding(PointModule):
    def __init__(
        self,
        in_channels,
        embed_channels,
        norm_layer=None,
        act_layer=None,
    ):
        super().__init__()
        self.in_channels = in_channels
        self.embed_channels = embed_channels
        # TODO: check remove spconv
        self.stem = PointSequential(
            conv=spconv.SubMConv3d(
                in_channels,
                embed_channels,
                kernel_size=5,
                padding=1,
                bias=False,
                indice_key="stem",
            )
        )
        if norm_layer:
            self.stem.add(norm_layer(embed_channels), name="norm")
        if act_layer:
            self.stem.add(act_layer(), name="act")

    def forward(self, point: Point):
        if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
            logging.error(f"Embeddingè¾“å…¥å¼‚å¸¸ï¼æ ·æœ¬={point['path'][:1]}")

        # åµŒå…¥å±‚å¤„ç†ï¼ˆå¯èƒ½åˆ›å»ºæ–°Pointå¯¹è±¡ï¼‰
        point = self.stem(point)

        # ç²¾ç®€æ ¡éªŒ
        if torch.isnan(point.feat).any() or torch.isinf(point.feat).any():
            logging.error(f"Embeddingè¾“å‡ºå¼‚å¸¸ï¼æ ·æœ¬={point['path'][:1]}")

        return point


@MODELS.register_module('PT-v3m1')
class PointTransformerV3(PointModule):
    def __init__(
        self,
        num_classes=5,  # æ˜ç¡®ä¸º5åˆ†ç±»ï¼ˆ0-4ï¼‰
        in_channels=6,
        order=("z", "z-trans"),
        stride=(2, 2, 2),
        enc_depths=(1, 1, 3, 1),
        enc_channels=(32, 64, 128, 256),
        enc_num_head=(2, 4, 8, 16),
        enc_patch_size=(16, 16, 16, 16),  # ä¸k_neighbors=16ä¿æŒä¸€è‡´
        dec_depths=(1, 1, 1),
        dec_channels=(64, 64, 128),
        dec_num_head=(4, 4, 8),
        dec_patch_size=(16, 16, 16),   # ä¸k_neighbors=16ä¿æŒä¸€è‡´
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        drop_path=0.5,
        pre_norm=True,
        shuffle_orders=True,
        enable_rpe=False,
        enable_flash=False,  # ä¿®æ­£ï¼šç”¨æˆ·æœªå®‰è£…flash_attnï¼Œè®¾ä¸ºFalse
        upcast_attention=False,
        upcast_softmax=False,
        cls_mode=False,
        pdnorm_bn=False,
        pdnorm_ln=False,
        pdnorm_decouple=True,
        pdnorm_adaptive=False,
        pdnorm_affine=True,
        pdnorm_conditions=("ScanNet", "S3DIS", "Structured3D"),
    ):
        super().__init__()
        self.num_classes = num_classes  # ä¿å­˜ç±»åˆ«æ•°
        self.num_stages = len(enc_depths)
        self.order = [order] if isinstance(order, str) else order
        self.cls_mode = cls_mode
        self.shuffle_orders = shuffle_orders

        # æ ¡éªŒå‚æ•°é•¿åº¦ï¼ˆç¡®ä¿ç¼–ç å™¨/è§£ç å™¨å‚æ•°åŒ¹é…ï¼‰
        assert self.num_stages == len(stride) + 1
        assert self.num_stages == len(enc_depths) == len(enc_channels) == len(enc_num_head) == len(enc_patch_size)
        if not self.cls_mode:
            assert self.num_stages == len(dec_depths) + 1 == len(dec_channels) + 1 == len(dec_num_head) + 1 == len(
                dec_patch_size) + 1

        # å½’ä¸€åŒ–å±‚é…ç½®
        if pdnorm_bn:
            bn_layer = partial(
                PDNorm,
                norm_layer=partial(
                    nn.BatchNorm1d, eps=1e-3, momentum=0.01, affine=pdnorm_affine
                ),
                conditions=pdnorm_conditions,
                decouple=pdnorm_decouple,
                adaptive=pdnorm_adaptive,
            )
        else:
            bn_layer = partial(nn.BatchNorm1d, eps=1e-3, momentum=0.01)
        if pdnorm_ln:
            ln_layer = partial(
                PDNorm,
                norm_layer=partial(nn.LayerNorm, elementwise_affine=pdnorm_affine),
                conditions=pdnorm_conditions,
                decouple=pdnorm_decouple,
                adaptive=pdnorm_adaptive,
            )
        else:
            ln_layer = nn.LayerNorm
        # activation layers
        act_layer = nn.GELU

        # åµŒå…¥å±‚
        self.embedding = Embedding(
            in_channels=in_channels,
            embed_channels=enc_channels[0],
            norm_layer=bn_layer,
            act_layer=act_layer,
        )

        # ç¼–ç å™¨
        enc_drop_path = [
            x.item() for x in torch.linspace(0, drop_path, sum(enc_depths))
        ]
        self.enc = PointSequential()
        for s in range(self.num_stages):
            enc_drop_path_ = enc_drop_path[
                sum(enc_depths[:s]) : sum(enc_depths[: s + 1])
            ]
            enc = PointSequential()
            if s > 0:
                enc.add(
                    SerializedPooling(
                        in_channels=enc_channels[s - 1],
                        out_channels=enc_channels[s],
                        stride=stride[s - 1],
                        norm_layer=bn_layer,
                        act_layer=act_layer,
                    ),
                    name="down",
                )
            for i in range(enc_depths[s]):
                enc.add(
                    Block(
                        channels=enc_channels[s],
                        num_heads=enc_num_head[s],
                        patch_size=enc_patch_size[s],   # ä¼ é€’æ­£ç¡®çš„é‚»åŸŸç‚¹æ•°
                        mlp_ratio=mlp_ratio,
                        qkv_bias=qkv_bias,
                        qk_scale=qk_scale,
                        attn_drop=attn_drop,
                        proj_drop=proj_drop,
                        drop_path=enc_drop_path_[i],
                        norm_layer=ln_layer,
                        act_layer=act_layer,
                        pre_norm=pre_norm,
                        order_index=i % len(self.order),
                        cpe_indice_key=f"stage{s}",
                        enable_rpe=enable_rpe,
                        enable_flash=enable_flash,
                        upcast_attention=upcast_attention,
                        upcast_softmax=upcast_softmax,
                    ),
                    name=f"block{i}",
                )
            if len(enc) != 0:
                self.enc.add(module=enc, name=f"enc{s}")

        # è§£ç å™¨
        self.dec = None
        self.original_dec_channels = dec_channels  # ä¿å­˜åŸå§‹è§£ç å™¨é€šé“é…ç½®
        if not self.cls_mode:
            dec_drop_path = [
                x.item() for x in torch.linspace(0, drop_path, sum(dec_depths))
            ]
            self.dec = PointSequential()
            # æ³¨æ„ï¼šè¿™é‡Œæ‹¼æ¥äº†ç¼–ç å™¨æœ€åä¸€å±‚é€šé“ï¼Œä½†ä»…ç”¨äºè§£ç å™¨å†…éƒ¨è®¡ç®—
            dec_channels = list(dec_channels) + [enc_channels[-1]]
            for s in reversed(range(self.num_stages - 1)):
                dec_drop_path_ = dec_drop_path[
                    sum(dec_depths[:s]) : sum(dec_depths[: s + 1][::-1])
                ]
                dec = PointSequential()
                dec.add(
                    SerializedUnpooling(
                        in_channels=dec_channels[s + 1],
                        skip_channels=enc_channels[s],
                        out_channels=dec_channels[s],
                        norm_layer=bn_layer,
                        act_layer=act_layer,
                    ),
                    name="up",
                )
                for i in range(dec_depths[s]):
                    dec.add(
                        Block(
                            channels=dec_channels[s],
                            num_heads=dec_num_head[s],
                            patch_size=dec_patch_size[s],
                            mlp_ratio=mlp_ratio,
                            qkv_bias=qkv_bias,
                            qk_scale=qk_scale,
                            attn_drop=attn_drop,
                            proj_drop=proj_drop,
                            drop_path=dec_drop_path_[i],
                            norm_layer=ln_layer,
                            act_layer=act_layer,
                            pre_norm=pre_norm,
                            order_index=i % len(self.order),
                            cpe_indice_key=f"stage{s}",
                            enable_rpe=enable_rpe,
                            enable_flash=enable_flash,
                            upcast_attention=upcast_attention,
                            upcast_softmax=upcast_softmax,
                        ),
                        name=f"block{i}",
                    )
                self.dec.add(module=dec, name=f"dec{s}")

        # åˆ†ç±»å¤´ï¼ˆå¤šåˆ†ç±»ï¼Œ0-4å…±5ç±»ï¼‰
        '''
        if not self.cls_mode:
            self.head = nn.Linear(self.original_dec_channels[0], self.num_classes)  # è¾“å‡º5ä¸ªé€šé“ï¼ˆå¯¹åº”5ç±»ï¼‰
        else:
            self.head = nn.Linear(enc_channels[-1], self.num_classes)  # è¾“å‡º5ä¸ªé€šé“ï¼ˆå¯¹åº”5ç±»ï¼‰
        '''
        if not self.cls_mode:
            in_channels = self.original_dec_channels[0]
        else:
            in_channels = enc_channels[-1]
        self.head = nn.Sequential(
            nn.Linear(in_channels, 256),  # ç¬¬ä¸€å±‚çº¿æ€§å˜æ¢ï¼Œæ‹“å®½ç»´åº¦
            nn.ReLU(inplace=True),  # æ¿€æ´»å‡½æ•°ï¼Œå¢åŠ éçº¿æ€§è¡¨è¾¾
            nn.Dropout(0.3),  # éšæœºå¤±æ´»30%ç¥ç»å…ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            nn.Linear(256, self.num_classes)  # ç¬¬äºŒå±‚çº¿æ€§å˜æ¢ï¼Œè¾“å‡º5ç±»é¢„æµ‹
        )

    def forward(self, data_dict):
        #  é¦–å…ˆæ£€æŸ¥pathæ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
        #if 'path' not in data_dict or data_dict['path'][0] == 'æœªçŸ¥è·¯å¾„':
        #    raise ValueError(f"æ ·æœ¬pathä¸¢å¤±ï¼å½“å‰data_dictä¸­çš„path: {data_dict.get('path', 'æ— ')}")
        #  å…³é”®1ï¼šä¿ç•™æ ·æœ¬è·¯å¾„ï¼Œç”¨äºå¼‚å¸¸å®šä½
        sample_paths = data_dict.get('path', ['æœªçŸ¥è·¯å¾„'])
        #  å…³é”®2ï¼šè®¡ç®—å¹¶æ‰“å°spatial_shapeï¼ˆéªŒè¯é›†æ ¸å¿ƒè°ƒè¯•ä¿¡æ¯ï¼‰
        coord = data_dict['coord']
        spatial_shape = [
            int(coord[:, 2].max().item()) + 1,  # zè½´ï¼ˆspconvé»˜è®¤z/y/xé¡ºåºï¼Œå¿…é¡»å¯¹åº”ï¼‰
            int(coord[:, 1].max().item()) + 1,  # yè½´
            int(coord[:, 0].max().item()) + 1  # xè½´ï¼ˆæ³¨æ„ï¼šcoordæ˜¯[x,y,z]ï¼Œéœ€è°ƒæ•´é¡ºåºï¼‰
        ]
        # åŒºåˆ†è®­ç»ƒ/éªŒè¯æ¨¡å¼ï¼Œæ‰“å°spatial_shapeï¼ˆå…³é”®ï¼šéªŒè¯æ˜¯å¦è¿‡å¤§ï¼‰
        mode = "è®­ç»ƒé›†" if self.training else "éªŒè¯é›†"
        logging.info(
            f"ã€{mode}ã€‘æ ·æœ¬è·¯å¾„={[os.path.basename(p) for p in sample_paths[:2]]}, "
            f"æ€»ç‚¹æ•°={coord.shape[0]}, spatial_shape={spatial_shape}ï¼ˆz/y/xï¼‰"
        )
        # æ£€æŸ¥spatial_shapeæ˜¯å¦è¿‡å¤§ï¼ˆè¶…è¿‡2000è§†ä¸ºå¼‚å¸¸ï¼Œéœ€åç»­è£å‰ªcoordï¼‰
        #TODO
        '''
        if any(dim > 2000 for dim in spatial_shape):
            logging.warning(
                f"âš ï¸ {mode} spatial_shapeè¿‡å¤§ï¼å„ç»´åº¦åº”â‰¤2000ï¼Œå½“å‰={spatial_shape}ï¼Œå¯èƒ½å¯¼è‡´logits=nan"
            )
        '''
        # 1. æ„å»ºPointå¯¹è±¡ï¼ˆä¿ç•™pathå­—æ®µï¼‰
        data_dict['path'] = sample_paths  # ç¡®ä¿pathä¼ å…¥Pointå¯¹è±¡
        point = Point(data_dict)
        # 2. ä¿ç•™åºåˆ—åŒ–é€»è¾‘ï¼ˆåŸæœ‰ä»£ç ï¼Œå¤„ç†ç‚¹äº‘é¡ºåºï¼‰
        point.serialization(order=self.order, shuffle_orders=self.shuffle_orders)

        # ğŸŒŸ æ–°å¢ï¼šæå–æ’åºé‚»åŸŸç´¢å¼•ï¼ˆæ ¸å¿ƒä¿®æ”¹1ï¼‰
        # æ³¨æ„ï¼škå€¼éœ€ä¸æ¨¡å‹åŸké‚»åŸŸä¸€è‡´ï¼ˆå¦‚16ï¼‰ï¼Œé¿å…åç»­å±‚è¾“å…¥ç»´åº¦ä¸åŒ¹é…
        k_neighbors = 16  # å¯æ ¹æ®æ¨¡å‹å®é™…éœ€æ±‚è°ƒæ•´ï¼ˆå¿…é¡»ä¸ºå¶æ•°ï¼‰
        point.get_sorted_neighbors(k=k_neighbors)

        # ğŸŒŸ å…³é”®3ï¼šæ›¿æ¢point.sparsify()ï¼Œæ‰‹åŠ¨æ„å»ºSparseConvTensorï¼ˆå¸¦allow_empty=Trueï¼‰
        # 3.1 ç”Ÿæˆæ ·æœ¬ç´¢å¼•ï¼ˆbatch_idxï¼‰ï¼šæ¯ä¸ªç‚¹å±äºå“ªä¸ªæ ·æœ¬
        batch_size = len(point.offset) - 1  # offseté•¿åº¦=æ ·æœ¬æ•°+1ï¼Œå¦‚[0,1920,3840]å¯¹åº”2ä¸ªæ ·æœ¬
        batch_idx = []
        for i in range(batch_size):
            start = point.offset[i].item()  # ç¬¬iä¸ªæ ·æœ¬çš„èµ·å§‹ç‚¹ç´¢å¼•
            end = point.offset[i + 1].item()  # ç¬¬iä¸ªæ ·æœ¬çš„ç»“æŸç‚¹ç´¢å¼•
            batch_idx.extend([i] * (end - start))  # ä¸ºæ¯ä¸ªç‚¹åˆ†é…æ ·æœ¬ç´¢å¼•
        # è½¬æ¢ä¸ºå¼ é‡å¹¶è°ƒæ•´å½¢çŠ¶ï¼ˆ[N,1]ï¼ŒNä¸ºæ€»ç‚¹æ•°ï¼‰
        batch_idx = torch.tensor(batch_idx, device=point.coord.device, dtype=torch.int32).unsqueeze(1)

        # 3.2 æ„å»ºindicesï¼ˆspconvè¦æ±‚æ ¼å¼ï¼š[z, y, x, batch_idx]ï¼Œå…±4åˆ—ï¼‰
        # æ³¨æ„ï¼šcoordåŸå§‹æ ¼å¼æ˜¯[x,y,z]ï¼Œéœ€è°ƒæ•´ä¸º[z,y,x]
        z_coord = point.coord[:, 2].unsqueeze(1).to(torch.int32)  # ç¬¬3åˆ—æ˜¯z
        y_coord = point.coord[:, 1].unsqueeze(1).to(torch.int32)  # ç¬¬2åˆ—æ˜¯y
        x_coord = point.coord[:, 0].unsqueeze(1).to(torch.int32)  # ç¬¬1åˆ—æ˜¯x
        indices = torch.cat([z_coord, y_coord, x_coord, batch_idx], dim=1)  # æ‹¼æ¥ä¸º[N,4]

        # 3.3 æ‰‹åŠ¨åˆ›å»ºSparseConvTensorï¼Œæ˜¾å¼è®¾ç½®allow_empty=True
        # æ­¥éª¤1ï¼šå…ˆåˆ›å»ºç©ºçš„SparseConvTensorï¼ˆç”¨é»˜è®¤å‚æ•°ï¼‰
        sparse_tensor = spconv.SparseConvTensor(
            features=point.feat,  # ç‚¹äº‘ç‰¹å¾ï¼ˆ[N, C]ï¼‰
            indices=indices,  # åæ ‡+æ ·æœ¬ç´¢å¼•ï¼ˆ[N,4]ï¼‰
            spatial_shape=spatial_shape,  # ä½“ç´ ç½‘æ ¼å¤§å°ï¼ˆz/y/xï¼‰
            batch_size=batch_size,  # æ‰¹æ¬¡å¤§å°
        )
        # æ­¥éª¤2ï¼šæ‰‹åŠ¨è®¾ç½®allow_empty=Trueï¼ˆç»•è¿‡fxå¯¹__init__çš„è¿½è¸ªï¼‰
        sparse_tensor.allow_empty = True  # ç›´æ¥ä¿®æ”¹å±æ€§ï¼Œè€Œéé€šè¿‡__init__å‚æ•°

        # èµ‹å€¼ç»™point.sparse_conv_feat
        point.sparse_conv_feat = sparse_tensor

        # 4.åµŒå…¥å±‚
        point = self.embedding(point)

        # 5. ç¼–ç å™¨ï¼ˆæ— éœ€é‡æ–°ç”Ÿæˆé‚»åŸŸï¼‰
        point = self.enc(point)

        # 6.è§£ç å™¨ï¼ˆåˆ†å‰²æ¨¡å¼ï¼‰
        if not self.cls_mode and self.dec is not None:
            point = self.dec(point)

        # 7.åˆ†ç±»å¤´è®¡ç®—logitsä¸æ•°å€¼æ ¡éªŒ
        logits = self.head(point.feat)
        if torch.isnan(logits).any() or torch.isinf(logits).any():
            logging.error(f"ã€{mode}ã€‘logitså¼‚å¸¸ï¼æ ·æœ¬={sample_paths[:1]}")
        else:
            logging.info(f"ã€{mode}ã€‘logitsæ­£å¸¸ï¼å½¢çŠ¶={logits.shape}")

        return logits  # è¿”å›å¯¹è±¡ï¼Œè€Œéå¼ é‡
