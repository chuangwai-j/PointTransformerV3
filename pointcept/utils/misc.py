#pointcept/utils/misc.py
"""
Misc

Author: Xiaoyang Wu (xiaoyang.wu.cs@gmail.com)
Please cite our work if the code is helpful to you.
"""
import logging
import os
import warnings
from collections import abc
import numpy as np
import torch
from importlib import import_module


class AverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


def intersection_and_union(output, target, K, ignore_index=-1):
    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.
    assert output.ndim in [1, 2, 3]
    assert output.shape == target.shape
    output = output.reshape(output.size).copy()
    target = target.reshape(target.size)
    output[np.where(target == ignore_index)[0]] = ignore_index
    intersection = output[np.where(output == target)[0]]
    area_intersection, _ = np.histogram(intersection, bins=np.arange(K + 1))
    area_output, _ = np.histogram(output, bins=np.arange(K + 1))
    area_target, _ = np.histogram(target, bins=np.arange(K + 1))
    area_union = area_output + area_target - area_intersection
    return area_intersection, area_union, area_target


def intersection_and_union_gpu(output, target, k, ignore_index=-1):
    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.
    assert output.dim() in [1, 2, 3]
    assert output.shape == target.shape
    output = output.view(-1)
    target = target.view(-1)
    output[target == ignore_index] = ignore_index
    intersection = output[output == target]
    area_intersection = torch.histc(intersection, bins=k, min=0, max=k - 1)
    area_output = torch.histc(output, bins=k, min=0, max=k - 1)
    area_target = torch.histc(target, bins=k, min=0, max=k - 1)
    area_union = area_output + area_target - area_intersection
    return area_intersection, area_union, area_target


def make_dirs(dir_name):
    if not os.path.exists(dir_name):
        os.makedirs(dir_name, exist_ok=True)


def find_free_port():
    import socket

    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    # Binding to port 0 will cause the OS to find an available port for us
    sock.bind(("", 0))
    port = sock.getsockname()[1]
    sock.close()
    # NOTE: there is still a chance the port could be taken by other processes.
    return port


def is_seq_of(seq, expected_type, seq_type=None):
    """Check whether it is a sequence of some type.

    Args:
        seq (Sequence): The sequence to be checked.
        expected_type (type): Expected type of sequence items.
        seq_type (type, optional): Expected sequence type.

    Returns:
        bool: Whether the sequence is valid.
    """
    if seq_type is None:
        exp_seq_type = abc.Sequence
    else:
        assert isinstance(seq_type, type)
        exp_seq_type = seq_type
    if not isinstance(seq, exp_seq_type):
        return False
    for item in seq:
        if not isinstance(item, expected_type):
            return False
    return True


def is_str(x):
    """Whether the input is an string instance.

    Note: This method is deprecated since python 2 is no longer supported.
    """
    return isinstance(x, str)


def import_modules_from_strings(imports, allow_failed_imports=False):
    """Import modules from the given list of strings.

    Args:
        imports (list | str | None): The given module names to be imported.
        allow_failed_imports (bool): If True, the failed imports will return
            None. Otherwise, an ImportError is raise. Default: False.

    Returns:
        list[module] | module | None: The imported modules.

    Examples:
        >>> osp, sys = import_modules_from_strings(
        ...     ['os.path', 'sys'])
        >>> import os.path as osp_
        >>> import sys as sys_
        >>> assert osp == osp_
        >>> assert sys == sys_
    """
    if not imports:
        return
    single_import = False
    if isinstance(imports, str):
        single_import = True
        imports = [imports]
    if not isinstance(imports, list):
        raise TypeError(f"custom_imports must be a list but got type {type(imports)}")
    imported = []
    for imp in imports:
        if not isinstance(imp, str):
            raise TypeError(f"{imp} is of type {type(imp)} and cannot be imported.")
        try:
            imported_tmp = import_module(imp)
        except ImportError:
            if allow_failed_imports:
                warnings.warn(f"{imp} failed to import and is ignored.", UserWarning)
                imported_tmp = None
            else:
                raise ImportError
        imported.append(imported_tmp)
    if single_import:
        imported = imported[0]
    return imported


'''def collate_fn(batch):
    """
    èåˆç‰ˆæ‰¹å¤„ç†å‡½æ•°ï¼š
    1. ä¿ç•™åŸå‡½æ•°å¯¹grid_sizeç­‰ç‰¹æ®Šå­—æ®µçš„å¤„ç†
    2. åŠ å…¥beamazçš„ç»´åº¦æ ¡éªŒï¼Œç¡®ä¿ä¸coordä¸¥æ ¼åŒæ­¥
    """
    if not batch:
        return {}

    if not isinstance(batch[0], dict):
        return torch.utils.data.dataloader.default_collate(batch)

    result = {}
    offsets = [0]
    # å…ˆè®¡ç®—offsetå¹¶æ”¶é›†beamazç”¨äºæ ¡éªŒ
    beamaz_list = []
    for item in batch:
        num_points = len(item['coord']) if 'coord' in item else 0
        offsets.append(offsets[-1] + num_points)

        # ğŸŒŸ å•æ ·æœ¬å†…beamazä¸coordç»´åº¦æ ¡éªŒ
        if 'beamaz' in item:
            assert len(item['beamaz']) == num_points, \
                f"æ ·æœ¬{item.get('path', 'æœªçŸ¥')}ä¸­beamazé•¿åº¦({len(item['beamaz'])})ä¸coordç‚¹æ•°({num_points})ä¸ä¸€è‡´"
            beamaz_list.append(item['beamaz'])

    result['offset'] = torch.tensor(offsets, dtype=torch.int64)

    # å¤„ç†å…¶ä»–å­—æ®µ
    for key in batch[0].keys():
        if key == 'offset':
            continue

        values = [item[key] for item in batch]

        # ä¿ç•™grid_sizeçš„ç‰¹æ®Šå¤„ç†ï¼ˆåŸå‡½æ•°åŠŸèƒ½ï¼‰
        if key == 'grid_size':
            result[key] = values[0].clone().detach().float() if isinstance(values[0], torch.Tensor) \
                else torch.tensor(values[0], dtype=torch.float32)
            continue

        # å¤„ç†å¼ é‡/æ•°ç»„ç±»å‹
        if isinstance(values[0], torch.Tensor):
            result[key] = torch.cat(values, dim=0)
        elif hasattr(values[0], '__array__'):
            if key in ['coord', 'feat', 'beamaz']:
                result[key] = torch.cat([torch.from_numpy(v).float() for v in values], dim=0)
            elif key == 'label':
                result[key] = torch.cat([torch.from_numpy(v).long() for v in values], dim=0)
            else:
                result[key] = values
                print(f"Warning: Could not concatenate {key}, keeping as list")
        else:
            result[key] = values

    # ğŸŒŸ æ‰¹æ¬¡çº§beamazä¸coordç»´åº¦æ ¡éªŒ
    if 'beamaz' in result:
        assert len(result['beamaz']) == len(result['coord']), \
            f"æ‰¹æ¬¡å†…beamazæ€»é•¿åº¦({len(result['beamaz'])})ä¸coordæ€»é•¿åº¦({len(result['coord'])})ä¸ä¸€è‡´"


    return result
'''


def collate_fn(batch):
    """
    é€‚é…é£åˆ‡å˜æ•°æ®çš„æ‰¹å¤„ç†å‡½æ•°ï¼š
    1. è¿‡æ»¤ç©ºæ ·æœ¬ï¼Œé¿å…ç‚¹æ•°â‰¤0ï¼›2. æ ¡éªŒè¡¥ç‚¹é€»è¾‘ï¼ˆç‚¹æ•°ä¸º384çš„å€æ•°ï¼‰ï¼›
    3. æ­£ç¡®åŒºåˆ†å­—æ®µç»´åº¦ï¼ˆcoord/featä¸º2ç»´ï¼Œlabel/beamazä¸º1ç»´ï¼‰ï¼›4. ç¡®ä¿offsetä¸¥æ ¼é€’å¢
    """

    # -------------------------- æ–°å¢ï¼šç¬¬ä¸€æ­¥è¿‡æ»¤Noneæ ·æœ¬ --------------------------
    # å…ˆç§»é™¤__getitem__è¿”å›çš„Noneï¼ˆé‡‡æ ·ç‚¹æ•°ä¸è¶³çš„æ ·æœ¬ï¼‰
    batch = [item for item in batch if item is not None]
    if not batch:
        warnings.warn("å½“å‰batchæ‰€æœ‰æ ·æœ¬å‡ä¸ºæ— æ•ˆï¼ˆç‚¹æ•°ä¸è¶³ï¼‰ï¼Œè¿”å›ç©ºbatchï¼Œéœ€åœ¨è®­ç»ƒå¾ªç¯ä¸­è·³è¿‡")
        return None  # è¿”å›ç©ºï¼Œè®­ç»ƒå¾ªç¯ä¸­å¤„ç†
    # --------------------------------------------------------------------------

    # 1. è¿‡æ»¤æ— æ•ˆ/ç©ºæ ·æœ¬
    valid_batch = []
    for idx, item in enumerate(batch):
        if not isinstance(item, dict) or 'coord' not in item:
            warnings.warn(f"è¿‡æ»¤æ— æ•ˆæ ·æœ¬{idx}ï¼šédictæˆ–ç¼ºå¤±coordå­—æ®µ", UserWarning)
            continue
        # ç»Ÿä¸€ç‚¹æ•°è®¡ç®—é€»è¾‘ï¼ˆé€‚é…Tensor/numpyæ•°ç»„ï¼‰
        num_points = item['coord'].shape[0] if isinstance(item['coord'], torch.Tensor) else len(item['coord'])
        if num_points <= 0:
            warnings.warn(f"è¿‡æ»¤ç©ºæ ·æœ¬{idx}ï¼šç‚¹æ•°={num_points}", UserWarning)
            continue
        valid_batch.append(item)
    if not valid_batch:
        raise ValueError("å½“å‰batchæ— æœ‰æ•ˆæ ·æœ¬ï¼è¯·æ£€æŸ¥æ•°æ®é¢„å¤„ç†/è¡¥ç‚¹æµç¨‹")

    # 2. åˆå§‹åŒ–å˜é‡ï¼Œæ ¡éªŒå•æ ·æœ¬åˆæ³•æ€§
    result = {}
    offsets = [0]
    total_points = 0
    sample_sizes = []
    device = valid_batch[0]['coord'].device if isinstance(valid_batch[0]['coord'], torch.Tensor) else torch.device(
        'cpu')

    for idx, item in enumerate(valid_batch):
        # 2.1 æ ¡éªŒç‚¹æ•°æ˜¯å¦ä¸º384çš„å€æ•°ï¼ˆé€‚é…è¡¥ç‚¹é€»è¾‘ï¼‰
        num_points = item['coord'].shape[0] if isinstance(item['coord'], torch.Tensor) else len(item['coord'])
        if num_points % 384 != 0:
            raise ValueError(
                f"æ ·æœ¬{idx}ç‚¹æ•°å¼‚å¸¸ï¼š{num_points}ï¼ˆéœ€ä¸º384çš„å€æ•°ï¼Œå¦‚1536/1920ï¼‰\n"
                "è¯·æ£€æŸ¥è¡¥ç‚¹ä»£ç æ˜¯å¦æ­£å¸¸æ‰§è¡Œ"
            )
        sample_sizes.append(num_points)
        total_points += num_points
        offsets.append(total_points)

        # 2.2 ç»Ÿä¸€å­—æ®µç±»å‹+ç»´åº¦æ ¡éªŒï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šåŒºåˆ†å­—æ®µç»´åº¦è¦æ±‚ï¼‰
        for key in ['coord', 'feat', 'label', 'beamaz', 'grid_size']:
            if key not in item:
                raise KeyError(f"æ ·æœ¬{idx}ç¼ºå¤±å¿…è¦å­—æ®µï¼š{key}")

            # numpyè½¬Tensorï¼Œç»Ÿä¸€ç±»å‹
            if isinstance(item[key], np.ndarray):
                if key == 'label':
                    dtype = torch.long
                elif key in ['coord', 'feat', 'beamaz', 'grid_size']:
                    dtype = torch.float32
                else:
                    dtype = torch.float32
                item[key] = torch.from_numpy(item[key]).to(dtype).to(device)
            elif not isinstance(item[key], torch.Tensor):
                raise TypeError(f"æ ·æœ¬{idx}çš„{key}ç±»å‹å¼‚å¸¸ï¼šéœ€Tensor/numpyæ•°ç»„")

            # -------------------------- æ ¸å¿ƒä¿®æ”¹ï¼šç»´åº¦æ ¡éªŒé€»è¾‘ --------------------------
            if key == 'coord':
                # coordï¼š2ç»´ (N, 3)ï¼ŒN=ç‚¹æ•°ï¼Œ3=x/y/z
                if item[key].dim() != 2 or item[key].shape[0] != num_points or item[key].shape[1] != 3:
                    raise ValueError(
                        f"æ ·æœ¬{idx}çš„coordå¼‚å¸¸ï¼šç»´åº¦={item[key].dim()}ï¼Œå½¢çŠ¶={item[key].shape}\n"
                        f"éœ€ä¸º2ç»´å¼ é‡ (ç‚¹æ•°, 3)ï¼Œå½“å‰ç‚¹æ•°={num_points}ï¼Œåº”æ»¡è¶³å½¢çŠ¶=({num_points}, 3)"
                    )
            elif key == 'feat':
                # featï¼š2ç»´ (N, C)ï¼ŒN=ç‚¹æ•°ï¼ŒC=ç‰¹å¾ç»´åº¦ï¼ˆå¦‚9ï¼‰
                if item[key].dim() != 2 or item[key].shape[0] != num_points:
                    raise ValueError(
                        f"æ ·æœ¬{idx}çš„featå¼‚å¸¸ï¼šç»´åº¦={item[key].dim()}ï¼Œå½¢çŠ¶={item[key].shape}\n"
                        f"éœ€ä¸º2ç»´å¼ é‡ (ç‚¹æ•°, ç‰¹å¾ç»´åº¦)ï¼Œå½“å‰ç‚¹æ•°={num_points}ï¼Œåº”æ»¡è¶³å½¢çŠ¶=({num_points}, C)ï¼ˆå¦‚C=9ï¼‰"
                    )
            elif key in ['label', 'beamaz']:
                # label/beamazï¼š1ç»´ (N,)ï¼ŒN=ç‚¹æ•°
                if item[key].dim() != 1 or item[key].shape[0] != num_points:
                    raise ValueError(
                        f"æ ·æœ¬{idx}çš„{key}å¼‚å¸¸ï¼šç»´åº¦={item[key].dim()}ï¼Œå½¢çŠ¶={item[key].shape}\n"
                        f"éœ€ä¸º1ç»´å¼ é‡ (ç‚¹æ•°,)ï¼Œå½“å‰ç‚¹æ•°={num_points}ï¼Œåº”æ»¡è¶³å½¢çŠ¶=({num_points},)"
                    )
            elif key == 'grid_size':
                # grid_sizeï¼š1ç»´ (3,)ï¼Œ3=x/y/zç½‘æ ¼å¤§å°
                if item[key].dim() != 1 or item[key].shape[0] != 3:
                    raise ValueError(f"æ ·æœ¬{idx}çš„grid_sizeå¼‚å¸¸ï¼šéœ€1ç»´å¼ é‡ (3,)ï¼Œå®é™…å½¢çŠ¶={item[key].shape}")
            # --------------------------------------------------------------------------

    # 3. ç”Ÿæˆoffsetå¹¶æ ¡éªŒ
    result['offset'] = torch.tensor(offsets, dtype=torch.int64, device=device)
    if not (torch.diff(result['offset']) > 0).all():
        raise ValueError(f"offsetç”Ÿæˆå¼‚å¸¸ï¼ˆéœ€ä¸¥æ ¼é€’å¢ï¼‰ï¼š{result['offset'].tolist()}")
    if result['offset'][-1] != total_points:
        raise ValueError(
            f"offsetæ€»ç‚¹æ•°ä¸åŒ¹é…ï¼šoffset[-1]={result['offset'][-1]}ï¼Œå®é™…æ€»ç‚¹æ•°={total_points}"
        )

    # 4. æ‹¼æ¥ç‚¹çº§å­—æ®µï¼ˆæ­£ç¡®å¤„ç†2ç»´/1ç»´å¼ é‡ï¼‰
    # coord/featï¼š2ç»´ (N_total, 3) / (N_total, C)ï¼ŒæŒ‰dim=0æ‹¼æ¥
    result['coord'] = torch.cat([item['coord'] for item in valid_batch], dim=0)
    result['feat'] = torch.cat([item['feat'] for item in valid_batch], dim=0)
    # label/beamazï¼š1ç»´ (N_total,)ï¼ŒæŒ‰dim=0æ‹¼æ¥
    result['label'] = torch.cat([item['label'] for item in valid_batch], dim=0)
    result['beamaz'] = torch.cat([item['beamaz'] for item in valid_batch], dim=0)

    # 5. æ ¡éªŒæ‹¼æ¥åç»´åº¦
    assert result['coord'].shape == (total_points, 3), f"coordæ‹¼æ¥å¼‚å¸¸ï¼š{result['coord'].shape} != ({total_points}, 3)"
    assert result['feat'].shape[0] == total_points, f"featæ‹¼æ¥å¼‚å¸¸ï¼š{result['feat'].shape[0]} != {total_points}"
    assert result['label'].shape == (total_points,), f"labelæ‹¼æ¥å¼‚å¸¸ï¼š{result['label'].shape} != ({total_points},)"
    assert result['beamaz'].shape == (total_points,), f"beamazæ‹¼æ¥å¼‚å¸¸ï¼š{result['beamaz'].shape} != ({total_points},)"

    # 6. å¤„ç†grid_sizeï¼ˆæ”¯æŒåŒ/ä¸åŒæ ·æœ¬åœºæ™¯ï¼‰
    # 6. å¤„ç†grid_sizeï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šå¼ºåˆ¶è½¬ä¸ºå¼ é‡ï¼Œé¿å…åˆ—è¡¨ç±»å‹ï¼‰
    grid_sizes = [item['grid_size'] for item in valid_batch]
    # æ–¹æ¡ˆï¼šæ— è®ºæ ·æœ¬é—´æ˜¯å¦ä¸€è‡´ï¼Œå‡å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„grid_sizeï¼ˆç¡®ä¿ä¸ºå¼ é‡ç±»å‹ï¼Œé€‚é…Pointå¯¹è±¡ï¼‰
    # ç†ç”±ï¼šgrid_sizeæ˜¯é¢„å¤„ç†çš„ç½‘æ ¼å‚æ•°ï¼Œå•batchå†…å·®å¼‚å¯¹æ¨¡å‹å½±å“æå°ï¼Œä¼˜å…ˆä¿è¯å­—æ®µæœ‰æ•ˆæ€§
    result['grid_size'] = grid_sizes[0].clone().detach().float()
    # ç§»é™¤ä¹‹å‰çš„â€œåˆ—è¡¨ä¿ç•™é€»è¾‘â€ï¼Œé¿å…grid_sizeä¸ºåˆ—è¡¨
    # ï¼ˆå¯é€‰ï¼‰æ‰“å°è­¦å‘Šï¼Œæç¤ºæ ·æœ¬é—´grid_sizeå·®å¼‚
    if not all(torch.equal(gs, result['grid_size']) for gs in grid_sizes):
        logging.debug(
            f"å½“å‰batchæ ·æœ¬grid_sizeä¸ä¸€è‡´ï¼ˆå·²å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„{result['grid_size']}ä½œä¸ºç»Ÿä¸€å€¼ï¼‰\n"
            f"å„æ ·æœ¬grid_sizeï¼š{[gs.tolist() for gs in grid_sizes]}"
        )

    # 7. ä¿ç•™pathå­—æ®µï¼ˆå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
    if 'path' in valid_batch[0]:
        result['path'] = [item['path'] for item in valid_batch]

    # 8. è°ƒè¯•æ—¥å¿—
    logging.info(f"âœ… Batchç”ŸæˆæˆåŠŸï¼šæ ·æœ¬æ•°={len(valid_batch)}ï¼Œæ€»ç‚¹æ•°={total_points}")
    logging.info(f"   å„æ ·æœ¬ç‚¹æ•°ï¼š{sample_sizes}ï¼ˆå‡ä¸º384çš„å€æ•°ï¼‰")
    logging.info(f"   æ‹¼æ¥åç»´åº¦ï¼šcoord={result['coord'].shape}ï¼Œfeat={result['feat'].shape}ï¼Œlabel={result['label'].shape}")
    logging.info(f"   Offsetï¼š{result['offset'].tolist()}")

    return result


'''
def offset2bincount(offset):
    """
    å°†offsetè½¬æ¢ä¸ºâ€œæ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°â€ï¼ˆæ¨¡å‹å¯èƒ½éœ€è¦ç”¨è¿™ä¸ªè®¡ç®—å•æ ·æœ¬æŸå¤±ï¼‰
    ä¾‹ï¼šoffset=[0,2603,8235] â†’ bincount=[2603, 5632]
    """
    if len(offset) < 2:
        return torch.tensor([0], dtype=torch.int64)
    # è®¡ç®—ç›¸é‚»offsetçš„å·®å€¼ï¼Œå³æ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°
    bincount = offset[1:] - offset[:-1]
    return bincount
'''

def offset2bincount(offset, check_padding=True):
    """
    ä»offsetè®¡ç®—æ ·æœ¬ç‚¹æ•°ï¼ˆå¢å¼ºé²æ£’æ€§ï¼‰ï¼š
    - æ ¡éªŒoffsetåˆæ³•æ€§ï¼›- ç¡®ä¿æ— ç‚¹æ•°â‰¤0çš„æ ·æœ¬ï¼›- å¯é€‰æ ¡éªŒè¡¥ç‚¹é€»è¾‘ï¼ˆä»…å¯¹åŸå§‹æ ·æœ¬ï¼‰
    å‚æ•°:
        check_padding: æ˜¯å¦æ ¡éªŒè¡¥ç‚¹é€»è¾‘ï¼ˆåŸå§‹æ ·æœ¬è®¾ä¸ºTrueï¼Œä¸‹é‡‡æ ·åä¸­é—´æ ·æœ¬è®¾ä¸ºFalseï¼‰
    """
    # 1. åŸºç¡€ç±»å‹/ç»´åº¦æ ¡éªŒ
    if not isinstance(offset, torch.Tensor):
        raise TypeError(f"offsetå¿…é¡»ä¸ºtorch.Tensorï¼Œå®é™…ç±»å‹ï¼š{type(offset)}")
    if offset.dim() != 1:
        raise ValueError(f"offsetå¿…é¡»ä¸º1ç»´å¼ é‡ï¼Œå®é™…ç»´åº¦ï¼š{offset.dim()}")
    if offset.shape[0] < 2:
        raise ValueError(f"offseté•¿åº¦å¿…é¡»â‰¥2ï¼ˆå¦‚[0, 1536]ï¼‰ï¼Œå®é™…é•¿åº¦ï¼š{offset.shape[0]}")

    # 2. è®¡ç®—æ ·æœ¬ç‚¹æ•°ï¼Œæ ¡éªŒæœ‰æ•ˆæ€§ï¼ˆæ ¸å¿ƒå¿…è¦æ ¡éªŒï¼Œä»»ä½•é˜¶æ®µéƒ½éœ€é€šè¿‡ï¼‰
    bincount = offset[1:] - offset[:-1]
    # å®šä½ç‚¹æ•°â‰¤0çš„æ ·æœ¬ï¼ˆä»»ä½•æƒ…å†µä¸‹éƒ½ä¸å…è®¸ï¼‰
    invalid_mask = bincount <= 0
    if invalid_mask.any():
        invalid_indices = torch.where(invalid_mask)[0].tolist()
        invalid_values = bincount[invalid_mask].tolist()
        raise ValueError(
            f"å­˜åœ¨ç‚¹æ•°â‰¤0çš„æ ·æœ¬ï¼šç´¢å¼•={invalid_indices}ï¼Œç‚¹æ•°={invalid_values}\n"
            f"å®Œæ•´offsetï¼š{offset.tolist()}ï¼Œå®Œæ•´æ ·æœ¬ç‚¹æ•°ï¼š{bincount.tolist()}"
        )

    # 3. å¯é€‰ï¼šæ ¡éªŒè¡¥ç‚¹é€»è¾‘ï¼ˆä»…å¯¹åŸå§‹è¾“å…¥æ ·æœ¬ç”Ÿæ•ˆï¼Œä¸‹é‡‡æ ·åæ ·æœ¬è·³è¿‡ï¼‰
    if check_padding:
        # åŸå§‹æ ·æœ¬å¿…é¡»æ»¡è¶³â‰¥1536ï¼ˆè¡¥ç‚¹åçš„æœ€å°è¦æ±‚ï¼‰
        small_mask = bincount < 1536
        if small_mask.any():
            small_indices = torch.where(small_mask)[0].tolist()
            small_values = bincount[small_mask].tolist()
            raise ValueError(
                f"åŸå§‹æ ·æœ¬ç‚¹æ•°è¿‡å°ï¼šç´¢å¼•={small_indices}ï¼Œç‚¹æ•°={small_values}\n"
                "è¡¥ç‚¹åæœ€å°ç‚¹æ•°åº”ä¸º1536ï¼ˆ384Ã—4ï¼‰ï¼Œè¯·æ£€æŸ¥è¡¥ç‚¹æµç¨‹"
            )
        # åŸå§‹æ ·æœ¬å¿…é¡»ä¸º384çš„å€æ•°ï¼ˆè¡¥ç‚¹é€»è¾‘è¦æ±‚ï¼‰
        if (bincount % 384 != 0).any():
            wrong_indices = torch.where(bincount % 384 != 0)[0].tolist()
            wrong_values = bincount[wrong_indices].tolist()
            raise ValueError(
                f"åŸå§‹æ ·æœ¬ç‚¹æ•°é384çš„å€æ•°ï¼šç´¢å¼•={wrong_indices}ï¼Œç‚¹æ•°={wrong_values}\n"
                "éœ€ä¸è¡¥ç‚¹é€»è¾‘ï¼ˆ384å€æ•°ï¼‰ä¿æŒä¸€è‡´"
            )
    else:
        # ä¸‹é‡‡æ ·åæ ·æœ¬çš„æ—¥å¿—æç¤ºï¼ˆéæŠ¥é”™ï¼‰
        min_points = bincount.min().item()
        if min_points < 384:
            logging.debug(f"[æ³¨æ„] ä¸‹é‡‡æ ·åæ ·æœ¬æœ€å°ç‚¹æ•°ä¸º{min_points}ï¼ˆå°äº384ï¼‰ï¼Œoffset={offset.tolist()}")

    # 4. ç¡®ä¿ä¸offsetåŒè®¾å¤‡
    return bincount.to(offset.device)



class DummyClass:
    def __init__(self):
        pass
