import os
import glob
import numpy as np
import pandas as pd
from tqdm import tqdm
import logging

# --- 1. é…ç½®æ‚¨çš„è·¯å¾„å’Œå‚æ•° ---

# æ‚¨çš„æ•°æ®æ ¹ç›®å½•
DATA_ROOT = "/mnt/d/model/wind_datas/csv_labels"

# è®­ç»ƒé›†å¯¹åº”çš„æ—¥æœŸæ–‡ä»¶å¤¹
# (ä¸ WindShearDataset.__init__ ä¸­çš„ 'train' split ä¿æŒä¸€è‡´)
TRAIN_DATES = [f"202303{i:02d}" for i in range(1, 23)]

# éœ€è¦è¿‡æ»¤çš„ä½ç‚¹æ•°æ ·æœ¬çš„å®Œæ•´è·¯å¾„
# (ä»æ‚¨çš„ yaml é…ç½®æ–‡ä»¶ä¸­å¤åˆ¶)
FILTER_PATHS_LIST = [
    "/mnt/d/model/wind_datas/csv_labels/20230310/datas4/period107_labeled.csv",
    "/mnt/d/model/wind_datas/csv_labels/20230319/datas1/nn217_labeled.csv",
    "/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa217_labeled.csv",
    "/mnt/d/model/wind_datas/csv_labels/20230317/datas1/gg1_labeled.csv",
    "/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i1_labeled.csv",
    "/mnt/d/model/wind_datas/csv_labels/20230310/datas1/period110_labeled.csv"
]
# è½¬æ¢ä¸º Set ç»“æ„ä»¥åŠ å¿«æŸ¥æ‰¾é€Ÿåº¦
FILTER_PATHS_SET = set(FILTER_PATHS_LIST)

# --- ğŸŒŸ ä¿®æ”¹1ï¼šæ·»åŠ æœ€å°é«˜åº¦é™åˆ¶ ---
MAX_HEIGHT = 1000.0
MIN_HEIGHT = 0.0  # å‡è®¾åœ°é¢ä¸º 0 ç±³

# --- 2. è¾…åŠ©å‡½æ•°ï¼Œç”¨äºå®‰å…¨è¯»å–åˆ— ---

def get_columns(df, columns):
    """
    å°è¯•è¯»å–åˆ—ï¼Œå…¼å®¹å¸¦ç©ºæ ¼å’Œä¸å¸¦ç©ºæ ¼çš„åˆ—å
    """
    data = {}
    for col in columns:
        try:
            data[col] = df[col].values
        except KeyError:
            try:
                data[col] = df[" " + col].values
            except Exception as e:
                logging.error(f"æ— æ³•è¯»å–åˆ— {col} æˆ– ' {col}'. é”™è¯¯: {e}")
                raise e
    return data

# --- 3. ä¸»è®¡ç®—é€»è¾‘ ---

def recalculate_stats_corrected():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    data_list = []
    logging.info("å¼€å§‹æœå¯»è®­ç»ƒé›†æ–‡ä»¶...")
    for date in TRAIN_DATES:
        date_path = os.path.join(DATA_ROOT, date)
        if not os.path.exists(date_path):
            continue
        datas_dirs = glob.glob(os.path.join(date_path, "datas*"))
        for datas_dir in datas_dirs:
            csv_files = glob.glob(os.path.join(datas_dir, "*_labeled.csv"))
            data_list.extend(csv_files)

    logging.info(f"å…±æ‰¾åˆ° {len(data_list)} ä¸ªè®­ç»ƒé›†æ–‡ä»¶ã€‚")

    all_u = []
    all_v = []
    all_beamaz = []

    pbar = tqdm(data_list, desc="å¤„ç†æ–‡ä»¶")
    for csv_path in pbar:
        # 2.1 è¿‡æ»¤ä½ç‚¹æ•°æ ·æœ¬
        if csv_path in FILTER_PATHS_SET:
            logging.debug(f"è·³è¿‡ä½ç‚¹æ•°æ ·æœ¬: {csv_path}")
            continue

        try:
            # 2.2 è¯»å–æ•°æ® (ç¡®ä¿è¯»å–æ‰€æœ‰ç›¸å…³åˆ—ï¼ŒåŒ…æ‹¬å¸¦ç©ºæ ¼çš„)
            data = pd.read_csv(csv_path, usecols=['x', 'y', 'z', 'u', 'v', 'BeamAz'])
            if data.empty:
                logging.warning(f"æ–‡ä»¶ä¸ºç©º: {csv_path}")
                continue

            # 2.3 æå–æ‰€éœ€åˆ—
            cols = get_columns(data, ['x', 'y', 'z', 'u', 'v', 'BeamAz'])

            # 2.4 ğŸŒŸ ä¿®æ”¹2ï¼šåº”ç”¨é«˜åº¦è¿‡æ»¤ (0 <= z <= 1000)
            height_mask = (cols['z'] <= MAX_HEIGHT) & (cols['z'] >= MIN_HEIGHT)

            # 2.5 è¿‡æ»¤åæ•°æ®
            u_filtered = cols['u'][height_mask]
            v_filtered = cols['v'][height_mask]
            beamaz_filtered = cols['BeamAz'][height_mask]

            if len(u_filtered) == 0:
                # logging.warning(f"æ–‡ä»¶ {csv_path} åœ¨ {MIN_HEIGHT}m <= z <= {MAX_HEIGHT}m è¿‡æ»¤åæ— æ•°æ®ã€‚")
                continue

            # 2.6 æ¸…æ´— NaN/Inf (åŒ __getitem__)
            valid_mask_u = ~ (np.isnan(u_filtered) | np.isinf(u_filtered))
            valid_mask_v = ~ (np.isnan(v_filtered) | np.isinf(v_filtered))
            valid_mask_beamaz = ~ (np.isnan(beamaz_filtered) | np.isinf(beamaz_filtered))

            valid_mask_all = valid_mask_u & valid_mask_v & valid_mask_beamaz

            all_u.append(u_filtered[valid_mask_all])
            all_v.append(v_filtered[valid_mask_all])
            all_beamaz.append(beamaz_filtered[valid_mask_all])

        except Exception as e:
            logging.error(f"å¤„ç†æ–‡ä»¶ {csv_path} å¤±è´¥: {e}", exc_info=True)

    logging.info("æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼Œå¼€å§‹åˆå¹¶æ•°æ®...")

    # 3. åˆå¹¶å¹¶è®¡ç®—ç»Ÿè®¡æ•°æ®
    # ä½¿ç”¨ float64 ä»¥æé«˜è®¡ç®—ç²¾åº¦
    all_u = np.concatenate(all_u, dtype=np.float64)
    all_v = np.concatenate(all_v, dtype=np.float64)
    all_beamaz = np.concatenate(all_beamaz, dtype=np.float64)

    logging.info(f"åœ¨ {MIN_HEIGHT}m <= z <= {MAX_HEIGHT}m æ¡ä»¶ä¸‹ï¼Œå…±åŠ è½½ {len(all_u)} ä¸ªæœ‰æ•ˆç‚¹ã€‚")

    u_mean = np.mean(all_u)
    u_std = np.std(all_u)
    v_mean = np.mean(all_v)
    v_std = np.std(all_v)
    beamaz_mean = np.mean(all_beamaz)
    beamaz_std = np.std(all_beamaz)

    # 4. æ‰“å°ç»“æœ
    print("\n--- ä¿®æ­£åçš„è®¡ç®—ç»“æœ (0 <= z <= 1000)ï¼Œè¯·ä½¿ç”¨è¿™ä¸ªæ›´æ–° .yaml ---")
    print("    transform:")
    print("      - type: NormalizeWind")
    print(f"        u_mean: {u_mean:.4f}")
    print(f"        u_std: {u_std:.4f}")
    print(f"        v_mean: {v_mean:.4f}")
    print(f"        v_std: {v_std:.4f}")
    print(f"        beamaz_mean: {beamaz_mean:.4f}")
    print(f"        beamaz_std: {beamaz_std:.4f}")
    print("      - type: WindShearGridSample")
    print(f"        ...")


if __name__ == "__main__":
    recalculate_stats_corrected()