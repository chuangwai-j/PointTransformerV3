import os
import sys
import logging

# è§£å†³æ¨¡å—å¯¼å…¥é—®é¢˜ï¼šå°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonæœç´¢è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
import yaml
import torch
import numpy as np
from datetime import datetime
from tqdm import tqdm
import warnings
from pointcept.utils.losses import MixedLoss

os.environ['MPLBACKEND'] = 'Agg'  # å…¨å±€å¼ºåˆ¶ä½¿ç”¨æ— GUIåç«¯ï¼Œé¿å…tkinterå†²çª

# 2. å†å¯¼å…¥matplotlib
import matplotlib.pyplot as plt
from torch.cuda.amp import autocast, GradScaler


# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from pointcept.datasets.builder import build_train_dataloader, build_val_dataloader
from pointcept.models import build_model
from pointcept.utils.logger import get_logger
from pointcept.utils.checkpoint import save_checkpoint
from pointcept.utils.logging import setup_logging  # å¯¼å…¥å·¥å…·å‡½æ•°

# 1. é…ç½®å…¨å±€æ—¥å¿—ï¼ˆåªè°ƒç”¨1æ¬¡ï¼ï¼‰
logger = setup_logging(log_dir="./logs")  # æ—¥å¿—æ–‡ä»¶å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•çš„logsæ–‡ä»¶å¤¹


# -------------------------- æ–°å¢ï¼šæ—©åœç­–ç•¥ç±» --------------------------
class EarlyStopping:
    def __init__(self, patience=10, min_delta=1e-4, mode='max', warmup=5):
        """
        æ—©åœç­–ç•¥
        Args:
            patience: å®¹å¿å¤šå°‘ä¸ªepochæ²¡æœ‰æ”¹å–„
            min_delta: æœ€å°æ”¹å–„å¹…åº¦
            mode: 'max' è¡¨ç¤ºæŒ‡æ ‡è¶Šå¤§è¶Šå¥½, 'min' è¡¨ç¤ºè¶Šå°è¶Šå¥½
            warmup: å‰å‡ ä¸ªepochä¸è¿›è¡Œæ—©åœåˆ¤æ–­
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.warmup = warmup
        self.counter = 0
        self.best_score = None
        self.early_stop = False

    def __call__(self, current_score, epoch):
        if epoch < self.warmup:
            return False

        if self.best_score is None:
            self.best_score = current_score
            return False

        if self.mode == 'max':
            improvement = current_score - self.best_score
        else:
            improvement = self.best_score - current_score

        if improvement > self.min_delta:
            self.best_score = current_score
            self.counter = 0
        else:
            self.counter += 1
            logger.info(f'æ—©åœè®¡æ•°å™¨: {self.counter}/{self.patience}')

        if self.counter >= self.patience:
            self.early_stop = True
            return True

        return False


def plot_loss_curve(epochs, train_loss, val_loss, save_dir):
    """ç»˜åˆ¶è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿å¹¶ä¿å­˜"""
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, train_loss, color='#e74c3c', linewidth=2.5, marker='o', markersize=4, label='Train Loss')
    plt.plot(epochs, val_loss, color='#3498db', linewidth=2.5, marker='s', markersize=4, label='Val Loss')

    plt.title('Training and Validation Loss Curve', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    plt.xticks(np.arange(0, len(epochs) + 1, step=5))

    save_path = os.path.join(save_dir, 'loss_curve.png')
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()


def plot_f1_curve(epochs, train_f1, val_f1, save_dir):
    """ç»˜åˆ¶è®­ç»ƒ/éªŒè¯F1æ›²çº¿å¹¶ä¿å­˜"""
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, train_f1, color='#2ecc71', linewidth=2.5, marker='o', markersize=4, label='Train F1')
    plt.plot(epochs, val_f1, color='#f39c12', linewidth=2.5, marker='s', markersize=4, label='Val F1')

    plt.title('Training and Validation F1 Score Curve', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('F1 Score', fontsize=12)
    plt.ylim(0.5, 1.0)
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    plt.xticks(np.arange(0, len(epochs) + 1, step=5))

    save_path = os.path.join(save_dir, 'f1_curve.png')
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()


def plot_lr_curve(epochs, learning_rates, save_dir):
    """ç»˜åˆ¶å­¦ä¹ ç‡å˜åŒ–æ›²çº¿"""
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, learning_rates, color='#9b59b6', linewidth=2.5, marker='o', markersize=4)

    plt.title('Learning Rate Schedule', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Learning Rate', fontsize=12)
    plt.yscale('log')
    plt.grid(True, alpha=0.3)
    plt.xticks(np.arange(0, len(epochs) + 1, step=5))

    save_path = os.path.join(save_dir, 'lr_curve.png')
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()


def calculate_metrics_gpu(logits, labels, criterion, num_classes=5):
    """
    GPUå‘é‡åŒ–è®¡ç®—æŒ‡æ ‡
    """
    loss = criterion(logits, labels)
    preds = torch.argmax(logits, dim=1)
    N = labels.shape[0]

    confusion = torch.bincount(
        labels * num_classes + preds,
        minlength=num_classes * num_classes
    ).view(num_classes, num_classes)

    tp = torch.diag(confusion)
    fp = confusion.sum(dim=1) - tp
    fn = confusion.sum(dim=0) - tp

    return {
        "loss": loss * N,
        "tp": tp,
        "fp": fp,
        "fn": fn,
        "total_points": N
    }


def main(config_path):
    # -------------------------- 1. åŠ è½½é…ç½®æ–‡ä»¶ --------------------------
    with open(config_path, 'r') as f:
        cfg = yaml.safe_load(f)

    logger = get_logger('wind_shear_train', log_dir='./logs')
    logger.info(f"ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_path}")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # -------------------------- 2. åˆå§‹åŒ–æ•°æ®é›†å’ŒDataLoader --------------------------
    train_loader = build_train_dataloader(cfg)
    val_loader = build_val_dataloader(cfg)

    # ã€è°ƒè¯•ã€‘éªŒè¯collate_fnæ˜¯å¦ç”Ÿæ•ˆ
    try:
        train_iter = iter(train_loader)
        first_batch = next(train_iter)
        if first_batch is not None:
            logger.info("\nè®­ç»ƒé›†ç¬¬ä¸€ä¸ªbatchå­—æ®µéªŒè¯ï¼š")
            for key in first_batch:
                if isinstance(first_batch[key], torch.Tensor):
                    logger.info(f"  {key}: shape {first_batch[key].shape}, dtype {first_batch[key].dtype}")
                else:
                    logger.info(f"  {key}: type {type(first_batch[key])}")
        else:
            logger.warning("ç¬¬ä¸€ä¸ªbatchä¸ºç©ºï¼Œå¯èƒ½æ‰€æœ‰æ ·æœ¬å‡è¢«è¿‡æ»¤")
    except Exception as e:
        logger.error(f"æ‰“å°ç¬¬ä¸€ä¸ªbatchå¤±è´¥: {e}")

    logger.info(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_loader.dataset)}, éªŒè¯é›†æ ·æœ¬æ•°: {len(val_loader.dataset)}")

    # -------------------------- 3. ä¼˜åŒ–åçš„ç±»åˆ«æƒé‡è®¾ç½® --------------------------
    # ğŸŒŸ ä½¿ç”¨æ›´åˆç†çš„æƒé‡è®¾ç½®
    weights = cfg['train']['class_weights']
    #inverse_weights = [0.05, 0.15, 0.3, 0.6, 0.45]

    weight_tensor = torch.tensor(weights, dtype=torch.float32, device=device)
    #criterion = torch.nn.CrossEntropyLoss(weight=weight_tensor)

    # 2. å®ä¾‹åŒ–æ··åˆæŸå¤±ï¼ˆnum_classes=5å¯¹åº”ä½ çš„5åˆ†ç±»ä»»åŠ¡ï¼Œalpha=weight_tensorå¤ç”¨åŸæƒé‡ï¼‰
    criterion = MixedLoss(num_classes=5, alpha=weight_tensor, gamma=2.0, focal_weight=1.0, dice_weight=1.0)

    logger.info("\n" + "=" * 60)
    logger.info("ä¼˜åŒ–åçš„ç±»åˆ«æƒé‡")
    logger.info("=" * 60)
    class_names = ["æ— é£åˆ‡å˜", "è½»å¾®é£åˆ‡å˜", "ä¸­åº¦é£åˆ‡å˜", "é‡åº¦é£åˆ‡å˜", "ä¸¥é‡é£åˆ‡å˜"]
    for cls in range(5):
        logger.info(f"ç±»åˆ«{cls}ï¼ˆ{class_names[cls]}ï¼‰ï¼šæƒé‡={weights[cls]:.6f}")
    logger.info("=" * 60)

    # -------------------------- 4. åˆå§‹åŒ–æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ --------------------------
    model = build_model(cfg['model']).to(device)
    logger.info(f"æ¨¡å‹ç±»å‹: {model.__class__.__name__}")

    # ğŸŒŸ ===================== æ–°å¢ä»£ç å¼€å§‹ ===================== ğŸŒŸ
    # æ‰“å°æ¨¡å‹é…ç½®å‚æ•°ï¼Œè¿™å¯¹äºæµ‹è¯•æ—¶å¤ç°æ¨¡å‹è‡³å…³é‡è¦
    logger.info("\n" + "=" * 60)
    logger.info("æ¨¡å‹é…ç½®å‚æ•° (cfg['model']):")
    logger.info("=" * 60)
    for key, value in cfg['model'].items():
        logger.info(f"  {key}: {value}")
    logger.info("=" * 60)

    # æ‰“å°æ¨¡å‹å®Œæ•´ç»“æ„
    logger.info("\n" + "=" * 60)
    logger.info("æ¨¡å‹å®Œæ•´ç»“æ„ (Model Structure):")
    logger.info("=" * 60)
    logger.info(str(model))  # str(model) å°†æ•è·å®Œæ•´çš„ PyTorch ç»“æ„
    logger.info("=" * 60)
    # ğŸŒŸ ===================== æ–°å¢ä»£ç ç»“æŸ ===================== ğŸŒŸ

    # ğŸŒŸ ä»é…ç½®è¯»å–å­¦ä¹ ç‡è®¾ç½®
    initial_lr = cfg['train']['optimizer']['lr']

    # ä¼˜åŒ–å™¨ï¼ˆAdamWï¼Œå¸¦æƒé‡è¡°å‡ï¼‰
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=initial_lr,
        weight_decay=cfg['train']['optimizer']['weight_decay']
    )

    # ğŸŒŸ ä½¿ç”¨ä¼ ç»Ÿçš„ä½™å¼¦é€€ç«è°ƒåº¦å™¨ï¼ˆ100è½®ç¼“æ…¢ä¸‹é™ï¼‰
    scheduler_cfg = cfg['train']['scheduler']
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=scheduler_cfg['T_max'],
        eta_min=scheduler_cfg['eta_min']
    )

    # ğŸŒŸ æ–°å¢ï¼šæ—©åœç­–ç•¥
    early_stopping = EarlyStopping(
        patience=15,  # å®¹å¿15ä¸ªepochæ²¡æœ‰æ”¹å–„
        min_delta=0.001,  # æœ€å°æ”¹å–„å¹…åº¦
        mode='max',  # ç›‘æ§éªŒè¯F1ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
        warmup=10  # å‰10ä¸ªepochä¸è¿›è¡Œæ—©åœåˆ¤æ–­
    )

    # ğŸŒŸ åˆå§‹åŒ–æ•°æ®è®°å½•åˆ—è¡¨
    train_losses = []
    train_f1s = []
    val_losses = []
    val_f1s = []
    epochs_list = []
    learning_rates = []  # è®°å½•å­¦ä¹ ç‡å˜åŒ–
    plot_save_dir = "./logs_photo/plots"
    os.makedirs(plot_save_dir, exist_ok=True)

    # -------------------------- 5. è®­ç»ƒå¾ªç¯ --------------------------
    best_val_f1 = 0.0
    total_epochs = cfg['train']['epochs']

    for epoch in range(1, total_epochs + 1):
        epochs_list.append(epoch)
        current_lr = optimizer.param_groups[0]['lr']
        learning_rates.append(current_lr)

        logger.info(f"\n===== Epoch {epoch}/{total_epochs} =====")
        logger.info(f"å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}")

        # -------------------------- 5.1 è®­ç»ƒé˜¶æ®µ --------------------------
        model.train()
        train_tp = torch.zeros(5, dtype=torch.long, device=device)
        train_fp = torch.zeros(5, dtype=torch.long, device=device)
        train_fn = torch.zeros(5, dtype=torch.long, device=device)
        train_total_loss = 0.0
        train_total_points = 0
        abnormal_train_batches = []
        total_train_batches = 0
        normal_train_batches = 0

        for batch_idx, batch in enumerate(tqdm(train_loader, desc="è®­ç»ƒä¸­")):
            total_train_batches += 1
            if batch is None or len(batch['path']) == 0:
                logger.warning(f"è·³è¿‡ç©ºè®­ç»ƒbatch {batch_idx}")
                continue

            # è½¬ç§»batchåˆ°è®¾å¤‡
            batch_device = {}
            for k, v in batch.items():
                if isinstance(v, torch.Tensor):
                    batch_device[k] = v.to(device)
                elif k == 'path':
                    batch_device[k] = v
            batch = batch_device
            labels = batch['generate_label'].long()
            logits = model(batch)

            # å¼‚å¸¸æ£€æµ‹
            loss = criterion(logits, labels)
            if torch.isnan(loss) or torch.isinf(loss):
                sample_paths = [os.path.basename(p) for p in batch.get('path', ['æœªçŸ¥è·¯å¾„'])]
                abnormal_info = {"batch_idx": batch_idx, "sample_paths": sample_paths,
                                 "loss_value": loss.item() if not torch.isnan(loss) else "nan",
                                 "points_count": labels.shape[0]}
                abnormal_train_batches.append(abnormal_info)
                logger.error(
                    f"âŒ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å¼‚å¸¸: loss={abnormal_info['loss_value']}, æ ·æœ¬è·¯å¾„={sample_paths}, ç‚¹æ•°={labels.shape[0]}")
                continue

            # æ­£å¸¸æ‰¹æ¬¡ï¼šåå‘ä¼ æ’­
            normal_train_batches += 1
            optimizer.zero_grad()
            loss.backward()

            # ğŸŒŸ æ”¹è¿›çš„æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)

            optimizer.step()

            # è®¡ç®—æŒ‡æ ‡
            metrics = calculate_metrics_gpu(logits, labels, criterion)
            train_total_loss += metrics["loss"].item()
            train_tp += metrics["tp"]
            train_fp += metrics["fp"]
            train_fn += metrics["fn"]
            train_total_points += metrics["total_points"]

        # è®­ç»ƒæŒ‡æ ‡è®¡ç®—
        train_avg_loss = train_total_loss / train_total_points if train_total_points > 0 else 0.0
        epsilon = 1e-6
        train_precision = train_tp / (train_tp + train_fp + epsilon)
        train_recall = train_tp / (train_tp + train_fn + epsilon)
        train_f1 = 2 * (train_precision * train_recall) / (train_precision + train_recall + epsilon)
        class_counts = train_tp + train_fn
        total_counts = class_counts.sum()
        train_weighted_f1 = (train_f1 * class_counts).sum() / (total_counts + epsilon)
        train_weighted_precision = (train_precision * class_counts).sum() / (total_counts + epsilon)
        train_weighted_recall = (train_recall * class_counts).sum() / (total_counts + epsilon)

        # è®°å½•è®­ç»ƒæŒ‡æ ‡
        train_losses.append(train_avg_loss if train_total_points > 0 else 0.0)
        train_f1s.append(train_weighted_f1.item() if train_total_points > 0 else 0.0)

        if train_total_points > 0:
            logger.info(
                f"è®­ç»ƒé›†: æŸå¤±={train_avg_loss:.4f}, "
                f"å¬å›ç‡={train_weighted_recall.item():.4f}, ç²¾ç¡®ç‡={train_weighted_precision.item():.4f}, F1={train_weighted_f1.item():.4f}"
            )

            # ğŸŒŸ è®°å½•å„ç±»åˆ«F1åˆ†æ•°
            logger.info("å„ç±»åˆ«è®­ç»ƒF1åˆ†æ•°:")
            for cls in range(5):
                logger.info(f"  ç±»åˆ«{cls}({class_names[cls]}): {train_f1[cls].item():.4f}")
        else:
            logger.warning("æœ¬epochæ— æœ‰æ•ˆè®­ç»ƒæ ·æœ¬ï¼Œè·³è¿‡è®­ç»ƒæŒ‡æ ‡è®¡ç®—")

        # -------------------------- 5.2 éªŒè¯é˜¶æ®µ --------------------------
        if epoch % cfg['evaluation']['interval'] == 0:
            model.eval()
            val_tp = torch.zeros(5, dtype=torch.long, device=device)
            val_fp = torch.zeros(5, dtype=torch.long, device=device)
            val_fn = torch.zeros(5, dtype=torch.long, device=device)
            val_total_loss = 0.0
            val_total_points = 0

            with torch.no_grad():
                for batch_idx, batch in enumerate(tqdm(val_loader, desc="éªŒè¯ä¸­")):
                    if batch is None:
                        logger.warning(f"è·³è¿‡ç©ºéªŒè¯batch {batch_idx}")
                        continue

                    batch_device = {}
                    for k, v in batch.items():
                        if isinstance(v, torch.Tensor):
                            batch_device[k] = v.to(device)
                        elif k == 'path':
                            batch_device[k] = v
                    batch = batch_device
                    labels = batch['generate_label'].long()
                    logits = model(batch)

                    metrics = calculate_metrics_gpu(logits, labels, criterion)
                    val_total_loss += metrics["loss"].item()
                    val_tp += metrics["tp"]
                    val_fp += metrics["fp"]
                    val_fn += metrics["fn"]
                    val_total_points += metrics["total_points"]

            # éªŒè¯æŒ‡æ ‡è®¡ç®—
            val_avg_loss = val_total_loss / val_total_points if val_total_points > 0 else 0.0
            val_precision = val_tp / (val_tp + val_fp + epsilon)
            val_recall = val_tp / (val_tp + val_fn + epsilon)
            val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall + epsilon)
            val_class_counts = val_tp + val_fn
            val_total_counts = val_class_counts.sum()
            val_weighted_f1 = (val_f1 * val_class_counts).sum() / (val_total_counts + epsilon)
            val_weighted_precision = (val_precision * val_class_counts).sum() / (val_total_counts + epsilon)
            val_weighted_recall = (val_recall * val_class_counts).sum() / (val_total_counts + epsilon)

            # è®°å½•éªŒè¯æŒ‡æ ‡
            val_losses.append(val_avg_loss if val_total_points > 0 else 0.0)
            val_f1s.append(val_weighted_f1.item() if val_total_points > 0 else 0.0)

            if val_total_points > 0:
                logger.info(
                    f"éªŒè¯é›†: æŸå¤±={val_avg_loss:.4f}, "
                    f"å¬å›ç‡={val_weighted_recall.item():.4f}, ç²¾ç¡®ç‡={val_weighted_precision.item():.4f}, F1={val_weighted_f1.item():.4f}"
                )

                # ğŸŒŸ è®°å½•å„ç±»åˆ«éªŒè¯F1åˆ†æ•°
                logger.info("å„ç±»åˆ«éªŒè¯F1åˆ†æ•°:")
                for cls in range(5):
                    logger.info(f"  ç±»åˆ«{cls}({class_names[cls]}): {val_f1[cls].item():.4f}")

                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_weighted_f1.item() > best_val_f1:
                    best_val_f1 = val_weighted_f1.item()
                    save_checkpoint(model, optimizer, scheduler, epoch,
                                    save_path=f"./checkpoints/best_model_epoch{epoch}.pth")
                    logger.info(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (F1={best_val_f1:.4f}) åˆ° ./checkpoints/")

                # ğŸŒŸ æ—©åœåˆ¤æ–­
                if early_stopping(val_weighted_f1.item(), epoch):
                    logger.info(f"ğŸš¨ è§¦å‘æ—©åœï¼æœ€ä½³éªŒè¯F1: {best_val_f1:.4f}")
                    break
            else:
                logger.warning("æœ¬epochæ— æœ‰æ•ˆéªŒè¯æ ·æœ¬ï¼Œè·³è¿‡éªŒè¯æŒ‡æ ‡è®¡ç®—å’Œæ¨¡å‹ä¿å­˜")
        else:
            # ä¸æ‰§è¡ŒéªŒè¯æ—¶ï¼Œè¿½åŠ é»˜è®¤å€¼
            val_losses.append(0.0)
            val_f1s.append(0.0)

        # ğŸŒŸ ç»˜åˆ¶æ›²çº¿ï¼ˆæ¯ä¸ªepochæ›´æ–°ï¼‰
        if epoch % 1 == 0:
            plot_loss_curve(epochs_list, train_losses, val_losses, plot_save_dir)
            plot_f1_curve(epochs_list, train_f1s, val_f1s, plot_save_dir)
            plot_lr_curve(epochs_list, learning_rates, plot_save_dir)

        # ğŸŒŸ å­¦ä¹ ç‡è°ƒåº¦å™¨æ­¥è¿›ï¼ˆæ”¾åœ¨æ¯ä¸ªepochæœ€åï¼‰
        scheduler.step()

        # ğŸŒŸ æ—©åœæ£€æŸ¥ï¼ˆå¦‚æœè§¦å‘åˆ™è·³å‡ºå¾ªç¯ï¼‰
        if early_stopping.early_stop:
            break

    logger.info(f"\nè®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯é›†F1åˆ†æ•°: {best_val_f1:.4f}")
    logger.info(f"æ€»è®­ç»ƒè½®æ•°: {len(epochs_list)}/{total_epochs}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='configs/wind_shear/pointtransformer_v3.yaml',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()

    # é¢„å…ˆåˆ›å»ºæ—¥å¿—å’Œæ£€æŸ¥ç‚¹ç›®å½•
    os.makedirs('./logs', exist_ok=True)
    os.makedirs('./checkpoints', exist_ok=True)
    os.makedirs('./logs_photo/plots', exist_ok=True)

    main(args.config)