import os
import sys
import yaml
import torch
import numpy as np
from tqdm import tqdm
from collections import defaultdict
import matplotlib.pyplot as plt  # æ–°å¢ï¼šç”¨äºç»˜åˆ¶ç‚¹æ•°åˆ†å¸ƒç›´æ–¹å›¾

# è§£å†³æ¨¡å—å¯¼å…¥é—®é¢˜ï¼šä¸train.pyä¿æŒä¸€è‡´
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆä»…ä¿ç•™æ•°æ®åŠ è½½ç›¸å…³ï¼‰
from pointcept.datasets.builder import build_train_dataloader
from pointcept.utils.logging import setup_logging
from pointcept.utils.logger import get_logger


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°ï¼šä»…éœ€æŒ‡å®šé…ç½®æ–‡ä»¶"""
    import argparse
    parser = argparse.ArgumentParser(description="ç»Ÿè®¡è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒå’Œæ ·æœ¬ç‚¹æ•°åˆ†å¸ƒ")
    parser.add_argument(
        '--config',
        type=str,
        default='configs/wind_shear/pointtransformer_v3.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆä¸train.pyä½¿ç”¨çš„é…ç½®ä¸€è‡´ï¼‰'
    )
    parser.add_argument(
        '--histogram',
        action='store_true',
        help='æ˜¯å¦ç”Ÿæˆç‚¹æ•°åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆä¿å­˜åˆ°logsç›®å½•ï¼‰'
    )
    return parser.parse_args()


def load_config(config_path):
    """åŠ è½½yamlé…ç½®æ–‡ä»¶"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{config_path}")
    with open(config_path, 'r', encoding='utf-8') as f:
        cfg = yaml.safe_load(f)
    return cfg


def count_train_statistics(train_loader, num_classes=5, save_histogram=False):
    """
    ç»Ÿè®¡è®­ç»ƒé›†ï¼š
    1. ç±»åˆ«åˆ†å¸ƒï¼ˆç‚¹çº§åˆ«ï¼‰
    2. æ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°ï¼ˆæ ·æœ¬çº§åˆ«ï¼‰åŠåˆ†å¸ƒç‰¹å¾
    """
    # 1. åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
    class_counts = defaultdict(int)  # ç±»åˆ«ç‚¹æ•°é‡
    sample_point_counts = {}  # æ ·æœ¬ç‚¹æ•°ï¼š{æ ·æœ¬è·¯å¾„: ç‚¹æ•°}
    total_points = 0  # æ€»ç‚¹æ•°
    all_sample_points = []  # æ‰€æœ‰æ ·æœ¬çš„ç‚¹æ•°åˆ—è¡¨ï¼ˆç”¨äºè®¡ç®—åˆ†å¸ƒï¼‰

    print(f"\nå¼€å§‹éå†è®­ç»ƒé›†ï¼ˆå…±{len(train_loader)}ä¸ªbatchï¼‰...")
    for batch_idx, batch in enumerate(tqdm(train_loader, desc="ç»Ÿè®¡ä¸­")):
        # è·³è¿‡ç©ºbatch
        if batch is None or len(batch.get('path', [])) == 0:
            print(f"âš ï¸  è·³è¿‡ç©ºbatch {batch_idx}ï¼ˆæ— æœ‰æ•ˆæ ·æœ¬ï¼‰")
            continue

        # 2. æå–å½“å‰batchçš„å…³é”®å­—æ®µ
        labels = batch['generate_label'].long()  # ç‚¹çº§åˆ«æ ‡ç­¾
        offsets = batch['offset']  # æ ·æœ¬åˆ†å‰²åç§»é‡ï¼ˆå…³é”®ï¼šç”¨äºè®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°ï¼‰
        paths = batch['path']  # æ ·æœ¬è·¯å¾„ï¼ˆå”¯ä¸€æ ‡è¯†æ ·æœ¬ï¼‰

        # 3. ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒï¼ˆç‚¹çº§åˆ«ï¼‰
        flat_labels = labels.view(-1).cpu().numpy()
        batch_class_count = np.bincount(flat_labels, minlength=num_classes)
        for cls in range(num_classes):
            class_counts[cls] += batch_class_count[cls]
        total_points += flat_labels.shape[0]

        # 4. ç»Ÿè®¡æ ·æœ¬ç‚¹æ•°ï¼ˆæ ¸å¿ƒæ–°å¢é€»è¾‘ï¼‰
        # offsetsæ ¼å¼ï¼š[0, p1, p1+p2, ..., total]ï¼Œæ¯ä¸ªæ ·æœ¬ç‚¹æ•° = offsets[i+1] - offsets[i]
        offsets_np = offsets.cpu().numpy()
        for i in range(len(paths)):
            sample_path = paths[i]
            # è®¡ç®—å½“å‰æ ·æœ¬çš„ç‚¹æ•°ï¼ˆå¤„ç†æœ€åä¸€ä¸ªæ ·æœ¬çš„è¾¹ç•Œæƒ…å†µï¼‰
            if i < len(offsets_np) - 1:
                point_num = offsets_np[i+1] - offsets_np[i]
            else:
                point_num = flat_labels.shape[0] - offsets_np[i]  # å…œåº•ï¼šé¿å…ç´¢å¼•è¶Šç•Œ
            # è®°å½•æ ·æœ¬ç‚¹æ•°
            sample_point_counts[sample_path] = point_num
            all_sample_points.append(point_num)

    # 5. è®¡ç®—ç‚¹æ•°åˆ†å¸ƒçš„å…³é”®æŒ‡æ ‡
    if all_sample_points:
        point_stats = {
            'min': np.min(all_sample_points),
            'max': np.max(all_sample_points),
            'mean': np.mean(all_sample_points),
            'median': np.median(all_sample_points),
            'std': np.std(all_sample_points),  # æ ‡å‡†å·®ï¼šåæ˜ ç‚¹æ•°æ³¢åŠ¨ç¨‹åº¦
            'total_samples': len(all_sample_points)
        }
    else:
        point_stats = None

    # 6. ç”Ÿæˆç‚¹æ•°åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆå¯é€‰ï¼‰
    if save_histogram and all_sample_points:
        plt.figure(figsize=(10, 6))
        plt.hist(all_sample_points, bins=20, color='skyblue', edgecolor='black')
        plt.axvline(point_stats['mean'], color='r', linestyle='--', label=f'å‡å€¼ï¼š{point_stats["mean"]:.1f}')
        plt.axvline(point_stats['median'], color='g', linestyle='-', label=f'ä¸­ä½æ•°ï¼š{point_stats["median"]:.1f}')
        plt.xlabel('æ ·æœ¬ç‚¹æ•°')
        plt.ylabel('æ ·æœ¬æ•°é‡')
        plt.title('è®­ç»ƒé›†æ ·æœ¬ç‚¹æ•°åˆ†å¸ƒ')
        plt.legend()
        os.makedirs('./logs', exist_ok=True)
        plt.savefig('./logs/sample_point_count_histogram.png')
        plt.close()
        print(f"ğŸ“Š ç‚¹æ•°åˆ†å¸ƒç›´æ–¹å›¾å·²ä¿å­˜åˆ° ./logs/sample_point_count_histogram.png")

    # æ•´ç†ç»“æœ
    final_class_counts = {cls: class_counts.get(cls, 0) for cls in range(num_classes)}
    return final_class_counts, total_points, sample_point_counts, point_stats


def main():
    # 1. åˆå§‹åŒ–æ—¥å¿—
    setup_logging(log_dir="./logs")
    logger = get_logger("train_statistics")

    # 2. è§£æå‚æ•°+åŠ è½½é…ç½®
    args = parse_args()
    cfg = load_config(args.config)
    logger.info(f"âœ… åŠ è½½é…ç½®æ–‡ä»¶ï¼š{args.config}")

    # 3. æ„å»ºè®­ç»ƒé›†DataLoaderï¼ˆå¤ç”¨train.pyé€»è¾‘ï¼‰
    train_loader = build_train_dataloader(cfg)
    logger.info(f"âœ… è®­ç»ƒé›†DataLoaderæ„å»ºå®Œæˆï¼šå…±{len(train_loader)}ä¸ªbatchï¼Œ{len(train_loader.dataset)}ä¸ªæ ·æœ¬æ–‡ä»¶")

    # 4. ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒå’Œæ ·æœ¬ç‚¹æ•°
    num_classes = cfg['model']['num_classes']
    class_counts, total_points, sample_counts, point_stats = count_train_statistics(
        train_loader,
        num_classes,
        save_histogram=args.histogram  # æ§åˆ¶æ˜¯å¦ç”Ÿæˆç›´æ–¹å›¾
    )

    # 5. è¾“å‡ºç±»åˆ«åˆ†å¸ƒç»“æœï¼ˆä¿æŒåŸæœ‰æ ¼å¼ï¼‰
    logger.info("\n" + "=" * 60)
    logger.info("è®­ç»ƒé›†ç±»åˆ«æ•°é‡ç»Ÿè®¡ç»“æœï¼ˆç‚¹çº§åˆ«ï¼‰")
    logger.info("=" * 60)
    class_names = {
        0: "æ— é£åˆ‡å˜",
        1: "è½»å¾®é£åˆ‡å˜",
        2: "ä¸­åº¦é£åˆ‡å˜",
        3: "é‡åº¦é£åˆ‡å˜",
        4: "ä¸¥é‡é£åˆ‡å˜"
    }
    for cls in range(num_classes):
        count = class_counts[cls]
        percentage = (count / total_points) * 100 if total_points > 0 else 0.0
        logger.info(f"ç±»åˆ«{cls}ï¼ˆ{class_names[cls]}ï¼‰ï¼š{count:,} ä¸ªç‚¹ï¼ˆå æ¯”ï¼š{percentage:.2f}%ï¼‰")
    logger.info("=" * 60)
    logger.info(f"è®­ç»ƒé›†æ€»ç‚¹æ•°ï¼š{total_points:,}")

    # 6. æ–°å¢ï¼šè¾“å‡ºæ ·æœ¬ç‚¹æ•°ç»Ÿè®¡ç»“æœ
    if point_stats:
        logger.info("\n" + "=" * 60)
        logger.info("è®­ç»ƒé›†æ ·æœ¬ç‚¹æ•°ç»Ÿè®¡ç»“æœï¼ˆæ ·æœ¬çº§åˆ«ï¼‰")
        logger.info("=" * 60)
        logger.info(f"æ ·æœ¬æ€»æ•°ï¼š{point_stats['total_samples']}")
        logger.info(f"æœ€å°ç‚¹æ•°ï¼š{point_stats['min']}")
        logger.info(f"æœ€å¤§ç‚¹æ•°ï¼š{point_stats['max']}")
        logger.info(f"å¹³å‡ç‚¹æ•°ï¼š{point_stats['mean']:.1f}")
        logger.info(f"ä¸­ä½æ•°ç‚¹æ•°ï¼š{point_stats['median']:.1f}")
        logger.info(f"ç‚¹æ•°æ ‡å‡†å·®ï¼š{point_stats['std']:.1f}ï¼ˆå€¼è¶Šå¤§ï¼Œç‚¹æ•°å·®å¼‚è¶Šæ˜¾è‘—ï¼‰")
        logger.info("=" * 60)

        # æ‰“å°ç‚¹æ•°æç«¯çš„æ ·æœ¬ï¼ˆè¾…åŠ©åˆ†æï¼‰
        sorted_samples = sorted(sample_counts.items(), key=lambda x: x[1])
        logger.info("\nç‚¹æ•°æœ€å°‘çš„5ä¸ªæ ·æœ¬ï¼š")
        for path, num in sorted_samples[:5]:
            logger.info(f"  {path.split('/')[-1]}: {num} ç‚¹")
        logger.info("\nç‚¹æ•°æœ€å¤šçš„5ä¸ªæ ·æœ¬ï¼š")
        for path, num in sorted_samples[-5:]:
            logger.info(f"  {path.split('/')[-1]}: {num} ç‚¹")
    else:
        logger.warning("\nâš ï¸  æœªç»Ÿè®¡åˆ°æœ‰æ•ˆæ ·æœ¬ç‚¹æ•°ï¼ˆå¯èƒ½æ•°æ®é›†ä¸ºç©ºï¼‰")

    logger.info("\nç»Ÿè®¡å®Œæˆï¼å¯æ ¹æ®æ ·æœ¬ç‚¹æ•°åˆ†å¸ƒè°ƒæ•´æ•°æ®é¢„å¤„ç†ç­–ç•¥")


if __name__ == "__main__":
    main()