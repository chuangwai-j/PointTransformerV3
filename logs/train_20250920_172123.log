2025-09-20 17:21:23 - wind_shear:30 - INFO - WindShearDataset train split: 8935 scenes
2025-09-20 17:21:24 - wind_shear:30 - INFO - WindShearDataset val split: 2130 scenes
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2377
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2377
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2377]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2377, 64])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2377
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2377
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2377]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2377, 64])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([914]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([914, 128])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([914]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([914, 128])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([914]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([914, 128])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([914]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([914, 128])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([914]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([914, 128])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:25 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:25 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:25 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:25 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 914
2025-09-20 17:21:25 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:25 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:25 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([914]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:25 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:25 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([914, 128])
2025-09-20 17:21:25 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:25 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:25 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 480], device='cuda:0')
2025-09-20 17:21:25 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:25 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 299
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 299
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([299]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([299, 256])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 480], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 299
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 299
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([299]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([299, 256])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 914
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 914
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([914]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([914, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 914
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 914
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([914]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([914, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2377
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2377
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2377]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2377, 64])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2377
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2377
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2377]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2377, 64])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2641
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2641
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2641]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2641, 64])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2641
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2641
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2641]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2641, 64])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1051, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1051, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1051, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1051, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1051, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1051, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:26 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 336
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 336
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([336]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([336, 256])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 336
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 336
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([336]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([336, 256])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1051, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1051
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1051, 128])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2641
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2641
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2641]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2641, 64])
2025-09-20 17:21:26 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:26 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:26 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:26 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:26 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:26 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:26 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2641
2025-09-20 17:21:26 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2641
2025-09-20 17:21:26 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:26 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:26 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2641]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:26 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:26 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2641, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2647
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2647
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2647]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2647, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2647
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2647
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2647]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2647, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 325
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 325
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([325]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([325, 256])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 325
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 325
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([325]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([325, 256])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2647
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2647
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2647]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2647, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2647
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2647
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2647]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2647, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4527
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4527
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4527]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4527, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4527
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4527
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4527]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4527, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1906]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1906, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1906]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1906, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1906]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1906, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1906]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1906, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1906]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1906, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1906]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1906, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 589
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 589
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([589]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([589, 256])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 589
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 589
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([589]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([589, 256])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1906]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1906, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1906
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1906]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1906, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4527
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4527
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4527]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4527, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4527
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4527
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4527]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4527, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4224], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4224], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2112], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4970
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4970
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4970]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4970, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2112], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4970
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4970
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4970]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4970, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2198]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2198, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2198]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2198, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2198]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2198, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2198]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2198, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2198]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2198, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2198]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2198, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 528], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 692
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 692
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([692]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([692, 256])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 528], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1248], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 692
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 692
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([692]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([692, 256])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2198]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2198, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2496], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2198
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2198]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2198, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2112], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4970
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4970
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4970]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4970, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2112], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4992], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4970
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4970
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4970]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4970, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4224], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4224], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9984], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 10368], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4224], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10368, unpad长度将设为=10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 10368], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 10368], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4224], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 10368], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5184], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2112], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5184, unpad长度将设为=5184
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5184], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7604
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7604
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7604]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7604, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5184], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2112], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5184], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7604
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7604
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7604]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7604, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2592, unpad长度将设为=2592
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3199]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3199, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3199]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3199, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3199]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3199, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3199]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3199, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3199]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3199, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3199]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3199, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1296], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 528], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1296, unpad长度将设为=1296
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1296], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 956
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 956
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([956]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([956, 256])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1296], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 528], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1296], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 956
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 956
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([956]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([956, 256])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3199]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3199, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1056], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2592], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3199
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3199]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3199, 128])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5184], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2112], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5184], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7604
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7604
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7604]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7604, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5184], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2112], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5184], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7604
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7604
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7604]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7604, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 10368], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4224], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 10368], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 10368], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4224], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 10368], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4041
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4041
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4041]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4041, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4041
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4041
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:27 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4041]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:27 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4041, 64])
2025-09-20 17:21:27 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:27 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:27 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:27 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:21:27 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:27 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:27 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:27 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:27 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:27 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1653
2025-09-20 17:21:27 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1653
2025-09-20 17:21:27 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:27 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1653]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1653, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1653]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1653, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1653]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1653, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1653]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1653, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1653]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1653, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1653]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1653, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 517
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 517
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([517]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([517, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 517
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 517
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([517]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([517, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1653]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1653, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1653
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1653]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1653, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4041
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4041
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4041]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4041, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4041
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4041
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4041]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4041, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2681
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2681
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2681]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2681, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2681
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2681
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2681]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2681, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 338
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 338
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([338]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([338, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 338
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 338
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([338]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([338, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1060
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1060]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1060, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2681
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2681
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2681]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2681, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2681
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2681
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2681]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2681, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 8064], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 6528], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 8064], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(6528, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=768
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6528，K=3264
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 8064], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 6528], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 8064], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(6528, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=768
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6528，K=3264
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 4032], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 3264], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 4032], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(3264, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=192
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3264，K=816
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6132
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6132
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6132]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6132, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 4032], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 3264], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 4032], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(3264, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=192
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3264，K=816
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6132
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6132
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6132]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6132, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 384, 1632], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=48
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 384, 1632], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=48
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 384, 1632], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=48
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 384, 1632], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=48
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 384, 1632], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=48
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 384, 1632], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=48
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  192, 1008], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([192, 816], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 192
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  192, 1008], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(192, device='cuda:0'), tensor(816, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数192，K=12
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数816，K=51
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 837
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 837
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([837]), 最大索引: 192, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([837, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  192, 1008], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([192, 816], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 192
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  192, 1008], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(192, device='cuda:0'), tensor(816, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数192，K=12
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数816，K=51
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 837
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 837
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([837]), 最大索引: 192, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([837, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 384, 1632], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=48
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 384, 1632], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 2016], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(1632, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=48
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1632，K=204
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 4032], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 3264], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 4032], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(3264, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=192
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3264，K=816
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6132
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6132
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6132]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6132, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 4032], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 3264], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 4032], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(3264, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=192
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3264，K=816
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6132
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6132
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6132]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6132, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 8064], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 6528], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 8064], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(6528, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6528，K=1632
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 8064], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 6528], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 8064], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(6528, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6528，K=1632
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2495
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2495
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2495]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2495, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2495
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2495
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2495]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2495, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 432], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 292
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 292
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([292]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([292, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 432], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 292
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 292
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([292]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([292, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 962
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([962]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([962, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2495
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2495
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2495]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2495, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2495
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2495
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2495]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2495, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6823
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6823
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6823]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6823, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6823
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6823
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6823]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6823, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 835
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 835
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([835]), 最大索引: 624, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([835, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 835
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 835
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([835]), 最大索引: 624, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([835, 256])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6823
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6823
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6823]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6823, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6823
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6823
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6823]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6823, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:21:28 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:28 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:28 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:28 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:21:28 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:28 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:21:28 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:21:28 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:21:28 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:28 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:28 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:28 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4230
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4230
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4230]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4230, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4230
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4230
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4230]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4230, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1751]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1751, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1751]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1751, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1751]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1751, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1751]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1751, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1751]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1751, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1751]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1751, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 536
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 536
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([536]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([536, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 536
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 536
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([536]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([536, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1751]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1751, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1751
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1751]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1751, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4230
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4230
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4230]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4230, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4230
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4230
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4230]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4230, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5404
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5404
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5404]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5404, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5404
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5404
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5404]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5404, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2469]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2469, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2469]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2469, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2469]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2469, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2469]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2469, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2469]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2469, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2469]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2469, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 432], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 771
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 771
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([771]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([771, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 432], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 771
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 771
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([771]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([771, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2469]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2469, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2469
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2469]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2469, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5404
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5404
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5404]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5404, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5404
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5404
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5404]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5404, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3072], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3072], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6596
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6596
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6596]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6596, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6596
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6596
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6596]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6596, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2763]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2763, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2763]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2763, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2763]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2763, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2763]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2763, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2763]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2763, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2763]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2763, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1104], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 384], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1104], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 720, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1104], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 384], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1104], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 720, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2763]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2763, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2763
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2763]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2763, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6596
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6596
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6596]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6596, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6596
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6596
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6596]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6596, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3072], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3072], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 6144], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 6144], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 3072], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7070
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7070
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7070]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7070, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 3072], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7070
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7070
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7070]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7070, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3023]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3023, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3023]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3023, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3023]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3023, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3023]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3023, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3023]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3023, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3023]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3023, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 905
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 905
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([905]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([905, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 768], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 1152], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 905
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 905
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([905]), 最大索引: 384, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([905, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3023]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3023, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3023
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3023]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3023, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 3072], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7070
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7070
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7070]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7070, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 3072], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7070
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7070
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7070]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7070, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 6144], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 6144], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4992], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10368, unpad长度将设为=10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4992], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2496], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5184, unpad长度将设为=5184
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4699
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4699
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4699]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4699, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2496], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4699
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4699
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4699]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4699, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2592, unpad长度将设为=2592
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1987]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1987, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1987]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1987, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1987]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1987, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1987]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1987, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1987]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1987, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1987]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1987, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1296], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 624], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:21:29 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1296, unpad长度将设为=1296
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1296], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 619
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 619
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([619]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([619, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1296], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 624], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1296], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 619
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 619
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([619]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([619, 256])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1987]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1987, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1987
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1987]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1987, 128])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2496], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4699
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4699
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4699]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4699, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2496], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4699
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4699
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4699]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4699, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4992], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:21:29 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:29 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:29 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4992], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:21:29 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:29 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:21:29 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:21:29 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:21:29 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:21:29 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:21:29 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:29 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1536], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5760, unpad长度将设为=5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=768
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1536], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=768
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  768], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2880, unpad长度将设为=2880
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=192
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4196
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4196
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4196]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4196, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  768], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=192
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4196
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4196
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4196]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4196, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1440, unpad长度将设为=1440
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1615]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1615, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1615]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1615, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1615]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1615, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1615]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1615, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1615]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1615, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1615]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1615, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 720], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 192], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 192
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=720, unpad长度将设为=720
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 720], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(192, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数192，K=12
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 485
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 485
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([485]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([485, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 720], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 192], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 192
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 720], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(192, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数192，K=12
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 485
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 485
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([485]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([485, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1615]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1615, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1615
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1615]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1615, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  768], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=192
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4196
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4196
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4196]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4196, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  768], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=192
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4196
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4196
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4196]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4196, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1536], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1536], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5342
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5342
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5342]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5342, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5342
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5342
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5342]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5342, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2040]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2040, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2040]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2040, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2040]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2040, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2040]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2040, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2040]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2040, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2040]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2040, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 603
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 603
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([603]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([603, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 603
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 603
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([603]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([603, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2040]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2040, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2040
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2040]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2040, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5342
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5342
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5342]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5342, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5342
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5342
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5342]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5342, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2997
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2997
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2997]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2997, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2997
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2997
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2997]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2997, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 388
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 388
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([388]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([388, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 388
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 388
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([388]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([388, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2997
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2997
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2997]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2997, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2997
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2997
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2997]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2997, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 4224], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 4224], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 2112], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2640
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2640
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2640]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2640, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 2112], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2640
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2640
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2640]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2640, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1081]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1081, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1081]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1081, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1081]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1081, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1081]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1081, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1081]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1081, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1081]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1081, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 288, 816], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([288, 528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 288, 816], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(288, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数288，K=18
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 344
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 344
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([344]), 最大索引: 288, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([344, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 288, 816], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([288, 528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 288, 816], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(288, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数288，K=18
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 344
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 344
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([344]), 最大索引: 288, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([344, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1081]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1081, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1081
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1081]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1081, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 2112], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2640
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2640
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2640]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2640, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 2112], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2640
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2640
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2640]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2640, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 4224], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 4224], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4608], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1536], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4608], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=768
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4608]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4608, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4608], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1536], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4608], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=768
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4608]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4608, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2304], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  768], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2304], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=192
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2304], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  768], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2304], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=192
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 576], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 192], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 192
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=576, unpad长度将设为=576
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 576], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(192, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数192，K=12
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 293
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 293
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([293]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([293, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 576], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 192], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 192
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 576], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(192, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数192，K=12
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 293
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 293
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([293]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([293, 256])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 384], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1152], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=48
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1030
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1030]), 最大索引: 768, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1030, 128])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2304], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  768], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2304], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=192
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2304], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  768], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2304], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=192
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4608], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1536], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4608], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4608]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4608, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4608], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1536], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4608], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 4608
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4608]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4608, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5760, unpad长度将设为=5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3840], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2880, unpad长度将设为=2880
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3938
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3938
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3938]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3938, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1920], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:30 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:21:30 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:30 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3938
2025-09-20 17:21:30 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3938
2025-09-20 17:21:30 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:30 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:30 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3938]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:30 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:30 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3938, 64])
2025-09-20 17:21:30 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:30 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:30 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:21:30 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:30 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1440, unpad长度将设为=1440
2025-09-20 17:21:30 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1432]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1432, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1432]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1432, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1432]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1432, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1432]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1432, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1432]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1432, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1432]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1432, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 720], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 480], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=720, unpad长度将设为=720
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 720], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 410
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 410
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([410]), 最大索引: 240, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([410, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 720], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 480], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 720], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 410
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 410
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([410]), 最大索引: 240, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([410, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1432]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1432, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1432
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1432]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1432, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3938
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3938
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3938]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3938, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3938
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3938
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3938]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3938, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5402
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5402
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5402]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5402, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5402
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5402
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5402]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5402, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 635
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 635
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([635]), 最大索引: 432, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([635, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 635
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 635
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([635]), 最大索引: 432, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([635, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2112]), 最大索引: 864, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2112, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5402
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5402
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5402]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5402, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5402
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5402
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5402]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5402, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6912], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4224], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6912], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6912], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4224], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6912], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2112], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3180
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3180
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3180]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3180, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2112], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3180
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3180
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3180]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3180, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1223]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1223, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1223]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1223, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1223]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1223, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1223]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1223, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1223]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1223, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1223]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1223, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 864], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 528], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 864], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 376
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 376
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([376]), 最大索引: 336, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([376, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 864], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 528], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 864], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 376
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 376
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([376]), 最大索引: 336, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([376, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1223]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1223, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1056], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1223
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1223]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1223, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2112], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3180
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3180
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3180]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3180, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2112], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3180
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3180
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3180]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3180, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6912], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4224], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6912], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6912], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4224], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6912], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5386
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5386
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5386]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5386, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5386
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5386
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5386]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5386, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2051, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2051, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2051, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2051, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2051, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2051, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 628
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 628
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([628]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([628, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 628
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 628
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([628]), 最大索引: 480, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([628, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2051, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2051
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2051]), 最大索引: 960, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2051, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5386
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5386
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5386]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5386, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5386
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5386
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5386]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5386, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3072], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3072], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1536], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6561
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6561
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6561]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6561, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1536], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6561
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6561
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6561]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6561, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1104], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 384], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1104], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 801
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 801
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([801]), 最大索引: 720, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([801, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1104], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 384], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1104], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 801
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 801
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([801]), 最大索引: 720, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([801, 256])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  768], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2208], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2704
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2704]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2704, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1536], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6561
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6561
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6561]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6561, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1536], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4416], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6561
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6561
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6561]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6561, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3072], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3072], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 8832], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5643
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5643
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5643]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5643, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5643
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5643
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5643]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5643, 64])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2192
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2192
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:31 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2192]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:31 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2192, 128])
2025-09-20 17:21:31 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:31 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:31 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:31 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:31 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:31 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:31 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:31 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:31 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2192
2025-09-20 17:21:31 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2192
2025-09-20 17:21:31 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:31 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2192]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2192, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2192]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2192, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2192]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2192, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2192]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2192, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2192]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2192, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 650
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 650
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([650]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([650, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 650
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 650
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([650]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([650, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2192]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2192, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2192
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2192]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2192, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5643
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5643
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5643]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5643, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5643
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5643
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5643]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5643, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3725
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3725
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3725]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3725, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3725
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3725
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3725]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3725, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1490]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1490, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1490]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1490, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1490]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1490, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1490]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1490, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1490]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1490, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1490]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1490, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 446
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 446
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([446]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([446, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 446
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 446
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([446]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([446, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1490]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1490, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1490
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1490]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1490, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3725
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3725
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3725]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3725, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3725
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3725
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3725]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3725, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4379
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4379
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4379]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4379, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4379
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4379
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4379]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4379, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1823]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1823, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1823]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1823, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1823]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1823, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1823]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1823, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1823]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1823, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1823]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1823, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 561
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 561
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([561]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([561, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 561
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 561
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([561]), 最大索引: 0, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([561, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1823]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1823, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1823
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1823]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1823, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4379
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4379
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4379]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4379, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4379
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4379
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4379]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4379, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6332
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6332
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6332]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6332, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6332
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6332
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6332]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6332, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2498]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2498, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2498]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2498, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2498]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2498, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2498]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2498, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2498]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2498, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2498]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2498, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 576], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 741
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 741
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([741]), 最大索引: 528, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([741, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 576], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 741
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 741
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([741]), 最大索引: 528, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([741, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2498]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2498, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2498
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2498]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2498, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6332
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6332
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6332]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6332, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6332
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6332
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6332]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6332, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5760], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3456], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5760, unpad长度将设为=5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5760], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5760], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3456], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5760], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2880], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1728], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2880, unpad长度将设为=2880
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2880], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3492
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3492
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3492]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3492, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2880], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1728], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2880], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3492
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3492
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3492]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3492, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1440, unpad长度将设为=1440
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1249]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1249, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1249]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1249, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1249]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1249, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1249]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1249, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1249]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1249, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1249]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1249, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 288, 720], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([288, 432], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=720, unpad长度将设为=720
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 288, 720], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(288, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数288，K=18
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 353
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 353
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([353]), 最大索引: 288, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([353, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 288, 720], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([288, 432], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 288, 720], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(288, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数288，K=18
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 353
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 353
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([353]), 最大索引: 288, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([353, 256])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1249]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1249, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 864], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1440], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1249
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1249]), 最大索引: 576, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1249, 128])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2880], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1728], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2880], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3492
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3492
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3492]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3492, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2880], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1728], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2880], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3492
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3492
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3492]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3492, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5760], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3456], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5760], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 5760], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 3456], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 5760], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:32 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:32 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:32 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:32 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:21:32 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:21:32 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:21:32 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:21:32 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:32 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:21:32 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:32 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:21:32 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6856
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6856
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6856]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6856, 64])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6856
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6856
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6856]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6856, 64])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2809]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2809, 128])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2809]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2809, 128])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2809]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2809, 128])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2809]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2809, 128])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2809]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2809, 128])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2809]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2809, 128])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:33 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 848
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 848
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([848]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([848, 256])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 848
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 848
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([848]), 最大索引: 672, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([848, 256])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2809]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2809, 128])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2809
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2809]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2809, 128])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6856
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6856
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6856]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6856, 64])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6856
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6856
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6856]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6856, 64])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:21:33 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:21:33 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:21:33 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:21:33 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:21:33 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:21:33 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:21:33 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:21:33 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:21:33 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:21:33 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:21:33 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:21:33 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:21:33 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:21:33 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
