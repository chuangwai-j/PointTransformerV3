2025-09-20 17:36:55 - wind_shear:30 - INFO - WindShearDataset train split: 8935 scenes
2025-09-20 17:36:56 - wind_shear:30 - INFO - WindShearDataset val split: 2130 scenes
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas2/vv61_labeled.csv
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn190_labeled.csv
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas2/pp16_labeled.csv
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas4/l59_labeled.csv
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] vv61_labeled.csv | 点数2713→3072（384的倍数）
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas3/u88_labeled.csv
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] l59_labeled.csv | 点数4449→4608（384的倍数）
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] nn190_labeled.csv | 点数4956→4992（384的倍数）
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n46_labeled.csv
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] pp16_labeled.csv | 点数4996→5376（384的倍数）
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m148_labeled.csv
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas2/f1 (161)_labeled.csv
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] u88_labeled.csv | 点数2990→3072（384的倍数）
2025-09-20 17:36:56 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:56 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6144
2025-09-20 17:36:56 - misc:366 - INFO -    各样本点数：[3072, 3072]（均为384的倍数）
2025-09-20 17:36:56 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6144, 3])，feat=torch.Size([6144, 9])，label=torch.Size([6144])
2025-09-20 17:36:56 - misc:368 - INFO -    Offset：[0, 3072, 6144]
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo13_labeled.csv
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] n46_labeled.csv | 点数3425→3456（384的倍数）
2025-09-20 17:36:56 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:56 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:36:56 - misc:366 - INFO -    各样本点数：[4608, 3456]（均为384的倍数）
2025-09-20 17:36:56 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:36:56 - misc:368 - INFO -    Offset：[0, 4608, 8064]
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] f1 (161)_labeled.csv | 点数3593→3840（384的倍数）
2025-09-20 17:36:56 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:56 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:36:56 - misc:366 - INFO -    各样本点数：[5376, 3840]（均为384的倍数）
2025-09-20 17:36:56 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:36:56 - misc:368 - INFO -    Offset：[0, 5376, 9216]
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] m148_labeled.csv | 点数3621→3840（384的倍数）
2025-09-20 17:36:56 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:56 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:36:56 - misc:366 - INFO -    各样本点数：[4992, 3840]（均为384的倍数）
2025-09-20 17:36:56 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:36:56 - misc:368 - INFO -    Offset：[0, 4992, 8832]
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a147_labeled.csv
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b112_labeled.csv
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas2/vv107_labeled.csv
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] oo13_labeled.csv | 点数4604→4608（384的倍数）
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y155_labeled.csv
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] vv107_labeled.csv | 点数2787→3072（384的倍数）
2025-09-20 17:36:56 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g119_labeled.csv
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] a147_labeled.csv | 点数3950→4224（384的倍数）
2025-09-20 17:36:56 - wind_shear:161 - DEBUG - [补点] b112_labeled.csv | 点数4660→4992（384的倍数）
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i54_labeled.csv
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn87_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] y155_labeled.csv | 点数3623→3840（384的倍数）
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[4608, 3840]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 4608, 8448]
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] g119_labeled.csv | 点数4263→4608（384的倍数）
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[3072, 4608]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 3072, 7680]
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y151_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] i54_labeled.csv | 点数3788→3840（384的倍数）
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] nn87_labeled.csv | 点数5637→5760（384的倍数）
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10752
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[4992, 5760]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10752, 3])，feat=torch.Size([10752, 9])，label=torch.Size([10752])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 4992, 10752]
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] y151_labeled.csv | 点数3615→3840（384的倍数）
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m123_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] m123_labeled.csv | 点数3798→3840（384的倍数）
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[3840, 3840]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 3840, 7680]
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu39_labeled.csv
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y211_labeled.csv
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas2/pp131_labeled.csv
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb2_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] uu39_labeled.csv | 点数1758→1920（384的倍数）
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc80_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] y211_labeled.csv | 点数4164→4224（384的倍数）
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa25_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] pp131_labeled.csv | 点数5109→5376（384的倍数）
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] bb2_labeled.csv | 点数5400→5760（384的倍数）
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas1/gg63_labeled.csv
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h115_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] cc80_labeled.csv | 点数4884→4992（384的倍数）
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[1920, 4992]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 1920, 6912]
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (186)_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] aa25_labeled.csv | 点数4200→4224（384的倍数）
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[4224, 4224]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 4224, 8448]
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] h115_labeled.csv | 点数3685→3840（384的倍数）
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[5376, 3840]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 5376, 9216]
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] gg63_labeled.csv | 点数4298→4608（384的倍数）
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss33_labeled.csv
2025-09-20 17:36:57 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:57 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10368
2025-09-20 17:36:57 - misc:366 - INFO -    各样本点数：[5760, 4608]（均为384的倍数）
2025-09-20 17:36:57 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10368, 3])，feat=torch.Size([10368, 9])，label=torch.Size([10368])
2025-09-20 17:36:57 - misc:368 - INFO -    Offset：[0, 5760, 10368]
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w159_labeled.csv
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o68_labeled.csv
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] eeee (186)_labeled.csv | 点数3316→3456（384的倍数）
2025-09-20 17:36:57 - wind_shear:161 - DEBUG - [补点] ss33_labeled.csv | 点数1814→1920（384的倍数）
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas2/j11_labeled.csv
2025-09-20 17:36:57 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb14_labeled.csv
2025-09-20 17:36:57 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:57 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:57 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:36:57 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:36:57 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:36:57 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:36:58 - wind_shear:161 - DEBUG - [补点] w159_labeled.csv | 点数4041→4224（384的倍数）
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas4/jj71_labeled.csv
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:36:58 - wind_shear:161 - DEBUG - [补点] j11_labeled.csv | 点数3801→3840（384的倍数）
2025-09-20 17:36:58 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:58 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:36:58 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 17:36:58 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:36:58 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 17:36:58 - wind_shear:161 - DEBUG - [补点] o68_labeled.csv | 点数4908→4992（384的倍数）
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n27_labeled.csv
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:36:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6805
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6805
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6805]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6805, 64])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6805
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6805
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6805]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6805, 64])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - wind_shear:161 - DEBUG - [补点] bb14_labeled.csv | 点数4922→4992（384的倍数）
2025-09-20 17:36:58 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:58 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:36:58 - misc:366 - INFO -    各样本点数：[1920, 4992]（均为384的倍数）
2025-09-20 17:36:58 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:36:58 - misc:368 - INFO -    Offset：[0, 1920, 6912]
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2817]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2817, 128])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2817]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2817, 128])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2817]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2817, 128])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2817]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2817, 128])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2817]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2817, 128])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2817]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2817, 128])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - wind_shear:161 - DEBUG - [补点] n27_labeled.csv | 点数3081→3456（384的倍数）
2025-09-20 17:36:58 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:58 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:36:58 - misc:366 - INFO -    各样本点数：[4992, 3456]（均为384的倍数）
2025-09-20 17:36:58 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:36:58 - misc:368 - INFO -    Offset：[0, 4992, 8448]
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:58 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:36:58 - wind_shear:161 - DEBUG - [补点] jj71_labeled.csv | 点数4669→4992（384的倍数）
2025-09-20 17:36:58 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:58 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:36:58 - misc:366 - INFO -    各样本点数：[4224, 4992]（均为384的倍数）
2025-09-20 17:36:58 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:36:58 - misc:368 - INFO -    Offset：[0, 4224, 9216]
2025-09-20 17:36:58 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=839，校正前pad范围: [0, 838]，校正后范围: [0, 838]
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 839
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 839
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([839]), 最大索引: 672, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([839, 256])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:58 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=839，校正前pad范围: [0, 838]，校正后范围: [0, 838]
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 839
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 839
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([839]), 最大索引: 672, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([839, 256])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa18_labeled.csv
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2817]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2817, 128])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2817
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2817]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2817, 128])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6805
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6805
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6805]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6805, 64])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:36:58 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6805
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6805
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6805]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6805, 64])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:36:58 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:58 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:58 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:36:58 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:58 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:36:58 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:36:58 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:36:58 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:36:58 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:36:58 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:58 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:36:58 - wind_shear:161 - DEBUG - [补点] aa18_labeled.csv | 点数3812→3840（384的倍数）
2025-09-20 17:36:58 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm49_labeled.csv
2025-09-20 17:36:58 - wind_shear:161 - DEBUG - [补点] mm49_labeled.csv | 点数3871→4224（384的倍数）
2025-09-20 17:36:58 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:58 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:36:58 - misc:366 - INFO -    各样本点数：[3840, 4224]（均为384的倍数）
2025-09-20 17:36:58 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:36:58 - misc:368 - INFO -    Offset：[0, 3840, 8064]
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3016，校正前pad范围: [0, 3015]，校正后范围: [0, 3015]
2025-09-20 17:36:59 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll40_labeled.csv
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3016
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3016
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3016]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3016, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3016，校正前pad范围: [0, 3015]，校正后范围: [0, 3015]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3016
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3016
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3016]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3016, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1222，校正前pad范围: [0, 1221]，校正后范围: [0, 1221]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1222]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1222, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1222，校正前pad范围: [0, 1221]，校正后范围: [0, 1221]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1222]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1222, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1222，校正前pad范围: [0, 1221]，校正后范围: [0, 1221]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1222]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1222, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1222，校正前pad范围: [0, 1221]，校正后范围: [0, 1221]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1222]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1222, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1222，校正前pad范围: [0, 1221]，校正后范围: [0, 1221]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1222]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1222, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1222，校正前pad范围: [0, 1221]，校正后范围: [0, 1221]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1222]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1222, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=393，校正前pad范围: [0, 392]，校正后范围: [0, 392]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 393
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 393
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([393]), 最大索引: 0, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([393, 256])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=393，校正前pad范围: [0, 392]，校正后范围: [0, 392]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 393
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 393
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([393]), 最大索引: 0, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([393, 256])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1222，校正前pad范围: [0, 1221]，校正后范围: [0, 1221]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1222]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1222, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1222，校正前pad范围: [0, 1221]，校正后范围: [0, 1221]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1222
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1222]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1222, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3016，校正前pad范围: [0, 3015]，校正后范围: [0, 3015]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3016
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3016
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3016]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3016, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3016，校正前pad范围: [0, 3015]，校正后范围: [0, 3015]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3016
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3016
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3016]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3016, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10368, unpad长度将设为=10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5184, unpad长度将设为=5184
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4783，校正前pad范围: [0, 4782]，校正后范围: [0, 4782]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4783
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4783
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4783]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4783, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4783，校正前pad范围: [0, 4782]，校正后范围: [0, 4782]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc103_labeled.csv
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4783
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4783
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4783]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4783, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2592, unpad长度将设为=2592
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2079，校正前pad范围: [0, 2078]，校正后范围: [0, 2078]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2079]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2079, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2079，校正前pad范围: [0, 2078]，校正后范围: [0, 2078]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:36:59 - wind_shear:161 - DEBUG - [补点] ll40_labeled.csv | 点数5874→6144（384的倍数）
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2079]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2079, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2079，校正前pad范围: [0, 2078]，校正后范围: [0, 2078]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2079]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2079, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2079，校正前pad范围: [0, 2078]，校正后范围: [0, 2078]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2079]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2079, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas1/period31_labeled.csv
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2079，校正前pad范围: [0, 2078]，校正后范围: [0, 2078]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2079]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2079, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2079，校正前pad范围: [0, 2078]，校正后范围: [0, 2078]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2079]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2079, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1296], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 576], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1296, unpad长度将设为=1296
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=644，校正前pad范围: [0, 643]，校正后范围: [0, 643]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1296], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 644
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 644
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([644]), 最大索引: 0, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([644, 256])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1296], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 576], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=644，校正前pad范围: [0, 643]，校正后范围: [0, 643]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1296], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 644
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 644
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([644]), 最大索引: 0, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([644, 256])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2079，校正前pad范围: [0, 2078]，校正后范围: [0, 2078]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2079]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2079, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2079，校正前pad范围: [0, 2078]，校正后范围: [0, 2078]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2592], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2079
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2079]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2079, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4783，校正前pad范围: [0, 4782]，校正后范围: [0, 4782]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4783
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4783
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4783]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4783, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4783，校正前pad范围: [0, 4782]，校正后范围: [0, 4782]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5184], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4783
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4783
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4783]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4783, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10368], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:36:59 - wind_shear:161 - DEBUG - [补点] cc103_labeled.csv | 点数3914→4224（384的倍数）
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4992], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:36:59 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee12_labeled.csv
2025-09-20 17:36:59 - wind_shear:161 - DEBUG - [补点] period31_labeled.csv | 点数3566→3840（384的倍数）
2025-09-20 17:36:59 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:59 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:36:59 - misc:366 - INFO -    各样本点数：[6144, 3840]（均为384的倍数）
2025-09-20 17:36:59 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:36:59 - misc:368 - INFO -    Offset：[0, 6144, 9984]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4992], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2496], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:36:59 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v53_labeled.csv
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3410，校正前pad范围: [0, 3409]，校正后范围: [0, 3409]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3410
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3410
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3410, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2496], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3410，校正前pad范围: [0, 3409]，校正后范围: [0, 3409]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3410
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3410
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3410, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1451，校正前pad范围: [0, 1450]，校正后范围: [0, 1450]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1451]), 最大索引: 480, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1451, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1451，校正前pad范围: [0, 1450]，校正后范围: [0, 1450]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1451]), 最大索引: 480, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1451, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1451，校正前pad范围: [0, 1450]，校正后范围: [0, 1450]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1451]), 最大索引: 480, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1451, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1451，校正前pad范围: [0, 1450]，校正后范围: [0, 1450]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1451]), 最大索引: 480, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1451, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1451，校正前pad范围: [0, 1450]，校正后范围: [0, 1450]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1451]), 最大索引: 480, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1451, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1451，校正前pad范围: [0, 1450]，校正后范围: [0, 1450]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1451]), 最大索引: 480, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1451, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 864], device='cuda:0')
2025-09-20 17:36:59 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 864]
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 624], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:36:59 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 864]
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=466，校正前pad范围: [0, 465]，校正后范围: [0, 465]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 864], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 466
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 466
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([466]), 最大索引: 240, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([466, 256])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 864], device='cuda:0')
2025-09-20 17:36:59 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 864]
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 624], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=466，校正前pad范围: [0, 465]，校正后范围: [0, 465]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 864], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 466
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 466
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([466]), 最大索引: 240, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([466, 256])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1451，校正前pad范围: [0, 1450]，校正后范围: [0, 1450]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1451]), 最大索引: 480, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1451, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1451，校正前pad范围: [0, 1450]，校正后范围: [0, 1450]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1451
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1451]), 最大索引: 480, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1451, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2496], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3410，校正前pad范围: [0, 3409]，校正后范围: [0, 3409]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3410
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3410
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3410, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2496], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3410，校正前pad范围: [0, 3409]，校正后范围: [0, 3409]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3410
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3410
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3410, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4992], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4992], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:36:59 - wind_shear:161 - DEBUG - [补点] v53_labeled.csv | 点数4434→4608（384的倍数）
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:36:59 - wind_shear:161 - DEBUG - [补点] ee12_labeled.csv | 点数5744→5760（384的倍数）
2025-09-20 17:36:59 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z66_labeled.csv
2025-09-20 17:36:59 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (180)_labeled.csv
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:36:59 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:36:59 - misc:366 - INFO -    各样本点数：[4224, 5760]（均为384的倍数）
2025-09-20 17:36:59 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:36:59 - misc:368 - INFO -    Offset：[0, 4224, 9984]
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6671
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6671
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6671]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6671, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6671
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6671
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6671]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6671, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2709]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2709, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2709]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2709, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2709]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2709, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2709]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2709, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2709]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2709, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2709]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2709, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:36:59 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=811，校正前pad范围: [0, 810]，校正后范围: [0, 810]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 811
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 811
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([811]), 最大索引: 528, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([811, 256])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:36:59 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=811，校正前pad范围: [0, 810]，校正后范围: [0, 810]
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 811
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 811
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([811]), 最大索引: 528, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([811, 256])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2709]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2709, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2709
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2709]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2709, 128])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6671
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6671
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6671]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6671, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:36:59 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6671
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6671
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6671]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6671, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:36:59 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:36:59 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:36:59 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:36:59 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:36:59 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:36:59 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:36:59 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:36:59 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:36:59 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:36:59 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:36:59 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:36:59 - wind_shear:161 - DEBUG - [补点] z66_labeled.csv | 点数3680→3840（384的倍数）
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu111_labeled.csv
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] gggg (180)_labeled.csv | 点数4371→4608（384的倍数）
2025-09-20 17:37:00 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:00 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:00 - misc:366 - INFO -    各样本点数：[4608, 4608]（均为384的倍数）
2025-09-20 17:37:00 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:00 - misc:368 - INFO -    Offset：[0, 4608, 9216]
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk171_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5132
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5132
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5132]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5132, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5132
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5132
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5132]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5132, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] uu111_labeled.csv | 点数2355→2688（384的倍数）
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:37:00 - misc:366 - INFO -    各样本点数：[3840, 2688]（均为384的倍数）
2025-09-20 17:37:00 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:37:00 - misc:368 - INFO -    Offset：[0, 3840, 6528]
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2058]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2058, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2058]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2058, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2058]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2058, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2058]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2058, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2058]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2058, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2058]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2058, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 864], device='cuda:0')
2025-09-20 17:37:00 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 864]
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 624], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:00 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 864]
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=612，校正前pad范围: [0, 611]，校正后范围: [0, 611]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 612
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 612
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([612]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([612, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 864], device='cuda:0')
2025-09-20 17:37:00 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 864]
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 624], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=612，校正前pad范围: [0, 611]，校正后范围: [0, 611]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 612
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 612
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([612]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([612, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2058]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2058, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2058
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2058]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2058, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5132
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5132
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5132]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5132, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5132
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5132
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5132]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5132, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] kk171_labeled.csv | 点数4403→4608（384的倍数）
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6115
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6115
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6115]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6115, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6115
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6115
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6115]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/q93_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6115, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2453]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2453, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2453]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2453, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas2/dd215_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2453]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2453, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2453]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2453, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2453]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2453, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2453]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2453, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 432], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=725，校正前pad范围: [0, 724]，校正后范围: [0, 724]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 725
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 725
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([725]), 最大索引: 624, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([725, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 432], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=725，校正前pad范围: [0, 724]，校正后范围: [0, 724]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 725
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 725
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([725]), 最大索引: 624, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([725, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2453]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2453, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2453
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2453]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2453, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6115
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6115
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6115]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6115, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6115
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6115
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6115]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6115, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] q93_labeled.csv | 点数3810→3840（384的倍数）
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b151_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2546，校正前pad范围: [0, 2545]，校正后范围: [0, 2545]
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu11_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2546
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2546
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2546]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2546, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2546，校正前pad范围: [0, 2545]，校正后范围: [0, 2545]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2546
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2546
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2546]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2546, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] dd215_labeled.csv | 点数5176→5376（384的倍数）
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:00 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:00 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:37:00 - misc:366 - INFO -    各样本点数：[4608, 5376]（均为384的倍数）
2025-09-20 17:37:00 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:37:00 - misc:368 - INFO -    Offset：[0, 4608, 9984]
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=994，校正前pad范围: [0, 993]，校正后范围: [0, 993]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([994]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([994, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=994，校正前pad范围: [0, 993]，校正后范围: [0, 993]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([994]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([994, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=994，校正前pad范围: [0, 993]，校正后范围: [0, 993]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([994]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([994, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=994，校正前pad范围: [0, 993]，校正后范围: [0, 993]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([994]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([994, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=994，校正前pad范围: [0, 993]，校正后范围: [0, 993]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([994]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([994, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=994，校正前pad范围: [0, 993]，校正后范围: [0, 993]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([994]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([994, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=305，校正前pad范围: [0, 304]，校正后范围: [0, 304]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 305
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 305
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([305]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([305, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=305，校正前pad范围: [0, 304]，校正后范围: [0, 304]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 305
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 305
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([305]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([305, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=994，校正前pad范围: [0, 993]，校正后范围: [0, 993]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([994]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([994, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] uu11_labeled.csv | 点数1595→1920（384的倍数）
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:00 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:00 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=5760
2025-09-20 17:37:00 - misc:366 - INFO -    各样本点数：[3840, 1920]（均为384的倍数）
2025-09-20 17:37:00 - misc:367 - INFO -    拼接后维度：coord=torch.Size([5760, 3])，feat=torch.Size([5760, 9])，label=torch.Size([5760])
2025-09-20 17:37:00 - misc:368 - INFO -    Offset：[0, 3840, 5760]
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=994，校正前pad范围: [0, 993]，校正后范围: [0, 993]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 994
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([994]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([994, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2546，校正前pad范围: [0, 2545]，校正后范围: [0, 2545]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2546
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2546
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2546]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2546, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2546，校正前pad范围: [0, 2545]，校正后范围: [0, 2545]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2546
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2546
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2546]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2546, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] b151_labeled.csv | 点数4571→4608（384的倍数）
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2863，校正前pad范围: [0, 2862]，校正后范围: [0, 2862]
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m22_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2863，校正前pad范围: [0, 2862]，校正后范围: [0, 2862]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1148，校正前pad范围: [0, 1147]，校正后范围: [0, 1147]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1148]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1148, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1148，校正前pad范围: [0, 1147]，校正后范围: [0, 1147]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1148]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1148, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1148，校正前pad范围: [0, 1147]，校正后范围: [0, 1147]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (48)_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1148]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1148, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1148，校正前pad范围: [0, 1147]，校正后范围: [0, 1147]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1148]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1148, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1148，校正前pad范围: [0, 1147]，校正后范围: [0, 1147]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1148]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1148, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1148，校正前pad范围: [0, 1147]，校正后范围: [0, 1147]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1148]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1148, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=355，校正前pad范围: [0, 354]，校正后范围: [0, 354]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 355
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 355
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([355]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([355, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=355，校正前pad范围: [0, 354]，校正后范围: [0, 354]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 355
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 355
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([355]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([355, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1148，校正前pad范围: [0, 1147]，校正后范围: [0, 1147]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1148]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1148, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1148，校正前pad范围: [0, 1147]，校正后范围: [0, 1147]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1148
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1148]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1148, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2863，校正前pad范围: [0, 2862]，校正后范围: [0, 2862]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2863，校正前pad范围: [0, 2862]，校正后范围: [0, 2862]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2863
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2863
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2863]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2863, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] m22_labeled.csv | 点数3923→4224（384的倍数）
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9984], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3840], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9984], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9984], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3840], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9984], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o105_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh46_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1920], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7467
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7467
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7467]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7467, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1920], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7467
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7467
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7467]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7467, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3135]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3135, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] eeee (48)_labeled.csv | 点数4040→4224（384的倍数）
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:00 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:00 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:00 - misc:366 - INFO -    各样本点数：[4608, 4224]（均为384的倍数）
2025-09-20 17:37:00 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:00 - misc:368 - INFO -    Offset：[0, 4608, 8832]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3135]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3135, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3135]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3135, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3135]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3135, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3135]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3135, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3135]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3135, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 480], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=957，校正前pad范围: [0, 956]，校正后范围: [0, 956]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 957
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 957
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([957]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([957, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 480], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:00 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=957，校正前pad范围: [0, 956]，校正后范围: [0, 956]
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1248], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 957
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 957
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([957]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([957, 256])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3135]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3135, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  960], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2496], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3135
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3135]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3135, 128])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1920], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7467
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7467
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7467]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7467, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1920], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:00 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4992], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7467
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7467
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7467]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7467, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9984], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3840], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9984], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:00 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9984], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3840], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:00 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:00 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9984], device='cuda:0')
2025-09-20 17:37:00 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:37:00 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:00 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:00 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:37:00 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:00 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] hh46_labeled.csv | 点数3746→3840（384的倍数）
2025-09-20 17:37:00 - wind_shear:161 - DEBUG - [补点] o105_labeled.csv | 点数5095→5376（384的倍数）
2025-09-20 17:37:00 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:00 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:37:00 - misc:366 - INFO -    各样本点数：[4224, 5376]（均为384的倍数）
2025-09-20 17:37:00 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:37:00 - misc:368 - INFO -    Offset：[0, 4224, 9600]
2025-09-20 17:37:00 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(187)_labeled.csv
2025-09-20 17:37:00 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:00 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas3/ii103_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7610
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7610
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7610]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7610, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7610
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7610
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7610]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7610, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3295, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3295, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3295, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3295, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3295, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3295, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1248], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 720], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1248], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1248], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 720], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1011，校正前pad范围: [0, 1010]，校正后范围: [0, 1010]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1248], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1011
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1011
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1011]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1011, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3295, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3295
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3295, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7610
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7610
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7610]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7610, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7610
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7610
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7610]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7610, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] bbbbb(187)_labeled.csv | 点数3137→3456（384的倍数）
2025-09-20 17:37:01 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:01 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:37:01 - misc:366 - INFO -    各样本点数：[3840, 3456]（均为384的倍数）
2025-09-20 17:37:01 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:37:01 - misc:368 - INFO -    Offset：[0, 3840, 7296]
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] ii103_labeled.csv | 点数4785→4992（384的倍数）
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk52_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n70_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3974，校正前pad范围: [0, 3973]，校正后范围: [0, 3973]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3974
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3974
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3974]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3974, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3974，校正前pad范围: [0, 3973]，校正后范围: [0, 3973]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3974
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3974
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3974]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3974, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1618，校正前pad范围: [0, 1617]，校正后范围: [0, 1617]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1618]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1618, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1618，校正前pad范围: [0, 1617]，校正后范围: [0, 1617]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1618]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1618, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1618，校正前pad范围: [0, 1617]，校正后范围: [0, 1617]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1618]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1618, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1618，校正前pad范围: [0, 1617]，校正后范围: [0, 1617]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1618]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1618, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1618，校正前pad范围: [0, 1617]，校正后范围: [0, 1617]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1618]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1618, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1618，校正前pad范围: [0, 1617]，校正后范围: [0, 1617]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1618]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1618, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=494，校正前pad范围: [0, 493]，校正后范围: [0, 493]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 494
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 494
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([494]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([494, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=494，校正前pad范围: [0, 493]，校正后范围: [0, 493]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 494
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 494
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([494]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([494, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1618，校正前pad范围: [0, 1617]，校正后范围: [0, 1617]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1618]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1618, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1618，校正前pad范围: [0, 1617]，校正后范围: [0, 1617]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1618
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1618]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1618, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3974，校正前pad范围: [0, 3973]，校正后范围: [0, 3973]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3974
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3974
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3974]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3974, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3974，校正前pad范围: [0, 3973]，校正后范围: [0, 3973]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3974
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3974
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3974]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3974, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] n70_labeled.csv | 点数3198→3456（384的倍数）
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa31_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2688], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2688], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v71_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4351
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4351
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4351]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4351, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4351
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4351
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4351]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4351, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] kk52_labeled.csv | 点数4789→4992（384的倍数）
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:01 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:01 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:37:01 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 17:37:01 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:37:01 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 816], device='cuda:0')
2025-09-20 17:37:01 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 480, 816]
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 336], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:01 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 480, 816]
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=460，校正前pad范围: [0, 459]，校正后范围: [0, 459]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 816], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 460
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 460
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([460]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([460, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 816], device='cuda:0')
2025-09-20 17:37:01 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 480, 816]
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 336], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=460，校正前pad范围: [0, 459]，校正后范围: [0, 459]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 816], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 460
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 460
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([460]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([460, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1557，校正前pad范围: [0, 1556]，校正后范围: [0, 1556]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1557
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1557, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4351
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4351
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4351]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4351, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4351
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4351
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4351]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4351, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] aa31_labeled.csv | 点数4399→4608（384的倍数）
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:01 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:01 - misc:366 - INFO -    各样本点数：[3456, 4608]（均为384的倍数）
2025-09-20 17:37:01 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:01 - misc:368 - INFO -    Offset：[0, 3456, 8064]
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2688], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2688], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] v71_labeled.csv | 点数3021→3072（384的倍数）
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g85_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/q5_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7491
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7491
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7491]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7491, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7491
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7491
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7491]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7491, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=937，校正前pad范围: [0, 936]，校正后范围: [0, 936]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 937
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 937
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([937]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([937, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 672], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=937，校正前pad范围: [0, 936]，校正后范围: [0, 936]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 937
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 937
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([937]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([937, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] g85_labeled.csv | 点数3989→4224（384的倍数）
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:01 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:37:01 - misc:366 - INFO -    各样本点数：[3072, 4224]（均为384的倍数）
2025-09-20 17:37:01 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:37:01 - misc:368 - INFO -    Offset：[0, 3072, 7296]
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] q5_labeled.csv | 点数2492→2688（384的倍数）
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7491
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7491
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7491]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7491, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:01 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7491
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7491
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7491]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7491, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas2/pp55_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 1920], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5760, unpad长度将设为=5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=960
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/q62_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 1920], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=960
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920,  960], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2880, unpad长度将设为=2880
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2541，校正前pad范围: [0, 2540]，校正后范围: [0, 2540]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2541
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2541
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2541]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2541, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920,  960], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2541，校正前pad范围: [0, 2540]，校正后范围: [0, 2540]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2541
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2541
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2541]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2541, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 480], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1440, unpad长度将设为=1440
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=964，校正前pad范围: [0, 963]，校正后范围: [0, 963]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([964]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([964, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 480], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=964，校正前pad范围: [0, 963]，校正后范围: [0, 963]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([964]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([964, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 480], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=964，校正前pad范围: [0, 963]，校正后范围: [0, 963]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([964]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([964, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 480], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=964，校正前pad范围: [0, 963]，校正后范围: [0, 963]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([964]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([964, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 480], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=964，校正前pad范围: [0, 963]，校正后范围: [0, 963]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([964]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([964, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 480], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=964，校正前pad范围: [0, 963]，校正后范围: [0, 963]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([964]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([964, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 720], device='cuda:0')
2025-09-20 17:37:01 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 480, 720]
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 240], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:01 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 480, 720]
2025-09-20 17:37:01 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=720, unpad长度将设为=720
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=304，校正前pad范围: [0, 303]，校正后范围: [0, 303]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 720], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(240, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数240，K=15
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 304
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 304
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([304]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([304, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 720], device='cuda:0')
2025-09-20 17:37:01 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 480, 720]
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 240], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=304，校正前pad范围: [0, 303]，校正后范围: [0, 303]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 720], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(240, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数240，K=15
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 304
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 304
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([304]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([304, 256])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 480], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=964，校正前pad范围: [0, 963]，校正后范围: [0, 963]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] q62_labeled.csv | 点数1762→1920（384的倍数）
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([964]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([964, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 480], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=964，校正前pad范围: [0, 963]，校正后范围: [0, 963]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1440], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 964
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([964]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([964, 128])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920,  960], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2541，校正前pad范围: [0, 2540]，校正后范围: [0, 2540]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2541
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2541
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2541]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2541, 64])
2025-09-20 17:37:01 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb81_labeled.csv
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920,  960], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:01 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2541，校正前pad范围: [0, 2540]，校正后范围: [0, 2540]
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 2880], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2541
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2541
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2541]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2541, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 1920], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:37:01 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:01 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:01 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 1920], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:01 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:01 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 5760], device='cuda:0')
2025-09-20 17:37:01 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:01 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:01 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:37:01 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:01 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:01 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:37:01 - wind_shear:161 - DEBUG - [补点] pp55_labeled.csv | 点数5695→5760（384的倍数）
2025-09-20 17:37:01 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:01 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:01 - misc:366 - INFO -    各样本点数：[2688, 5760]（均为384的倍数）
2025-09-20 17:37:01 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:01 - misc:368 - INFO -    Offset：[0, 2688, 8448]
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6545
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6545
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6545]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6545, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6545
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6545
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6545]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6545, 64])
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss65_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2632]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2632, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2632]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2632, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2632]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2632, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2632]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2632, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2632]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2632, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2632]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2632, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 528], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=787，校正前pad范围: [0, 786]，校正后范围: [0, 786]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 787
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 787
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([787]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([787, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 528], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=787，校正前pad范围: [0, 786]，校正后范围: [0, 786]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 787
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 787
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([787]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([787, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2632]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2632, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - wind_shear:161 - DEBUG - [补点] bb81_labeled.csv | 点数4436→4608（384的倍数）
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:02 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:02 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:37:02 - misc:366 - INFO -    各样本点数：[1920, 4608]（均为384的倍数）
2025-09-20 17:37:02 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:37:02 - misc:368 - INFO -    Offset：[0, 1920, 6528]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2632
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2632]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2632, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6545
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6545
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6545]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6545, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6545
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6545
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6545]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6545, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:02 - wind_shear:161 - DEBUG - [补点] ss65_labeled.csv | 点数2733→3072（384的倍数）
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x143_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9600], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5376], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn31_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9600], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9600], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5376], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9600], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4800], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2688], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4800], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6969
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6969
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6969]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6969, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4800], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2688], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4800], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6969
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6969
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6969]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6969, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1344], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2869]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2869, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1344], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2869]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2869, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1344], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2869]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2869, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1344], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2869]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2869, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1344], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2869]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2869, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1344], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2869]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2869, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1200], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 672], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1200], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1200], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 672], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1200], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1344], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2869]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2869, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1344], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2400], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2869
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2869]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2869, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4800], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2688], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4800], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6969
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6969
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6969]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6969, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4800], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2688], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:02 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4800], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6969
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6969
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6969]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6969, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9600], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5376], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9600], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9600], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5376], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9600], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:02 - wind_shear:161 - DEBUG - [补点] x143_labeled.csv | 点数4108→4224（384的倍数）
2025-09-20 17:37:02 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:02 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:37:02 - misc:366 - INFO -    各样本点数：[3072, 4224]（均为384的倍数）
2025-09-20 17:37:02 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:37:02 - misc:368 - INFO -    Offset：[0, 3072, 7296]
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:02 - wind_shear:161 - DEBUG - [补点] nn31_labeled.csv | 点数5649→5760（384的倍数）
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo43_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2523，校正前pad范围: [0, 2522]，校正后范围: [0, 2522]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2523
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2523
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2523]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2523, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2523，校正前pad范围: [0, 2522]，校正后范围: [0, 2522]
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h117_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2523
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2523
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2523]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2523, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=968，校正前pad范围: [0, 967]，校正后范围: [0, 967]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([968]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([968, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=968，校正前pad范围: [0, 967]，校正后范围: [0, 967]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([968]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([968, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=968，校正前pad范围: [0, 967]，校正后范围: [0, 967]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([968]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([968, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=968，校正前pad范围: [0, 967]，校正后范围: [0, 967]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([968]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([968, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=968，校正前pad范围: [0, 967]，校正后范围: [0, 967]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([968]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([968, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=968，校正前pad范围: [0, 967]，校正后范围: [0, 967]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([968]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([968, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 432], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=314，校正前pad范围: [0, 313]，校正后范围: [0, 313]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 314
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 314
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([314]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([314, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 432], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=314，校正前pad范围: [0, 313]，校正后范围: [0, 313]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 912], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 314
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 314
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([314]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([314, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=968，校正前pad范围: [0, 967]，校正后范围: [0, 967]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([968]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([968, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 864], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=968，校正前pad范围: [0, 967]，校正后范围: [0, 967]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1824], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 968
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([968]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([968, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2523，校正前pad范围: [0, 2522]，校正后范围: [0, 2522]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2523
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2523
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2523]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2523, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1728], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2523，校正前pad范围: [0, 2522]，校正后范围: [0, 2522]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3648], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2523
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2523
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2523]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2523, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3456], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7296], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:02 - wind_shear:161 - DEBUG - [补点] oo43_labeled.csv | 点数4238→4608（384的倍数）
2025-09-20 17:37:02 - wind_shear:161 - DEBUG - [补点] h117_labeled.csv | 点数3744→3840（384的倍数）
2025-09-20 17:37:02 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:02 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:37:02 - misc:366 - INFO -    各样本点数：[5760, 3840]（均为384的倍数）
2025-09-20 17:37:02 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:37:02 - misc:368 - INFO -    Offset：[0, 5760, 9600]
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk86_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb148_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3529，校正前pad范围: [0, 3528]，校正后范围: [0, 3528]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3529，校正前pad范围: [0, 3528]，校正后范围: [0, 3528]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1526，校正前pad范围: [0, 1525]，校正后范围: [0, 1525]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1526]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1526, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1526，校正前pad范围: [0, 1525]，校正后范围: [0, 1525]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1526]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1526, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1526，校正前pad范围: [0, 1525]，校正后范围: [0, 1525]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1526]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1526, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1526，校正前pad范围: [0, 1525]，校正后范围: [0, 1525]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1526]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1526, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1526，校正前pad范围: [0, 1525]，校正后范围: [0, 1525]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1526]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1526, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1526，校正前pad范围: [0, 1525]，校正后范围: [0, 1525]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1526]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1526, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=492，校正前pad范围: [0, 491]，校正后范围: [0, 491]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 492
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 492
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([492]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([492, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=492，校正前pad范围: [0, 491]，校正后范围: [0, 491]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 492
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 492
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([492]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([492, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1526，校正前pad范围: [0, 1525]，校正后范围: [0, 1525]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1526]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1526, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1526，校正前pad范围: [0, 1525]，校正后范围: [0, 1525]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1526
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1526]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1526, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3529，校正前pad范围: [0, 3528]，校正后范围: [0, 3528]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3529，校正前pad范围: [0, 3528]，校正后范围: [0, 3528]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3529
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3529
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3529]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3529, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:02 - wind_shear:161 - DEBUG - [补点] kk86_labeled.csv | 点数4688→4992（384的倍数）
2025-09-20 17:37:02 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:02 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:37:02 - misc:366 - INFO -    各样本点数：[4608, 4992]（均为384的倍数）
2025-09-20 17:37:02 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:37:02 - misc:368 - INFO -    Offset：[0, 4608, 9600]
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4608], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4608], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2304], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas2/t30_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3062，校正前pad范围: [0, 3061]，校正后范围: [0, 3061]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3062
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3062
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3062]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3062, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2304], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3062，校正前pad范围: [0, 3061]，校正后范围: [0, 3061]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3062
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3062
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3062]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3062, 64])
2025-09-20 17:37:02 - wind_shear:161 - DEBUG - [补点] bb148_labeled.csv | 点数4486→4608（384的倍数）
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1236，校正前pad范围: [0, 1235]，校正后范围: [0, 1235]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1236]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1236, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1236，校正前pad范围: [0, 1235]，校正后范围: [0, 1235]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1236]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1236, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1236，校正前pad范围: [0, 1235]，校正后范围: [0, 1235]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1236]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1236, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss149_labeled.csv
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1236，校正前pad范围: [0, 1235]，校正后范围: [0, 1235]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1236]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1236, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1236，校正前pad范围: [0, 1235]，校正后范围: [0, 1235]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1236]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1236, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1236，校正前pad范围: [0, 1235]，校正后范围: [0, 1235]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1236]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1236, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  432, 1008], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 576], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:02 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=396，校正前pad范围: [0, 395]，校正后范围: [0, 395]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  432, 1008], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 396
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 396
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([396]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([396, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  432, 1008], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 576], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=396，校正前pad范围: [0, 395]，校正后范围: [0, 395]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  432, 1008], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 396
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 396
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([396]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([396, 256])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1236，校正前pad范围: [0, 1235]，校正后范围: [0, 1235]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1236]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1236, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1152], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1236，校正前pad范围: [0, 1235]，校正后范围: [0, 1235]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 2016], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1236
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1236]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1236, 128])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2304], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3062，校正前pad范围: [0, 3061]，校正后范围: [0, 3061]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3062
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3062
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3062]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3062, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2304], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:02 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3062，校正前pad范围: [0, 3061]，校正后范围: [0, 3061]
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 4032], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3062
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3062
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:02 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3062]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:02 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3062, 64])
2025-09-20 17:37:02 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:02 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:02 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4608], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:02 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:02 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:02 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 17:37:02 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:02 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:02 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:02 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4608], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 8064], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] t30_labeled.csv | 点数4345→4608（384的倍数）
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (209)_labeled.csv
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o60_labeled.csv
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] ss149_labeled.csv | 点数3537→3840（384的倍数）
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:37:03 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:03 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:03 - misc:366 - INFO -    各样本点数：[4608, 3840]（均为384的倍数）
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:03 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:03 - misc:368 - INFO -    Offset：[0, 4608, 8448]
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3361，校正前pad范围: [0, 3360]，校正后范围: [0, 3360]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3361
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3361
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3361]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3361, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3361，校正前pad范围: [0, 3360]，校正后范围: [0, 3360]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3361
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3361
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3361]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3361, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1312，校正前pad范围: [0, 1311]，校正后范围: [0, 1311]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1312]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1312, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1312，校正前pad范围: [0, 1311]，校正后范围: [0, 1311]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1312]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1312, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1312，校正前pad范围: [0, 1311]，校正后范围: [0, 1311]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1312]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1312, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1312，校正前pad范围: [0, 1311]，校正后范围: [0, 1311]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1312]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1312, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1312，校正前pad范围: [0, 1311]，校正后范围: [0, 1311]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1312]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1312, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1312，校正前pad范围: [0, 1311]，校正后范围: [0, 1311]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1312]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1312, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=400，校正前pad范围: [0, 399]，校正后范围: [0, 399]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 400
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 400
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([400]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([400, 256])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=400，校正前pad范围: [0, 399]，校正后范围: [0, 399]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 400
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 400
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([400]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([400, 256])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1312，校正前pad范围: [0, 1311]，校正后范围: [0, 1311]
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] gggg (209)_labeled.csv | 点数3317→3456（384的倍数）
2025-09-20 17:37:03 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:03 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:03 - misc:366 - INFO -    各样本点数：[4608, 3456]（均为384的倍数）
2025-09-20 17:37:03 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:03 - misc:368 - INFO -    Offset：[0, 4608, 8064]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1312]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1312, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1312，校正前pad范围: [0, 1311]，校正后范围: [0, 1311]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1312
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1312]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1312, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3361，校正前pad范围: [0, 3360]，校正后范围: [0, 3360]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3361
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3361
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3361]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3361, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3361，校正前pad范围: [0, 3360]，校正后范围: [0, 3360]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3361
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3361
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3361]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3361, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] o60_labeled.csv | 点数4820→4992（384的倍数）
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i84_labeled.csv
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 8448], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 5760], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 8448], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 8448], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 5760], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 8448], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas1/e160_labeled.csv
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2880], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6387
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6387
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6387]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6387, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2880], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6387
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6387
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6387]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6387, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1440], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2711]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2711, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1440], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2711]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2711, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1440], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2711]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2711, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1440], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2711]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2711, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1440], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2711]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2711, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1440], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2711]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2711, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  336, 1056], device='cuda:0')
2025-09-20 17:37:03 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 1056]
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 720], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:03 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 1056]
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=801，校正前pad范围: [0, 800]，校正后范围: [0, 800]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  336, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 801
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 801
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([801]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([801, 256])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  336, 1056], device='cuda:0')
2025-09-20 17:37:03 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 1056]
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 720], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=801，校正前pad范围: [0, 800]，校正后范围: [0, 800]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  336, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 801
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 801
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([801]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([801, 256])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1440], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2711]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2711, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1440], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2711
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2711]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2711, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2880], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6387
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6387
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6387]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6387, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2880], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6387
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6387
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6387]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6387, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 8448], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 5760], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 8448], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 8448], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 5760], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 8448], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] i84_labeled.csv | 点数4729→4992（384的倍数）
2025-09-20 17:37:03 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:03 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:37:03 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 17:37:03 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:37:03 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4608], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] e160_labeled.csv | 点数4352→4608（384的倍数）
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4608], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt76_labeled.csv
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee186_labeled.csv
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2304], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4629
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4629
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4629]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4629, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2304], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4629
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4629
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4629]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4629, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1788]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1788, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1788]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1788, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1788]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1788, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1788]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1788, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1788]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1788, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1788]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1788, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 816], device='cuda:0')
2025-09-20 17:37:03 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 816]
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 576], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:03 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 816]
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=509，校正前pad范围: [0, 508]，校正后范围: [0, 508]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 816], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 509
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 509
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([509]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([509, 256])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 816], device='cuda:0')
2025-09-20 17:37:03 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 816]
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 576], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=509，校正前pad范围: [0, 508]，校正后范围: [0, 508]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 816], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 509
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 509
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([509]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([509, 256])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1788]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1788, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1788
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1788]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1788, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2304], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4629
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4629
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4629]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4629, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2304], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4629
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4629
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4629]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4629, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4608], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4608], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] tt76_labeled.csv | 点数3441→3456（384的倍数）
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm118_labeled.csv
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] ee186_labeled.csv | 点数4252→4608（384的倍数）
2025-09-20 17:37:03 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:03 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:03 - misc:366 - INFO -    各样本点数：[4608, 4608]（均为384的倍数）
2025-09-20 17:37:03 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:03 - misc:368 - INFO -    Offset：[0, 4608, 9216]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc191_labeled.csv
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5052
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5052
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5052]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5052, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5052
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5052
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5052]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5052, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1872]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1872, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1872]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1872, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1872]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1872, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1872]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1872, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1872]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1872, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1872]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1872, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=555，校正前pad范围: [0, 554]，校正后范围: [0, 554]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 555
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 555
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([555]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([555, 256])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 528], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:03 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=555，校正前pad范围: [0, 554]，校正后范围: [0, 554]
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 555
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 555
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([555]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([555, 256])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1872]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1872, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1872
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1872]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1872, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5052
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5052
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5052]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5052, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5052
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5052
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5052]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5052, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] mm118_labeled.csv | 点数3820→3840（384的倍数）
2025-09-20 17:37:03 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:03 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:37:03 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 17:37:03 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:37:03 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 17:37:03 - wind_shear:161 - DEBUG - [补点] cc191_labeled.csv | 点数3635→3840（384的倍数）
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (40)_labeled.csv
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu85_labeled.csv
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7377
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7377
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7377]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7377, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7377
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7377
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7377]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7377, 64])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3155]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3155, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3155]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3155, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3155]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3155, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3155]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3155, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:03 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:03 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3155
2025-09-20 17:37:03 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:03 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:03 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3155]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:03 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3155, 128])
2025-09-20 17:37:03 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:03 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:03 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:03 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:03 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:03 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:03 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:03 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3155
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3155
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3155]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3155, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 480], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=956，校正前pad范围: [0, 955]，校正后范围: [0, 955]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 956
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 956
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([956]), 最大索引: 720, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([956, 256])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 480], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=956，校正前pad范围: [0, 955]，校正后范围: [0, 955]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 956
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 956
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([956]), 最大索引: 720, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([956, 256])
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] uu85_labeled.csv | 点数2335→2688（384的倍数）
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3155
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3155
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3155]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3155, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3155
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3155
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3155]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3155, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7377
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7377
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7377]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7377, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7377
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7377
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7377]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7377, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z212_labeled.csv
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] eeee (40)_labeled.csv | 点数4253→4608（384的倍数）
2025-09-20 17:37:04 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:04 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:04 - misc:366 - INFO -    各样本点数：[3840, 4608]（均为384的倍数）
2025-09-20 17:37:04 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:04 - misc:368 - INFO -    Offset：[0, 3840, 8448]
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3330，校正前pad范围: [0, 3329]，校正后范围: [0, 3329]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt125_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3330
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3330
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3330]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3330, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3330，校正前pad范围: [0, 3329]，校正后范围: [0, 3329]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3330
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3330
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3330]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3330, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1422，校正前pad范围: [0, 1421]，校正后范围: [0, 1421]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1422]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1422, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1422，校正前pad范围: [0, 1421]，校正后范围: [0, 1421]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1422]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1422, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1422，校正前pad范围: [0, 1421]，校正后范围: [0, 1421]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1422]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1422, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1422，校正前pad范围: [0, 1421]，校正后范围: [0, 1421]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1422]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1422, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1422，校正前pad范围: [0, 1421]，校正后范围: [0, 1421]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1422]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1422, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1422，校正前pad范围: [0, 1421]，校正后范围: [0, 1421]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1422]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1422, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=457，校正前pad范围: [0, 456]，校正后范围: [0, 456]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 457
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 457
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([457]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([457, 256])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=457，校正前pad范围: [0, 456]，校正后范围: [0, 456]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 457
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 457
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([457]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([457, 256])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1422，校正前pad范围: [0, 1421]，校正后范围: [0, 1421]
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] z212_labeled.csv | 点数4641→4992（384的倍数）
2025-09-20 17:37:04 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:04 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:37:04 - misc:366 - INFO -    各样本点数：[2688, 4992]（均为384的倍数）
2025-09-20 17:37:04 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - misc:368 - INFO -    Offset：[0, 2688, 7680]
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1422]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1422, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1422，校正前pad范围: [0, 1421]，校正后范围: [0, 1421]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1422
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1422]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1422, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3330，校正前pad范围: [0, 3329]，校正后范围: [0, 3329]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3330
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3330
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3330]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3330, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3330，校正前pad范围: [0, 3329]，校正后范围: [0, 3329]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3330
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3330
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3330]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3330, 64])
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] tt125_labeled.csv | 点数2529→2688（384的倍数）
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o120_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas2/aaaa (37)_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6067
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6067
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6067]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6067, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6067
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6067
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6067]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6067, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2351]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2351, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2351]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2351, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2351]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2351, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2351]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2351, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2351]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2351, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2351]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2351, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 480], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=687，校正前pad范围: [0, 686]，校正后范围: [0, 686]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 687
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 687
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([687]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([687, 256])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 480], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=687，校正前pad范围: [0, 686]，校正后范围: [0, 686]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 687
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 687
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([687]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([687, 256])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2351]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2351, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2351
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2351]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2351, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6067
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6067
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6067]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6067, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6067
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6067
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6067]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6067, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] o120_labeled.csv | 点数4606→4608（384的倍数）
2025-09-20 17:37:04 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:04 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:37:04 - misc:366 - INFO -    各样本点数：[2688, 4608]（均为384的倍数）
2025-09-20 17:37:04 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:37:04 - misc:368 - INFO -    Offset：[0, 2688, 7296]
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] aaaa (37)_labeled.csv | 点数4176→4224（384的倍数）
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas2/f1 (191)_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas2/dd128_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5552
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5552
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5552]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5552, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5552
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5552
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5552]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5552, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2107]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2107, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2107]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2107, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2107]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2107, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2107]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2107, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2107]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2107, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2107]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2107, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=618，校正前pad范围: [0, 617]，校正后范围: [0, 617]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 618
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 618
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([618]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([618, 256])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=618，校正前pad范围: [0, 617]，校正后范围: [0, 617]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 618
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 618
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([618]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([618, 256])
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] f1 (191)_labeled.csv | 点数2781→3072（384的倍数）
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:04 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:37:04 - misc:366 - INFO -    各样本点数：[4224, 3072]（均为384的倍数）
2025-09-20 17:37:04 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:37:04 - misc:368 - INFO -    Offset：[0, 4224, 7296]
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2107]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2107, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2107
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2107]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2107, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5552
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5552
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5552]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5552, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:04 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5552
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5552
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5552]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5552, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] dd128_labeled.csv | 点数4418→4608（384的倍数）
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (22)_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt65_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4339，校正前pad范围: [0, 4338]，校正后范围: [0, 4338]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4339
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4339
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4339]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4339, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4339，校正前pad范围: [0, 4338]，校正后范围: [0, 4338]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4339
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4339
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4339]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4339, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1797，校正前pad范围: [0, 1796]，校正后范围: [0, 1796]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1797]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1797, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1797，校正前pad范围: [0, 1796]，校正后范围: [0, 1796]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1797]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1797, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1797，校正前pad范围: [0, 1796]，校正后范围: [0, 1796]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1797]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1797, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1797，校正前pad范围: [0, 1796]，校正后范围: [0, 1796]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1797]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1797, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1797，校正前pad范围: [0, 1796]，校正后范围: [0, 1796]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1797]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1797, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1797，校正前pad范围: [0, 1796]，校正后范围: [0, 1796]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1797]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1797, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=541，校正前pad范围: [0, 540]，校正后范围: [0, 540]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 541
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 541
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([541]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([541, 256])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=541，校正前pad范围: [0, 540]，校正后范围: [0, 540]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 541
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 541
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([541]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([541, 256])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1797，校正前pad范围: [0, 1796]，校正后范围: [0, 1796]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1797]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1797, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1797，校正前pad范围: [0, 1796]，校正后范围: [0, 1796]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1797
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1797]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1797, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4339，校正前pad范围: [0, 4338]，校正后范围: [0, 4338]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4339
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4339
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4339]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4339, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4339，校正前pad范围: [0, 4338]，校正后范围: [0, 4338]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4339
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4339
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4339]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4339, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] tt65_labeled.csv | 点数2878→3072（384的倍数）
2025-09-20 17:37:04 - wind_shear:161 - DEBUG - [补点] eeee (22)_labeled.csv | 点数3876→4224（384的倍数）
2025-09-20 17:37:04 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:04 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:04 - misc:366 - INFO -    各样本点数：[4608, 4224]（均为384的倍数）
2025-09-20 17:37:04 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:04 - misc:368 - INFO -    Offset：[0, 4608, 8832]
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h139_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:04 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas1/period26_labeled.csv
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3865，校正前pad范围: [0, 3864]，校正后范围: [0, 3864]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3865
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3865
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3865]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3865, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3865，校正前pad范围: [0, 3864]，校正后范围: [0, 3864]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3865
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3865
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3865]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3865, 64])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1548，校正前pad范围: [0, 1547]，校正后范围: [0, 1547]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1548]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1548, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1548，校正前pad范围: [0, 1547]，校正后范围: [0, 1547]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1548]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1548, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1548，校正前pad范围: [0, 1547]，校正后范围: [0, 1547]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1548]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1548, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1548，校正前pad范围: [0, 1547]，校正后范围: [0, 1547]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1548]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1548, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1548，校正前pad范围: [0, 1547]，校正后范围: [0, 1547]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1548]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1548, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1548，校正前pad范围: [0, 1547]，校正后范围: [0, 1547]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:04 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1548
2025-09-20 17:37:04 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:04 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:04 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1548]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:04 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1548, 128])
2025-09-20 17:37:04 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:04 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:04 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:04 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:04 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=480，校正前pad范围: [0, 479]，校正后范围: [0, 479]
2025-09-20 17:37:04 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:04 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:04 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:04 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:04 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 480
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 480
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([480]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([480, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=480，校正前pad范围: [0, 479]，校正后范围: [0, 479]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 480
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 480
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([480]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([480, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1548，校正前pad范围: [0, 1547]，校正后范围: [0, 1547]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1548
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1548
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1548]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1548, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1548，校正前pad范围: [0, 1547]，校正后范围: [0, 1547]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1548
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1548
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1548]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1548, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3865，校正前pad范围: [0, 3864]，校正后范围: [0, 3864]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3865
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3865
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3865]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3865, 64])
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] h139_labeled.csv | 点数3683→3840（384的倍数）
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:05 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:37:05 - misc:366 - INFO -    各样本点数：[3072, 3840]（均为384的倍数）
2025-09-20 17:37:05 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:37:05 - misc:368 - INFO -    Offset：[0, 3072, 6912]
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3865，校正前pad范围: [0, 3864]，校正后范围: [0, 3864]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3865
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3865
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3865]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3865, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] period26_labeled.csv | 点数3584→3840（384的倍数）
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas4/jj1_labeled.csv
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(51)_labeled.csv
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5266
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5266
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5266]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5266, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5266
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5266
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5266]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5266, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1998]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1998, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1998]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1998, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1998]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1998, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1998]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1998, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1998]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1998, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1998]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1998, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=589，校正前pad范围: [0, 588]，校正后范围: [0, 588]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 589
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 589
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([589]), 最大索引: 432, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([589, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=589，校正前pad范围: [0, 588]，校正后范围: [0, 588]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 589
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 589
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([589]), 最大索引: 432, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([589, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1998]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1998, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1998
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1998]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1998, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] jj1_labeled.csv | 点数2905→3072（384的倍数）
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:05 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:05 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:37:05 - misc:366 - INFO -    各样本点数：[3840, 3072]（均为384的倍数）
2025-09-20 17:37:05 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:37:05 - misc:368 - INFO -    Offset：[0, 3840, 6912]
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5266
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5266
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5266]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5266, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5266
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5266
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5266]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5266, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] bbbbb(51)_labeled.csv | 点数3866→4224（384的倍数）
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas2/f1 (39)_labeled.csv
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d73_labeled.csv
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2902，校正前pad范围: [0, 2901]，校正后范围: [0, 2901]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2902
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2902
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2902]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2902, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2902，校正前pad范围: [0, 2901]，校正后范围: [0, 2901]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2902
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2902
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2902]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2902, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1161，校正前pad范围: [0, 1160]，校正后范围: [0, 1160]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1161]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1161, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1161，校正前pad范围: [0, 1160]，校正后范围: [0, 1160]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1161]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1161, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1161，校正前pad范围: [0, 1160]，校正后范围: [0, 1160]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1161]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1161, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1161，校正前pad范围: [0, 1160]，校正后范围: [0, 1160]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1161]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1161, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1161，校正前pad范围: [0, 1160]，校正后范围: [0, 1160]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1161]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1161, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1161，校正前pad范围: [0, 1160]，校正后范围: [0, 1160]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1161]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1161, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=372，校正前pad范围: [0, 371]，校正后范围: [0, 371]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 372
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 372
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([372]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([372, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=372，校正前pad范围: [0, 371]，校正后范围: [0, 371]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 372
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 372
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([372]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([372, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1161，校正前pad范围: [0, 1160]，校正后范围: [0, 1160]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1161]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1161, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1161，校正前pad范围: [0, 1160]，校正后范围: [0, 1160]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1161
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1161]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1161, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2902，校正前pad范围: [0, 2901]，校正后范围: [0, 2901]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2902
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2902
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2902]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2902, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2902，校正前pad范围: [0, 2901]，校正后范围: [0, 2901]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2902
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2902
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2902]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2902, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] f1 (39)_labeled.csv | 点数4052→4224（384的倍数）
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4992], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4992], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] d73_labeled.csv | 点数3722→3840（384的倍数）
2025-09-20 17:37:05 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:05 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:05 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 17:37:05 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:05 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2496], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5286
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5286
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5286]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5286, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2496], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5286
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5286
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5286]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5286, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i42_labeled.csv
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo142_labeled.csv
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2088]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2088, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2088]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2088, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2088]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2088, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2088]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2088, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2088]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2088, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2088]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2088, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 960], device='cuda:0')
2025-09-20 17:37:05 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 960]
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 624], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:05 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 960]
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=613，校正前pad范围: [0, 612]，校正后范围: [0, 612]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 613
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 613
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([613]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([613, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 960], device='cuda:0')
2025-09-20 17:37:05 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 960]
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 624], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=613，校正前pad范围: [0, 612]，校正后范围: [0, 612]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 960], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 613
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 613
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([613]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([613, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2088]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2088, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1248], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1920], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2088
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2088]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2088, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2496], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5286
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5286
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5286]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5286, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2496], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3840], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5286
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5286
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5286]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5286, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4992], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4992], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7680], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] i42_labeled.csv | 点数4088→4224（384的倍数）
2025-09-20 17:37:05 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:05 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:05 - misc:366 - INFO -    各样本点数：[4224, 4224]（均为384的倍数）
2025-09-20 17:37:05 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:05 - misc:368 - INFO -    Offset：[0, 4224, 8448]
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] oo142_labeled.csv | 点数4214→4224（384的倍数）
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas1/hhhh (4)_labeled.csv
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas1/hhhh (9)_labeled.csv
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3912
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3912
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3912]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3912, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3912
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3912
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3912]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3912, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1621，校正前pad范围: [0, 1620]，校正后范围: [0, 1620]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1621]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1621, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1621，校正前pad范围: [0, 1620]，校正后范围: [0, 1620]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1621]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1621, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1621，校正前pad范围: [0, 1620]，校正后范围: [0, 1620]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1621]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1621, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1621，校正前pad范围: [0, 1620]，校正后范围: [0, 1620]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1621]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1621, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1621，校正前pad范围: [0, 1620]，校正后范围: [0, 1620]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1621]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1621, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1621，校正前pad范围: [0, 1620]，校正后范围: [0, 1620]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1621]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1621, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 912], device='cuda:0')
2025-09-20 17:37:05 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 912]
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 576], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:05 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 912]
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=504，校正前pad范围: [0, 503]，校正后范围: [0, 503]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 912], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 504
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 504
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([504]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([504, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 912], device='cuda:0')
2025-09-20 17:37:05 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 912]
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 576], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=504，校正前pad范围: [0, 503]，校正后范围: [0, 503]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 912], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 504
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 504
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([504]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([504, 256])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] hhhh (4)_labeled.csv | 点数2898→3072（384的倍数）
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1621，校正前pad范围: [0, 1620]，校正后范围: [0, 1620]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1621]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1621, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 672, 1152], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:05 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1621，校正前pad范围: [0, 1620]，校正后范围: [0, 1620]
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1824], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1621
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1621]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1621, 128])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (168)_labeled.csv
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3912
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3912
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3912]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3912, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3648], device='cuda:0')
2025-09-20 17:37:05 - wind_shear:161 - DEBUG - [补点] hhhh (9)_labeled.csv | 点数2925→3072（384的倍数）
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 2304], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:05 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:05 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:37:05 - misc:366 - INFO -    各样本点数：[4224, 3072]（均为384的倍数）
2025-09-20 17:37:05 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:37:05 - misc:368 - INFO -    Offset：[0, 4224, 7296]
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3912
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3912
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3912]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3912, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 4608], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:05 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5170
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5170
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5170]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5170, 64])
2025-09-20 17:37:05 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:05 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:05 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:05 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:05 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:05 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:05 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:05 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:05 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5170
2025-09-20 17:37:05 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5170
2025-09-20 17:37:05 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:05 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:05 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5170]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:05 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:05 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5170, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b48_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1954]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1954, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1954]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1954, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1954]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1954, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1954]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1954, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1954]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1954, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1954]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1954, 128])
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] gggg (168)_labeled.csv | 点数4922→4992（384的倍数）
2025-09-20 17:37:06 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:06 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:06 - misc:366 - INFO -    各样本点数：[3072, 4992]（均为384的倍数）
2025-09-20 17:37:06 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:06 - misc:368 - INFO -    Offset：[0, 3072, 8064]
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 384], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=570，校正前pad范围: [0, 569]，校正后范围: [0, 569]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 570
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 570
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([570]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([570, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 384], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=570，校正前pad范围: [0, 569]，校正后范围: [0, 569]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 570
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 570
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([570]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([570, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1954]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1954, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1954
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1954]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1954, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5170
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5170
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5170]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5170, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5170
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5170
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5170]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5170, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] b48_labeled.csv | 点数4084→4224（384的倍数）
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas2/p12_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas1/gg99_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6283
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6283
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6283]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6283, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6283
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6283
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6283]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6283, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2493]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2493, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2493]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2493, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2493]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2493, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2493]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2493, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2493]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2493, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2493]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2493, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 528], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=759，校正前pad范围: [0, 758]，校正后范围: [0, 758]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 759
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 759
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([759]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([759, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 528], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=759，校正前pad范围: [0, 758]，校正后范围: [0, 758]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 759
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 759
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([759]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([759, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] gg99_labeled.csv | 点数2383→2688（384的倍数）
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2493]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2493, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2493
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2493]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2493, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6283
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6283
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6283]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6283, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6283
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6283
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6283]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6283, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa106_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] p12_labeled.csv | 点数3617→3840（384的倍数）
2025-09-20 17:37:06 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:06 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:06 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 17:37:06 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:06 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss38_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4615
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4615
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] aa106_labeled.csv | 点数3185→3456（384的倍数）
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4615]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:06 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6144
2025-09-20 17:37:06 - misc:366 - INFO -    各样本点数：[2688, 3456]（均为384的倍数）
2025-09-20 17:37:06 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6144, 3])，feat=torch.Size([6144, 9])，label=torch.Size([6144])
2025-09-20 17:37:06 - misc:368 - INFO -    Offset：[0, 2688, 6144]
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4615, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4615
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4615
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4615]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4615, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1698，校正前pad范围: [0, 1697]，校正后范围: [0, 1697]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1698]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1698, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1698，校正前pad范围: [0, 1697]，校正后范围: [0, 1697]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1698]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1698, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1698，校正前pad范围: [0, 1697]，校正后范围: [0, 1697]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1698]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1698, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1698，校正前pad范围: [0, 1697]，校正后范围: [0, 1697]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1698]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1698, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1698，校正前pad范围: [0, 1697]，校正后范围: [0, 1697]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1698]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1698, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1698，校正前pad范围: [0, 1697]，校正后范围: [0, 1697]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1698]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1698, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 480], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] ss38_labeled.csv | 点数1853→1920（384的倍数）
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=486，校正前pad范围: [0, 485]，校正后范围: [0, 485]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 486
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 486
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([486]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([486, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 480], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=486，校正前pad范围: [0, 485]，校正后范围: [0, 485]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 486
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 486
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([486]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([486, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h161_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1698，校正前pad范围: [0, 1697]，校正后范围: [0, 1697]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1698]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1698, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1698，校正前pad范围: [0, 1697]，校正后范围: [0, 1697]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1698
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1698]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1698, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4615
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4615
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4615]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4615, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4615
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4615
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4615]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4615, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3072], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3072], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1536], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3456], device='cuda:0')
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x159_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4506
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4506
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4506]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4506, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1536], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4506
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4506
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4506]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4506, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1630，校正前pad范围: [0, 1629]，校正后范围: [0, 1629]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1630]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1630, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1630，校正前pad范围: [0, 1629]，校正后范围: [0, 1629]
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] h161_labeled.csv | 点数4092→4224（384的倍数）
2025-09-20 17:37:06 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:06 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6144
2025-09-20 17:37:06 - misc:366 - INFO -    各样本点数：[1920, 4224]（均为384的倍数）
2025-09-20 17:37:06 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6144, 3])，feat=torch.Size([6144, 9])，label=torch.Size([6144])
2025-09-20 17:37:06 - misc:368 - INFO -    Offset：[0, 1920, 6144]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1630]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1630, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1630，校正前pad范围: [0, 1629]，校正后范围: [0, 1629]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1630]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1630, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1630，校正前pad范围: [0, 1629]，校正后范围: [0, 1629]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1630]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1630, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1630，校正前pad范围: [0, 1629]，校正后范围: [0, 1629]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1630]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1630, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1630，校正前pad范围: [0, 1629]，校正后范围: [0, 1629]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1630]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1630, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 864], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 384], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=467，校正前pad范围: [0, 466]，校正后范围: [0, 466]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 864], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 467
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 467
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([467]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([467, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 864], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 384], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=467，校正前pad范围: [0, 466]，校正后范围: [0, 466]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 864], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 467
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 467
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([467]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([467, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1630，校正前pad范围: [0, 1629]，校正后范围: [0, 1629]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1630]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1630, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 768], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1630，校正前pad范围: [0, 1629]，校正后范围: [0, 1629]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1728], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1630
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1630]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1630, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1536], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4506
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4506
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4506]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4506, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1536], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:06 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3456], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4506
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4506
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4506]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4506, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3072], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3072], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6912], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss113_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3246，校正前pad范围: [0, 3245]，校正后范围: [0, 3245]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3246
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3246
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3246]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3246, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3246，校正前pad范围: [0, 3245]，校正后范围: [0, 3245]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] x159_labeled.csv | 点数4806→4992（384的倍数）
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3246
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3246
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3246]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3246, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1254，校正前pad范围: [0, 1253]，校正后范围: [0, 1253]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1254]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1254, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1254，校正前pad范围: [0, 1253]，校正后范围: [0, 1253]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1254]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1254, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1254，校正前pad范围: [0, 1253]，校正后范围: [0, 1253]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1254]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1254, 128])
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas4/jj74_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1254，校正前pad范围: [0, 1253]，校正后范围: [0, 1253]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1254]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1254, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1254，校正前pad范围: [0, 1253]，校正后范围: [0, 1253]
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] ss113_labeled.csv | 点数1636→1920（384的倍数）
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1254]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1254, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1254，校正前pad范围: [0, 1253]，校正后范围: [0, 1253]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1254]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1254, 128])
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x46_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=385，校正前pad范围: [0, 384]，校正后范围: [0, 384]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 385
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 385
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([385]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([385, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=385，校正前pad范围: [0, 384]，校正后范围: [0, 384]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 385
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 385
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([385]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([385, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1254，校正前pad范围: [0, 1253]，校正后范围: [0, 1253]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1254]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1254, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1254，校正前pad范围: [0, 1253]，校正后范围: [0, 1253]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1254
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1254]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1254, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3246，校正前pad范围: [0, 3245]，校正后范围: [0, 3245]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3246
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3246
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3246]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3246, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3246，校正前pad范围: [0, 3245]，校正后范围: [0, 3245]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3246
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3246
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3246]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3246, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa195_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6112
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6112
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6112]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6112, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6112
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6112
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6112]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6112, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] jj74_labeled.csv | 点数4615→4992（384的倍数）
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2404]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2404, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2404]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2404, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2404]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2404, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] x46_labeled.csv | 点数4602→4608（384的倍数）
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[1920, 4608]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 1920, 6528]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2404]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2404, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2404]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2404, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2404]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2404, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=726，校正前pad范围: [0, 725]，校正后范围: [0, 725]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 726
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 726
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([726]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([726, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=726，校正前pad范围: [0, 725]，校正后范围: [0, 725]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 726
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 726
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([726]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([726, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2404]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2404, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2404
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2404]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2404, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6112
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6112
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6112]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6112, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6112
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6112
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6112]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6112, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] aa195_labeled.csv | 点数4508→4608（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c210_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas1/e10_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2879，校正前pad范围: [0, 2878]，校正后范围: [0, 2878]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2879
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2879
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2879]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2879, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2879，校正前pad范围: [0, 2878]，校正后范围: [0, 2878]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2879
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2879
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2879]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2879, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1151，校正前pad范围: [0, 1150]，校正后范围: [0, 1150]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1151]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1151, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1151，校正前pad范围: [0, 1150]，校正后范围: [0, 1150]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1151]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1151, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1151，校正前pad范围: [0, 1150]，校正后范围: [0, 1150]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1151]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1151, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1151，校正前pad范围: [0, 1150]，校正后范围: [0, 1150]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1151]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1151, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1151，校正前pad范围: [0, 1150]，校正后范围: [0, 1150]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1151]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1151, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1151，校正前pad范围: [0, 1150]，校正后范围: [0, 1150]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1151]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1151, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 384], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=363，校正前pad范围: [0, 362]，校正后范围: [0, 362]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 363
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 363
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([363]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([363, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 384], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=363，校正前pad范围: [0, 362]，校正后范围: [0, 362]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 363
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 363
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([363]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([363, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1151，校正前pad范围: [0, 1150]，校正后范围: [0, 1150]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1151]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1151, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1151，校正前pad范围: [0, 1150]，校正后范围: [0, 1150]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1151
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1151]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1151, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2879，校正前pad范围: [0, 2878]，校正后范围: [0, 2878]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2879
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2879
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2879]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2879, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2879，校正前pad范围: [0, 2878]，校正后范围: [0, 2878]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2879
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2879
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2879]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2879, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] c210_labeled.csv | 点数3287→3456（384的倍数）
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[4608, 3456]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 4608, 8064]
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] e10_labeled.csv | 点数4285→4608（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5990
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5990
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5990]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5990, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/q83_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5990
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5990
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5990]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5990, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/period216_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 624], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=694，校正前pad范围: [0, 693]，校正后范围: [0, 693]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 694
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 694
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([694]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([694, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 624], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=694，校正前pad范围: [0, 693]，校正后范围: [0, 693]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 694
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 694
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([694]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([694, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5990
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5990
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5990]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5990, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5990
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5990
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5990]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5990, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] q83_labeled.csv | 点数3278→3456（384的倍数）
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m135_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] period216_labeled.csv | 点数4352→4608（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[4608, 4608]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 4608, 9216]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa79_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3517，校正前pad范围: [0, 3516]，校正后范围: [0, 3516]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3517
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3517
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3517]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3517, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3517，校正前pad范围: [0, 3516]，校正后范围: [0, 3516]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3517
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3517
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3517]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3517, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1379，校正前pad范围: [0, 1378]，校正后范围: [0, 1378]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1379]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1379, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1379，校正前pad范围: [0, 1378]，校正后范围: [0, 1378]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1379]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1379, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1379，校正前pad范围: [0, 1378]，校正后范围: [0, 1378]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1379]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1379, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1379，校正前pad范围: [0, 1378]，校正后范围: [0, 1378]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1379]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1379, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1379，校正前pad范围: [0, 1378]，校正后范围: [0, 1378]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1379]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1379, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1379，校正前pad范围: [0, 1378]，校正后范围: [0, 1378]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1379]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1379, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=426，校正前pad范围: [0, 425]，校正后范围: [0, 425]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 426
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 426
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([426]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([426, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=426，校正前pad范围: [0, 425]，校正后范围: [0, 425]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 426
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 426
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([426]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([426, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1379，校正前pad范围: [0, 1378]，校正后范围: [0, 1378]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1379]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1379, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1379，校正前pad范围: [0, 1378]，校正后范围: [0, 1378]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1379
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1379]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1379, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3517，校正前pad范围: [0, 3516]，校正后范围: [0, 3516]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3517
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3517
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3517]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3517, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3517，校正前pad范围: [0, 3516]，校正后范围: [0, 3516]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3517
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3517
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3517]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3517, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] m135_labeled.csv | 点数3895→4224（384的倍数）
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[3456, 4224]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 3456, 7680]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] aa79_labeled.csv | 点数3797→3840（384的倍数）
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(158)_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3456], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6144, unpad长度将设为=6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3456], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a95_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1728], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3072, unpad长度将设为=3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3072，校正前最大索引=3071, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3733
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3733
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3733]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3733, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1728], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3072，校正前最大索引=3071, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3733
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3733
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3733]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3733, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 864], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1536, unpad长度将设为=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1306，校正前pad范围: [0, 1305]，校正后范围: [0, 1305]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1306]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1306, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 864], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1306，校正前pad范围: [0, 1305]，校正后范围: [0, 1305]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1306]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1306, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 864], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1306，校正前pad范围: [0, 1305]，校正后范围: [0, 1305]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1306]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1306, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 864], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1306，校正前pad范围: [0, 1305]，校正后范围: [0, 1305]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1306]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1306, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 864], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1306，校正前pad范围: [0, 1305]，校正后范围: [0, 1305]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1306]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1306, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 864], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1306，校正前pad范围: [0, 1305]，校正后范围: [0, 1305]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1306]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1306, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 768], device='cuda:0')
2025-09-20 17:37:07 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 768]
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 432], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:07 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 768]
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=768, unpad长度将设为=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=368，校正前pad范围: [0, 367]，校正后范围: [0, 367]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 368
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 368
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([368]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([368, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 768], device='cuda:0')
2025-09-20 17:37:07 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 768]
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 432], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=368，校正前pad范围: [0, 367]，校正后范围: [0, 367]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 368
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 368
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([368]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([368, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 864], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1306，校正前pad范围: [0, 1305]，校正后范围: [0, 1305]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1306]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1306, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 864], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1306，校正前pad范围: [0, 1305]，校正后范围: [0, 1305]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1306
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1306]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1306, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1728], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3072，校正前最大索引=3071, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3733
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3733
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3733]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3733, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1728], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3072，校正前最大索引=3071, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3733
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3733
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3733]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3733, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3456], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3456], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] bbbbb(158)_labeled.csv | 点数4102→4224（384的倍数）
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[3840, 4224]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 3840, 8064]
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] a95_labeled.csv | 点数4131→4224（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll132_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6144, unpad长度将设为=6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m86_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3072], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2112], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3072, unpad长度将设为=3072
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2750，校正前pad范围: [0, 2749]，校正后范围: [0, 2749]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3072], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2750
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2750
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2750]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2750, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3072], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2112], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2750，校正前pad范围: [0, 2749]，校正后范围: [0, 2749]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3072], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2750
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2750
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2750]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2750, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1056], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1536, unpad长度将设为=1536
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1088，校正前pad范围: [0, 1087]，校正后范围: [0, 1087]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1088]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1088, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1056], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1088，校正前pad范围: [0, 1087]，校正后范围: [0, 1087]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1088]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1088, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1056], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1088，校正前pad范围: [0, 1087]，校正后范围: [0, 1087]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1088]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1088, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1056], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1088，校正前pad范围: [0, 1087]，校正后范围: [0, 1087]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1088]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1088, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1056], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1088，校正前pad范围: [0, 1087]，校正后范围: [0, 1087]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1088]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1088, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1056], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1088，校正前pad范围: [0, 1087]，校正后范围: [0, 1087]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1088]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1088, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 768], device='cuda:0')
2025-09-20 17:37:08 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 768]
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:08 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 768]
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=768, unpad长度将设为=768
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=355，校正前pad范围: [0, 354]，校正后范围: [0, 354]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 768], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 355
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 355
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([355]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([355, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 768], device='cuda:0')
2025-09-20 17:37:08 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 768]
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=355，校正前pad范围: [0, 354]，校正后范围: [0, 354]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 768], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 355
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 355
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([355]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([355, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1056], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1088，校正前pad范围: [0, 1087]，校正后范围: [0, 1087]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1088]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1088, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1056], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1088，校正前pad范围: [0, 1087]，校正后范围: [0, 1087]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1536], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1088
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1088]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1088, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3072], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2112], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2750，校正前pad范围: [0, 2749]，校正后范围: [0, 2749]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3072], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2750
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2750
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2750]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2750, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3072], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2112], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2750，校正前pad范围: [0, 2749]，校正后范围: [0, 2749]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3072], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2750
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2750
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2750]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2750, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6144], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4224], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6144], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6144], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4224], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6144], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] ll132_labeled.csv | 点数5414→5760（384的倍数）
2025-09-20 17:37:08 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:08 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:37:08 - misc:366 - INFO -    各样本点数：[4224, 5760]（均为384的倍数）
2025-09-20 17:37:08 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:37:08 - misc:368 - INFO -    Offset：[0, 4224, 9984]
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] m86_labeled.csv | 点数4530→4608（384的倍数）
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas3/ii10_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh86_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4263，校正前pad范围: [0, 4262]，校正后范围: [0, 4262]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4263
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4263
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4263]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4263, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4263，校正前pad范围: [0, 4262]，校正后范围: [0, 4262]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4263
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4263
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4263]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4263, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=561，校正前pad范围: [0, 560]，校正后范围: [0, 560]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 561
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 561
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([561]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([561, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=561，校正前pad范围: [0, 560]，校正后范围: [0, 560]
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] hh86_labeled.csv | 点数1807→1920（384的倍数）
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 561
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 561
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([561]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([561, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1781，校正前pad范围: [0, 1780]，校正后范围: [0, 1780]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1781
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1781]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee45_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1781, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4263，校正前pad范围: [0, 4262]，校正后范围: [0, 4262]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4263
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4263
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4263]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4263, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4263，校正前pad范围: [0, 4262]，校正后范围: [0, 4262]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4263
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4263
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4263]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4263, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] ii10_labeled.csv | 点数2765→3072（384的倍数）
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:08 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:37:08 - misc:366 - INFO -    各样本点数：[4608, 3072]（均为384的倍数）
2025-09-20 17:37:08 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:37:08 - misc:368 - INFO -    Offset：[0, 4608, 7680]
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas2/f1 (51)_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4688
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4688
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4688]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4688, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4688
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4688
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4688]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4688, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1838]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1838, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1838]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1838, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1838]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1838, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1838]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1838, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1838]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1838, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1838]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1838, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 816], device='cuda:0')
2025-09-20 17:37:08 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 816]
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 576], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:08 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 816]
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=535，校正前pad范围: [0, 534]，校正后范围: [0, 534]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 816], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 535
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 535
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([535]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([535, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 816], device='cuda:0')
2025-09-20 17:37:08 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 816]
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 576], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=535，校正前pad范围: [0, 534]，校正后范围: [0, 534]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 816], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 535
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 535
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([535]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([535, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1838]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1838, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1632，校正前最大索引=1631, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1632], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1838
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1838]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1838, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4688
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4688
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4688]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4688, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3264], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4688
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4688
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4688]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4688, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 6528], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] ee45_labeled.csv | 点数5802→6144（384的倍数）
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:08 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:08 - misc:366 - INFO -    各样本点数：[1920, 6144]（均为384的倍数）
2025-09-20 17:37:08 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:08 - misc:368 - INFO -    Offset：[0, 1920, 8064]
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] f1 (51)_labeled.csv | 点数3962→4224（384的倍数）
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas3/gh1 (132)_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3113，校正前pad范围: [0, 3112]，校正后范围: [0, 3112]
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g107_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3113
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3113
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3113]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3113, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3113，校正前pad范围: [0, 3112]，校正后范围: [0, 3112]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3113
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3113
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3113]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3113, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1271，校正前pad范围: [0, 1270]，校正后范围: [0, 1270]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1271]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1271, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1271，校正前pad范围: [0, 1270]，校正后范围: [0, 1270]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1271]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1271, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1271，校正前pad范围: [0, 1270]，校正后范围: [0, 1270]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1271]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1271, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1271，校正前pad范围: [0, 1270]，校正后范围: [0, 1270]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1271]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1271, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1271，校正前pad范围: [0, 1270]，校正后范围: [0, 1270]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1271]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1271, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1271，校正前pad范围: [0, 1270]，校正后范围: [0, 1270]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1271]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1271, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=413，校正前pad范围: [0, 412]，校正后范围: [0, 412]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 413
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 413
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([413]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([413, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=413，校正前pad范围: [0, 412]，校正后范围: [0, 412]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 413
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 413
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([413]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([413, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1271，校正前pad范围: [0, 1270]，校正后范围: [0, 1270]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1271]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1271, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1271，校正前pad范围: [0, 1270]，校正后范围: [0, 1270]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1271
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1271]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1271, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3113，校正前pad范围: [0, 3112]，校正后范围: [0, 3112]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3113
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3113
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3113]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3113, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3113，校正前pad范围: [0, 3112]，校正后范围: [0, 3112]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3113
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3113
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3113]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3113, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] g107_labeled.csv | 点数4217→4224（384的倍数）
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] gh1 (132)_labeled.csv | 点数4636→4992（384的倍数）
2025-09-20 17:37:06 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:06 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:06 - misc:366 - INFO -    各样本点数：[4224, 4992]（均为384的倍数）
2025-09-20 17:37:06 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:06 - misc:368 - INFO -    Offset：[0, 4224, 9216]
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (77)_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3889，校正前pad范围: [0, 3888]，校正后范围: [0, 3888]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3889
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3889
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (77)_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3889]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3889, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3889，校正前pad范围: [0, 3888]，校正后范围: [0, 3888]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3889
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3889
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3889]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3889, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1550，校正前pad范围: [0, 1549]，校正后范围: [0, 1549]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1550]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1550, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1550，校正前pad范围: [0, 1549]，校正后范围: [0, 1549]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1550]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1550, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1550，校正前pad范围: [0, 1549]，校正后范围: [0, 1549]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1550]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1550, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1550，校正前pad范围: [0, 1549]，校正后范围: [0, 1549]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1550]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1550, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1550，校正前pad范围: [0, 1549]，校正后范围: [0, 1549]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1550]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1550, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1550，校正前pad范围: [0, 1549]，校正后范围: [0, 1549]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1550]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1550, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=474，校正前pad范围: [0, 473]，校正后范围: [0, 473]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 474
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 474
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([474]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([474, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=474，校正前pad范围: [0, 473]，校正后范围: [0, 473]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 474
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 474
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([474]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([474, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1550，校正前pad范围: [0, 1549]，校正后范围: [0, 1549]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1550]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1550, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1550，校正前pad范围: [0, 1549]，校正后范围: [0, 1549]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1550
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1550]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1550, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3889，校正前pad范围: [0, 3888]，校正后范围: [0, 3888]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3889
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3889
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3889]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3889, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3889，校正前pad范围: [0, 3888]，校正后范围: [0, 3888]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3889
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3889
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3889]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3889, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] gggg (77)_labeled.csv | 点数4936→4992（384的倍数）
2025-09-20 17:37:06 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:06 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:06 - misc:366 - INFO -    各样本点数：[4224, 4992]（均为384的倍数）
2025-09-20 17:37:06 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:06 - misc:368 - INFO -    Offset：[0, 4224, 9216]
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] iiii (77)_labeled.csv | 点数4880→4992（384的倍数）
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll81_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2691，校正前pad范围: [0, 2690]，校正后范围: [0, 2690]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2691
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2691
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2691]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2691, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2691，校正前pad范围: [0, 2690]，校正后范围: [0, 2690]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2691
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2691
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2691]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2691, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1037，校正前pad范围: [0, 1036]，校正后范围: [0, 1036]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y70_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1037，校正前pad范围: [0, 1036]，校正后范围: [0, 1036]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1037，校正前pad范围: [0, 1036]，校正后范围: [0, 1036]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1037，校正前pad范围: [0, 1036]，校正后范围: [0, 1036]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1037，校正前pad范围: [0, 1036]，校正后范围: [0, 1036]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1037，校正前pad范围: [0, 1036]，校正后范围: [0, 1036]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=329，校正前pad范围: [0, 328]，校正后范围: [0, 328]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 329
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 329
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([329]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([329, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=329，校正前pad范围: [0, 328]，校正后范围: [0, 328]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 329
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 329
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([329]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([329, 256])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1037，校正前pad范围: [0, 1036]，校正后范围: [0, 1036]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1037，校正前pad范围: [0, 1036]，校正后范围: [0, 1036]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1037
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1037]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1037, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2691，校正前pad范围: [0, 2690]，校正后范围: [0, 2690]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2691
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2691
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2691]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2691, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2691，校正前pad范围: [0, 2690]，校正后范围: [0, 2690]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2691
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2691
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2691]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2691, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] y70_labeled.csv | 点数3730→3840（384的倍数）
2025-09-20 17:37:06 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:06 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:06 - misc:366 - INFO -    各样本点数：[4992, 3840]（均为384的倍数）
2025-09-20 17:37:06 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:06 - misc:368 - INFO -    Offset：[0, 4992, 8832]
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas3/gh1 (29)_labeled.csv
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2842，校正前pad范围: [0, 2841]，校正后范围: [0, 2841]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2842
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2842
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2842]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2842, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2842，校正前pad范围: [0, 2841]，校正后范围: [0, 2841]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2842
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2842
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2842]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2842, 64])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1102，校正前pad范围: [0, 1101]，校正后范围: [0, 1101]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1102]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1102, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1102，校正前pad范围: [0, 1101]，校正后范围: [0, 1101]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - wind_shear:161 - DEBUG - [补点] ll81_labeled.csv | 点数5748→5760（384的倍数）
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1102]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1102, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1102，校正前pad范围: [0, 1101]，校正后范围: [0, 1101]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1102]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1102, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1102，校正前pad范围: [0, 1101]，校正后范围: [0, 1101]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1102]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1102, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1102，校正前pad范围: [0, 1101]，校正后范围: [0, 1101]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1102]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1102, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:06 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1102，校正前pad范围: [0, 1101]，校正后范围: [0, 1101]
2025-09-20 17:37:06 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:06 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:06 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:06 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1102
2025-09-20 17:37:06 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:06 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:06 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1102]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:06 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:06 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1102, 128])
2025-09-20 17:37:06 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:06 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:06 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 17:37:06 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:06 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:06 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i52_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=354，校正前pad范围: [0, 353]，校正后范围: [0, 353]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 354
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 354
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([354]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([354, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=354，校正前pad范围: [0, 353]，校正后范围: [0, 353]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 354
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 354
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([354]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([354, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1102，校正前pad范围: [0, 1101]，校正后范围: [0, 1101]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1102
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1102
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1102]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1102, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1102，校正前pad范围: [0, 1101]，校正后范围: [0, 1101]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1102
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1102
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1102]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1102, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2842，校正前pad范围: [0, 2841]，校正后范围: [0, 2841]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2842
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2842
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2842]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2842, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2842，校正前pad范围: [0, 2841]，校正后范围: [0, 2841]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2842
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2842
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2842]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2842, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5760], device='cuda:0')
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] gh1 (29)_labeled.csv | 点数4306→4608（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas1/e48_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5760], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll94_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2880], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7460
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7460
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7460]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7460, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2880], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] i52_labeled.csv | 点数3602→3840（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[5760, 3840]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 5760, 9600]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7460
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7460
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7460]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7460, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3176]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3176, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3176]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3176, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3176]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3176, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3176]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3176, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3176]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3176, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3176]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3176, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 720], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=954，校正前pad范围: [0, 953]，校正后范围: [0, 953]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 954
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 954
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([954]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([954, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 720], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=954，校正前pad范围: [0, 953]，校正后范围: [0, 953]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 954
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 954
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([954]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([954, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3176]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3176, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1440], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3176
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3176]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3176, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2880], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7460
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7460
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7460]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7460, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2880], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7460
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7460
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7460]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7460, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5760], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 5760], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9984], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] e48_labeled.csv | 点数5051→5376（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c127_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g159_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3131，校正前pad范围: [0, 3130]，校正后范围: [0, 3130]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3131
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3131
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3131]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3131, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3131，校正前pad范围: [0, 3130]，校正后范围: [0, 3130]
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] ll94_labeled.csv | 点数5319→5376（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[4608, 5376]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 4608, 9984]
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3131
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3131
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3131]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3131, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1274，校正前pad范围: [0, 1273]，校正后范围: [0, 1273]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1274]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1274, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1274，校正前pad范围: [0, 1273]，校正后范围: [0, 1273]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1274]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1274, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1274，校正前pad范围: [0, 1273]，校正后范围: [0, 1273]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1274]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1274, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1274，校正前pad范围: [0, 1273]，校正后范围: [0, 1273]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1274]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1274, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1274，校正前pad范围: [0, 1273]，校正后范围: [0, 1273]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1274]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1274, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1274，校正前pad范围: [0, 1273]，校正后范围: [0, 1273]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1274]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1274, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 576, 960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 384], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=412，校正前pad范围: [0, 411]，校正后范围: [0, 411]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 576, 960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 412
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 412
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([412]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([412, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 576, 960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 384], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=412，校正前pad范围: [0, 411]，校正后范围: [0, 411]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 576, 960], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 412
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 412
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([412]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([412, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1274，校正前pad范围: [0, 1273]，校正后范围: [0, 1273]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1274]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1274, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1274，校正前pad范围: [0, 1273]，校正后范围: [0, 1273]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1920], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1274
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1274]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1274, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3131，校正前pad范围: [0, 3130]，校正后范围: [0, 3130]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3131
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3131
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3131]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3131, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3131，校正前pad范围: [0, 3130]，校正后范围: [0, 3130]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3840], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3131
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3131
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3131]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3131, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7680], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] c127_labeled.csv | 点数3633→3840（384的倍数）
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[5376, 3840]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 5376, 9216]
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5980
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5980
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5980, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5980
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5980
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5980, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas2/p32_labeled.csv
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] g159_labeled.csv | 点数5060→5376（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2555]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2555, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2555]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2555, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2555]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2555, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2555]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2555, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2555]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2555, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y119_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2555]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2555, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  240, 1008], device='cuda:0')
2025-09-20 17:37:07 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 1008]
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:07 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 1008]
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=779，校正前pad范围: [0, 778]，校正后范围: [0, 778]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  240, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 779
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 779
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([779]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([779, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  240, 1008], device='cuda:0')
2025-09-20 17:37:07 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 1008]
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 768], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=779，校正前pad范围: [0, 778]，校正后范围: [0, 778]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  240, 1008], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 779
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 779
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([779]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([779, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2555]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2555, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1536], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 2016], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2555
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2555]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2555, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5980
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5980
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5980, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 3072], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 4032], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5980
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5980
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5980, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 6144], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 8064], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] p32_labeled.csv | 点数4039→4224（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas2/j41_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6572
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6572
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6572]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6572, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6572
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6572
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6572]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6572, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d94_labeled.csv
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2649]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2649, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2649]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2649, 128])
2025-09-20 17:37:07 - wind_shear:161 - DEBUG - [补点] y119_labeled.csv | 点数3450→3456（384的倍数）
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:07 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:07 - misc:366 - INFO -    各样本点数：[5376, 3456]（均为384的倍数）
2025-09-20 17:37:07 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:07 - misc:368 - INFO -    Offset：[0, 5376, 8832]
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2649]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2649, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2649]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2649, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2649]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2649, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2649]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2649, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:07 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=806，校正前pad范围: [0, 805]，校正后范围: [0, 805]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 806
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 806
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([806]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([806, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:07 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=806，校正前pad范围: [0, 805]，校正后范围: [0, 805]
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 806
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 806
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([806]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([806, 256])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2649]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2649, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2649
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2649]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2649, 128])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:07 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:07 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:07 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:07 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:07 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:07 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6572
2025-09-20 17:37:07 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6572
2025-09-20 17:37:07 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:07 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:07 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6572]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:07 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:07 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6572, 64])
2025-09-20 17:37:07 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:07 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:07 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] d94_labeled.csv | 点数4051→4224（384的倍数）
2025-09-20 17:37:08 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:08 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:08 - misc:366 - INFO -    各样本点数：[4224, 4224]（均为384的倍数）
2025-09-20 17:37:08 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:08 - misc:368 - INFO -    Offset：[0, 4224, 8448]
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6572
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6572
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6572]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6572, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] j41_labeled.csv | 点数3822→3840（384的倍数）
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g94_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk76_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4329，校正前pad范围: [0, 4328]，校正后范围: [0, 4328]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4329
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4329
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4329]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4329, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4329，校正前pad范围: [0, 4328]，校正后范围: [0, 4328]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4329
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4329
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4329]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4329, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1804，校正前pad范围: [0, 1803]，校正后范围: [0, 1803]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1804]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1804, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1804，校正前pad范围: [0, 1803]，校正后范围: [0, 1803]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1804]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1804, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1804，校正前pad范围: [0, 1803]，校正后范围: [0, 1803]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1804]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1804, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1804，校正前pad范围: [0, 1803]，校正后范围: [0, 1803]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1804]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1804, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1804，校正前pad范围: [0, 1803]，校正后范围: [0, 1803]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1804]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1804, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1804，校正前pad范围: [0, 1803]，校正后范围: [0, 1803]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1804]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1804, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=561，校正前pad范围: [0, 560]，校正后范围: [0, 560]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 561
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 561
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([561]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([561, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=561，校正前pad范围: [0, 560]，校正后范围: [0, 560]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 561
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 561
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([561]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([561, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] g94_labeled.csv | 点数4232→4608（384的倍数）
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:08 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:08 - misc:366 - INFO -    各样本点数：[3840, 4608]（均为384的倍数）
2025-09-20 17:37:08 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:08 - misc:368 - INFO -    Offset：[0, 3840, 8448]
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1804，校正前pad范围: [0, 1803]，校正后范围: [0, 1803]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1804]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1804, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1804，校正前pad范围: [0, 1803]，校正后范围: [0, 1803]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1804
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1804]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1804, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4329，校正前pad范围: [0, 4328]，校正后范围: [0, 4328]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4329
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4329
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4329]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4329, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4329，校正前pad范围: [0, 4328]，校正后范围: [0, 4328]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4329
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4329
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4329]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4329, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] kk76_labeled.csv | 点数5494→5760（384的倍数）
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c101_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a58_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6599
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6599
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6599]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6599, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6599
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6599
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6599]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6599, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2673]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2673, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2673]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2673, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2673]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2673, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2673]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2673, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2673]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2673, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2673]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2673, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=789，校正前pad范围: [0, 788]，校正后范围: [0, 788]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 789
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 789
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([789]), 最大索引: 624, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([789, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=789，校正前pad范围: [0, 788]，校正后范围: [0, 788]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 789
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 789
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([789]), 最大索引: 624, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([789, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2673]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2673, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2673
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2673]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2673, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6599
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6599
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6599]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6599, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6599
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6599
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6599]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6599, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] c101_labeled.csv | 点数3201→3456（384的倍数）
2025-09-20 17:37:08 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:08 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:08 - misc:366 - INFO -    各样本点数：[5760, 3456]（均为384的倍数）
2025-09-20 17:37:08 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:08 - misc:368 - INFO -    Offset：[0, 5760, 9216]
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] a58_labeled.csv | 点数3310→3456（384的倍数）
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas1/period53_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:08 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb70_labeled.csv
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5116
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5116
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5116]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5116, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5116
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5116
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5116]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5116, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2264，校正前pad范围: [0, 2263]，校正后范围: [0, 2263]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2264]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2264, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2264，校正前pad范围: [0, 2263]，校正后范围: [0, 2263]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2264]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2264, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2264，校正前pad范围: [0, 2263]，校正后范围: [0, 2263]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2264]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2264, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2264，校正前pad范围: [0, 2263]，校正后范围: [0, 2263]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2264]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2264, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2264，校正前pad范围: [0, 2263]，校正后范围: [0, 2263]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2264]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2264, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2264，校正前pad范围: [0, 2263]，校正后范围: [0, 2263]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2264]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2264, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 480], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=719，校正前pad范围: [0, 718]，校正后范围: [0, 718]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 719
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 719
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([719]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([719, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 480], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=719，校正前pad范围: [0, 718]，校正后范围: [0, 718]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 719
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 719
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([719]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([719, 256])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2264，校正前pad范围: [0, 2263]，校正后范围: [0, 2263]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2264]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2264, 128])
2025-09-20 17:37:08 - wind_shear:161 - DEBUG - [补点] period53_labeled.csv | 点数3681→3840（384的倍数）
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:08 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:37:08 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 17:37:08 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:37:08 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:08 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2264，校正前pad范围: [0, 2263]，校正后范围: [0, 2263]
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2264
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2264]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2264, 128])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5116
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5116
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5116]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5116, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:08 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5116
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5116
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5116]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5116, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:08 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:08 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:08 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:08 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:08 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:08 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:37:08 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:08 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:08 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:08 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:08 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] bb70_labeled.csv | 点数4630→4992（384的倍数）
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh74_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4670，校正前pad范围: [0, 4669]，校正后范围: [0, 4669]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4670
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4670
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4670]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4670, 64])
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (112)_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4670，校正前pad范围: [0, 4669]，校正后范围: [0, 4669]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4670
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4670
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4670]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4670, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2020，校正前pad范围: [0, 2019]，校正后范围: [0, 2019]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2020]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2020, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2020，校正前pad范围: [0, 2019]，校正后范围: [0, 2019]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2020]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2020, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2020，校正前pad范围: [0, 2019]，校正后范围: [0, 2019]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2020]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2020, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2020，校正前pad范围: [0, 2019]，校正后范围: [0, 2019]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2020]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2020, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2020，校正前pad范围: [0, 2019]，校正后范围: [0, 2019]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2020]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2020, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2020，校正前pad范围: [0, 2019]，校正后范围: [0, 2019]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2020]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2020, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 672], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=628，校正前pad范围: [0, 627]，校正后范围: [0, 627]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 628
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 628
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([628]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([628, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 672], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=628，校正前pad范围: [0, 627]，校正后范围: [0, 627]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 628
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 628
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([628]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([628, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2020，校正前pad范围: [0, 2019]，校正后范围: [0, 2019]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] hh74_labeled.csv | 点数1914→1920（384的倍数）
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2020]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2020, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2020，校正前pad范围: [0, 2019]，校正后范围: [0, 2019]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2020
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2020]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2020, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4670，校正前pad范围: [0, 4669]，校正后范围: [0, 4669]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4670
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4670
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4670]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4670, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4670，校正前pad范围: [0, 4669]，校正后范围: [0, 4669]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4670
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4670
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4670]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4670, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt175_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] eeee (112)_labeled.csv | 点数3702→3840（384的倍数）
2025-09-20 17:37:09 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:09 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:09 - misc:366 - INFO -    各样本点数：[4992, 3840]（均为384的倍数）
2025-09-20 17:37:09 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:09 - misc:368 - INFO -    Offset：[0, 4992, 8832]
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6722
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6722
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6722]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6722, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc98_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6722
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6722
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6722]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6722, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2792]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2792, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2792]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2792, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2792]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2792, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2792]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2792, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] tt175_labeled.csv | 点数3219→3456（384的倍数）
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:09 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:09 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=5376
2025-09-20 17:37:09 - misc:366 - INFO -    各样本点数：[1920, 3456]（均为384的倍数）
2025-09-20 17:37:09 - misc:367 - INFO -    拼接后维度：coord=torch.Size([5376, 3])，feat=torch.Size([5376, 9])，label=torch.Size([5376])
2025-09-20 17:37:09 - misc:368 - INFO -    Offset：[0, 1920, 5376]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2792]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2792, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2792]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2792, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=851，校正前pad范围: [0, 850]，校正后范围: [0, 850]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 851
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 851
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([851]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([851, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=851，校正前pad范围: [0, 850]，校正后范围: [0, 850]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 851
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 851
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([851]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([851, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2792]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2792, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2792
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2792]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2792, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6722
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6722
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6722]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6722, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6722
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6722
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6722]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6722, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] cc98_labeled.csv | 点数3727→3840（384的倍数）
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas1/gg42_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 8832], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3456], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 8832], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 8832], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3456], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 8832], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n33_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4416], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1728], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4416], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6607
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6607
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6607]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6607, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4416], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1728], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4416], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6607
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6607
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6607]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6607, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  864], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2688]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2688, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  864], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2688]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2688, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  864], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2688]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2688, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  864], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2688]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2688, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  864], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2688]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2688, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  864], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2688]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2688, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1104], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 432], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=806，校正前pad范围: [0, 805]，校正后范围: [0, 805]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1104], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 806
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 806
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([806]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([806, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1104], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 432], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=806，校正前pad范围: [0, 805]，校正后范围: [0, 805]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1104], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 806
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 806
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([806]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([806, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  864], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2688]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2688, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  864], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2208], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2688
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2688]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2688, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4416], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1728], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4416], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6607
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6607
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6607]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6607, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4416], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1728], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4416], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6607
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6607
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6607]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6607, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 8832], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3456], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 8832], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 8832], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3456], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 8832], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] n33_labeled.csv | 点数3000→3072（384的倍数）
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas2/vv147_labeled.csv
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] gg42_labeled.csv | 点数4903→4992（384的倍数）
2025-09-20 17:37:09 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:09 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:09 - misc:366 - INFO -    各样本点数：[3840, 4992]（均为384的倍数）
2025-09-20 17:37:09 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:09 - misc:368 - INFO -    Offset：[0, 3840, 8832]
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3550，校正前pad范围: [0, 3549]，校正后范围: [0, 3549]
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas2/aaaa (34)_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3550
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3550
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3550]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3550, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3550，校正前pad范围: [0, 3549]，校正后范围: [0, 3549]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3550
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3550
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3550]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3550, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1413，校正前pad范围: [0, 1412]，校正后范围: [0, 1412]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1413]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1413, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1413，校正前pad范围: [0, 1412]，校正后范围: [0, 1412]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1413]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1413, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1413，校正前pad范围: [0, 1412]，校正后范围: [0, 1412]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1413]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1413, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1413，校正前pad范围: [0, 1412]，校正后范围: [0, 1412]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1413]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1413, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1413，校正前pad范围: [0, 1412]，校正后范围: [0, 1412]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1413]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1413, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1413，校正前pad范围: [0, 1412]，校正后范围: [0, 1412]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1413]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1413, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] vv147_labeled.csv | 点数3210→3456（384的倍数）
2025-09-20 17:37:09 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:09 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:37:09 - misc:366 - INFO -    各样本点数：[3072, 3456]（均为384的倍数）
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:37:09 - misc:368 - INFO -    Offset：[0, 3072, 6528]
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=440，校正前pad范围: [0, 439]，校正后范围: [0, 439]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 440
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 440
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([440]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([440, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=440，校正前pad范围: [0, 439]，校正后范围: [0, 439]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 440
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 440
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([440]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([440, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1413，校正前pad范围: [0, 1412]，校正后范围: [0, 1412]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1413]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1413, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1413，校正前pad范围: [0, 1412]，校正后范围: [0, 1412]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1413
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1413]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1413, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3550，校正前pad范围: [0, 3549]，校正后范围: [0, 3549]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3550
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3550
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3550]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3550, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3550，校正前pad范围: [0, 3549]，校正后范围: [0, 3549]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3550
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3550
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3550]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3550, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - wind_shear:161 - DEBUG - [补点] aaaa (34)_labeled.csv | 点数4327→4608（384的倍数）
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa145_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:09 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo106_labeled.csv
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6029
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6029
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6029]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6029, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6029
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6029
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6029]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6029, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2341]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2341, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2341]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2341, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2341]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2341, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2341]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2341, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2341]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2341, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2341]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2341, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:09 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=717，校正前pad范围: [0, 716]，校正后范围: [0, 716]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 717
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 717
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([717]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([717, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:09 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=717，校正前pad范围: [0, 716]，校正后范围: [0, 716]
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 717
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 717
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([717]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([717, 256])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2341]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2341, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2341
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2341]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2341, 128])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6029
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6029
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6029]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6029, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:09 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6029
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6029
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6029]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6029, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:09 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:09 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:09 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:09 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:09 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:09 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:09 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:09 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:09 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:09 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:09 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] oo106_labeled.csv | 点数4238→4608（384的倍数）
2025-09-20 17:37:10 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:10 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:10 - misc:366 - INFO -    各样本点数：[4608, 4608]（均为384的倍数）
2025-09-20 17:37:10 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:10 - misc:368 - INFO -    Offset：[0, 4608, 9216]
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] aa145_labeled.csv | 点数3976→4224（384的倍数）
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas2/p39_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3914，校正前pad范围: [0, 3913]，校正后范围: [0, 3913]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3914
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3914
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3914]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3914, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m41_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3914，校正前pad范围: [0, 3913]，校正后范围: [0, 3913]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3914
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3914
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3914]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3914, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 432], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=556，校正前pad范围: [0, 555]，校正后范围: [0, 555]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 556
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 556
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([556]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([556, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 432], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=556，校正前pad范围: [0, 555]，校正后范围: [0, 555]
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] p39_labeled.csv | 点数1859→1920（384的倍数）
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6144
2025-09-20 17:37:10 - misc:366 - INFO -    各样本点数：[4224, 1920]（均为384的倍数）
2025-09-20 17:37:10 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6144, 3])，feat=torch.Size([6144, 9])，label=torch.Size([6144])
2025-09-20 17:37:10 - misc:368 - INFO -    Offset：[0, 4224, 6144]
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 556
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 556
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([556]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([556, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1710，校正前pad范围: [0, 1709]，校正后范围: [0, 1709]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1710
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1710]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1710, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3914，校正前pad范围: [0, 3913]，校正后范围: [0, 3913]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3914
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3914
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3914]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3914, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3914，校正前pad范围: [0, 3913]，校正后范围: [0, 3913]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3914
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3914
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3914]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3914, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] m41_labeled.csv | 点数4157→4224（384的倍数）
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt46_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn67_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2554，校正前pad范围: [0, 2553]，校正后范围: [0, 2553]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2554
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2554
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2554]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2554, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2554，校正前pad范围: [0, 2553]，校正后范围: [0, 2553]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2554
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2554
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2554]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2554, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=984，校正前pad范围: [0, 983]，校正后范围: [0, 983]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([984]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([984, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=984，校正前pad范围: [0, 983]，校正后范围: [0, 983]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([984]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([984, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=984，校正前pad范围: [0, 983]，校正后范围: [0, 983]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([984]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([984, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=984，校正前pad范围: [0, 983]，校正后范围: [0, 983]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([984]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([984, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=984，校正前pad范围: [0, 983]，校正后范围: [0, 983]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([984]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([984, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=984，校正前pad范围: [0, 983]，校正后范围: [0, 983]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([984]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([984, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=306，校正前pad范围: [0, 305]，校正后范围: [0, 305]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 306
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 306
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([306]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([306, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=306，校正前pad范围: [0, 305]，校正后范围: [0, 305]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] tt46_labeled.csv | 点数2156→2304（384的倍数）
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 306
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 306
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([306]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:10 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:37:10 - misc:366 - INFO -    各样本点数：[4224, 2304]（均为384的倍数）
2025-09-20 17:37:10 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:37:10 - misc:368 - INFO -    Offset：[0, 4224, 6528]
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([306, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=984，校正前pad范围: [0, 983]，校正后范围: [0, 983]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([984]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([984, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=984，校正前pad范围: [0, 983]，校正后范围: [0, 983]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 984
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([984]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([984, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2554，校正前pad范围: [0, 2553]，校正后范围: [0, 2553]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2554
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2554
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2554]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2554, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2554，校正前pad范围: [0, 2553]，校正后范围: [0, 2553]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2554
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2554
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2554]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2554, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu139_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6338
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6338
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6338]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6338, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6338
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6338
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6338]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6338, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2538]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2538, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2538]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2538, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2538]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2538, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2538]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2538, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2538]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2538, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] nn67_labeled.csv | 点数5734→5760（384的倍数）
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2538]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2538, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=757，校正前pad范围: [0, 756]，校正后范围: [0, 756]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 757
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 757
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([757]), 最大索引: 624, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([757, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=757，校正前pad范围: [0, 756]，校正后范围: [0, 756]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 757
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 757
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([757]), 最大索引: 624, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([757, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2538]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2538, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2538
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2538]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2538, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6338
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6338
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6338]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6338, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] uu139_labeled.csv | 点数2532→2688（384的倍数）
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6338
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6338
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6338]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6338, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas3/k95_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas1/e194_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y201_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3527
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3527
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3527]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3527, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3527
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3527
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3527]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3527, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1221，校正前pad范围: [0, 1220]，校正后范围: [0, 1220]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1221]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1221, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1221，校正前pad范围: [0, 1220]，校正后范围: [0, 1220]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1221]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1221, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1221，校正前pad范围: [0, 1220]，校正后范围: [0, 1220]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1221]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1221, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1221，校正前pad范围: [0, 1220]，校正后范围: [0, 1220]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1221]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1221, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1221，校正前pad范围: [0, 1220]，校正后范围: [0, 1220]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1221]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1221, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1221，校正前pad范围: [0, 1220]，校正后范围: [0, 1220]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1221]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1221, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 17:37:10 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 672]
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 432], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:10 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 672]
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] e194_labeled.csv | 点数3512→3840（384的倍数）
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=672, unpad长度将设为=672
2025-09-20 17:37:10 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:10 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:37:10 - misc:366 - INFO -    各样本点数：[2688, 3840]（均为384的倍数）
2025-09-20 17:37:10 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:37:10 - misc:368 - INFO -    Offset：[0, 2688, 6528]
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=344，校正前pad范围: [0, 343]，校正后范围: [0, 343]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 344
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 344
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([344]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([344, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] k95_labeled.csv | 点数3783→3840（384的倍数）
2025-09-20 17:37:10 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 672]
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 432], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:10 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:10 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:37:10 - misc:366 - INFO -    各样本点数：[5760, 3840]（均为384的倍数）
2025-09-20 17:37:10 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:37:10 - misc:368 - INFO -    Offset：[0, 5760, 9600]
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=344，校正前pad范围: [0, 343]，校正后范围: [0, 343]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 344
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 344
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([344]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([344, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1221，校正前pad范围: [0, 1220]，校正后范围: [0, 1220]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1221]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1221, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1221，校正前pad范围: [0, 1220]，校正后范围: [0, 1220]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1221
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1221]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1221, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3527
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3527
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3527]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3527, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3527
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3527
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3527]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3527, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 64])
2025-09-20 17:37:10 - wind_shear:161 - DEBUG - [补点] y201_labeled.csv | 点数3534→3840（384的倍数）
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa185_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:10 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a121_labeled.csv
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6663
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6663
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6663]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6663, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6663
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6663
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6663]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6663, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2746]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2746, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2746]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2746, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2746]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2746, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2746]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2746, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2746]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2746, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2746]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2746, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=831，校正前pad范围: [0, 830]，校正后范围: [0, 830]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 831
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 831
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([831]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([831, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:10 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=831，校正前pad范围: [0, 830]，校正后范围: [0, 830]
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 831
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 831
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([831]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([831, 256])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2746]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2746, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2746
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2746]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2746, 128])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6663
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6663
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6663]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6663, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:10 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6663
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6663
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6663]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6663, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:10 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:10 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:10 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:10 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:10 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:10 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:10 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:10 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:10 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:10 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:10 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] a121_labeled.csv | 点数3520→3840（384的倍数）
2025-09-20 17:37:11 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:11 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:37:11 - misc:366 - INFO -    各样本点数：[3840, 3840]（均为384的倍数）
2025-09-20 17:37:11 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:37:11 - misc:368 - INFO -    Offset：[0, 3840, 7680]
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] aa185_labeled.csv | 点数4024→4224（384的倍数）
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm89_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3456], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3456], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas3/k31_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1728], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4382
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4382
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4382]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4382, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1728], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4382
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4382
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4382]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4382, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 864], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1597，校正前pad范围: [0, 1596]，校正后范围: [0, 1596]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1597]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1597, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 864], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1597，校正前pad范围: [0, 1596]，校正后范围: [0, 1596]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1597]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1597, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 864], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1597，校正前pad范围: [0, 1596]，校正后范围: [0, 1596]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1597]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1597, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 864], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1597，校正前pad范围: [0, 1596]，校正后范围: [0, 1596]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1597]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1597, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 864], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1597，校正前pad范围: [0, 1596]，校正后范围: [0, 1596]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1597]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1597, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 864], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1597，校正前pad范围: [0, 1596]，校正后范围: [0, 1596]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1597]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1597, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 816], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 432], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=459，校正前pad范围: [0, 458]，校正后范围: [0, 458]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 816], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 459
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 459
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([459]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([459, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 816], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 432], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=459，校正前pad范围: [0, 458]，校正后范围: [0, 458]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 816], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 459
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 459
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([459]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([459, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 864], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1597，校正前pad范围: [0, 1596]，校正后范围: [0, 1596]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1597]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1597, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 864], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1597，校正前pad范围: [0, 1596]，校正后范围: [0, 1596]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1597
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1597]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1597, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1728], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4382
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4382
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4382]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4382, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1728], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4382
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4382
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4382]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4382, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3456], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3456], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] mm89_labeled.csv | 点数4446→4608（384的倍数）
2025-09-20 17:37:11 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:11 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:11 - misc:366 - INFO -    各样本点数：[4224, 4608]（均为384的倍数）
2025-09-20 17:37:11 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:11 - misc:368 - INFO -    Offset：[0, 4224, 8832]
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] k31_labeled.csv | 点数3812→3840（384的倍数）
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas1/period19_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o11_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6462
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6462
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6462]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6462, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6462
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6462
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6462]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6462, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2569]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2569, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2569]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2569, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2569]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2569, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2569]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2569, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2569]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2569, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2569]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2569, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=770，校正前pad范围: [0, 769]，校正后范围: [0, 769]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 770
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 770
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([770]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([770, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=770，校正前pad范围: [0, 769]，校正后范围: [0, 769]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 770
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 770
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([770]), 最大索引: 576, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([770, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2569]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2569, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2569
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2569]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2569, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6462
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6462
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6462]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6462, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6462
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6462
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6462]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6462, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] period19_labeled.csv | 点数3687→3840（384的倍数）
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] o11_labeled.csv | 点数4280→4608（384的倍数）
2025-09-20 17:37:11 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:11 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:11 - misc:366 - INFO -    各样本点数：[3840, 4608]（均为384的倍数）
2025-09-20 17:37:11 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:11 - misc:368 - INFO -    Offset：[0, 3840, 8448]
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a150_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1920], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6144, unpad长度将设为=6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=960
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1920], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=960
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3072, unpad长度将设为=3072
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm65_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3072，校正前最大索引=3071, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3937
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3937
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3937]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3937, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3072，校正前最大索引=3071, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3937
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3937
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3937]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3937, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1536, unpad长度将设为=1536
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1450，校正前pad范围: [0, 1449]，校正后范围: [0, 1449]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1450]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1450, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1450，校正前pad范围: [0, 1449]，校正后范围: [0, 1449]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1450]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1450, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1450，校正前pad范围: [0, 1449]，校正后范围: [0, 1449]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1450]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1450, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1450，校正前pad范围: [0, 1449]，校正后范围: [0, 1449]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1450]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1450, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1450，校正前pad范围: [0, 1449]，校正后范围: [0, 1449]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1450]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1450, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1450，校正前pad范围: [0, 1449]，校正后范围: [0, 1449]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1450]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1450, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 768], device='cuda:0')
2025-09-20 17:37:11 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 528, 768]
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 240], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:11 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 528, 768]
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=768, unpad长度将设为=768
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=419，校正前pad范围: [0, 418]，校正后范围: [0, 418]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 768], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(240, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数240，K=15
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 419
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 419
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([419]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([419, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 768], device='cuda:0')
2025-09-20 17:37:11 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 528, 768]
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 240], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=419，校正前pad范围: [0, 418]，校正后范围: [0, 418]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 768], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(240, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数240，K=15
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 419
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 419
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([419]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([419, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1450，校正前pad范围: [0, 1449]，校正后范围: [0, 1449]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1450]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1450, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1450，校正前pad范围: [0, 1449]，校正后范围: [0, 1449]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1536], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1450
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1450]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1450, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3072，校正前最大索引=3071, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3937
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3937
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3937]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3937, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3072，校正前最大索引=3071, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3072], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3937
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3937
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3937]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3937, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1920], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 1920], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6144], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6144
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6144]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6144, 64])
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] a150_labeled.csv | 点数4309→4608（384的倍数）
2025-09-20 17:37:11 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:11 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:11 - misc:366 - INFO -    各样本点数：[3840, 4608]（均为384的倍数）
2025-09-20 17:37:11 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:11 - misc:368 - INFO -    Offset：[0, 3840, 8448]
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm112_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4302
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4302
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4302]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4302, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4302
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4302
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4302]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4302, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1601，校正前pad范围: [0, 1600]，校正后范围: [0, 1600]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1601]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1601, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1601，校正前pad范围: [0, 1600]，校正后范围: [0, 1600]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1601]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1601, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1601，校正前pad范围: [0, 1600]，校正后范围: [0, 1600]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1601]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1601, 128])
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] mm65_labeled.csv | 点数4897→4992（384的倍数）
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1601，校正前pad范围: [0, 1600]，校正后范围: [0, 1600]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1601]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1601, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1601，校正前pad范围: [0, 1600]，校正后范围: [0, 1600]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1601]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1601, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1601，校正前pad范围: [0, 1600]，校正后范围: [0, 1600]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1601]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1601, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 816], device='cuda:0')
2025-09-20 17:37:11 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 528, 816]
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 288], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:37:11 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 528, 816]
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=471，校正前pad范围: [0, 470]，校正后范围: [0, 470]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 816], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 471
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 471
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([471]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([471, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 816], device='cuda:0')
2025-09-20 17:37:11 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为288（小于384），offset=[0, 528, 816]
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 288], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=471，校正前pad范围: [0, 470]，校正后范围: [0, 470]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 816], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 471
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 471
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([471]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([471, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1601，校正前pad范围: [0, 1600]，校正后范围: [0, 1600]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1601]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1601, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1601，校正前pad范围: [0, 1600]，校正后范围: [0, 1600]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1601
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1601]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1601, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4302
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4302
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4302]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4302, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1152], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4302
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4302
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4302]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4302, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2304], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h168_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] mm112_labeled.csv | 点数3670→3840（384的倍数）
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g137_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:11 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n53_labeled.csv
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7484
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7484
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7484]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7484, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7484
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7484
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7484]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7484, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3158]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3158, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3158]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3158, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3158]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3158, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3158]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3158, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3158]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3158, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3158]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3158, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=946，校正前pad范围: [0, 945]，校正后范围: [0, 945]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 946
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 946
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([946]), 最大索引: 720, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - wind_shear:161 - DEBUG - [补点] h168_labeled.csv | 点数4007→4224（384的倍数）
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([946, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:11 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:11 - misc:366 - INFO -    各样本点数：[4992, 4224]（均为384的倍数）
2025-09-20 17:37:11 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:11 - misc:368 - INFO -    Offset：[0, 4992, 9216]
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 480], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:11 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=946，校正前pad范围: [0, 945]，校正后范围: [0, 945]
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1200], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 946
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 946
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([946]), 最大索引: 720, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([946, 256])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3158]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3158, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  960], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2400], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3158
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3158]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3158, 128])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7484
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7484
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7484]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7484, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1920], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:11 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4800], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7484
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7484
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7484]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7484, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:11 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:11 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:11 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3840], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:11 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:11 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9600], device='cuda:0')
2025-09-20 17:37:11 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:37:11 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:11 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:37:11 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:37:11 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:11 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] g137_labeled.csv | 点数4720→4992（384的倍数）
2025-09-20 17:37:12 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:12 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:12 - misc:366 - INFO -    各样本点数：[3840, 4992]（均为384的倍数）
2025-09-20 17:37:12 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:12 - misc:368 - INFO -    Offset：[0, 3840, 8832]
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] n53_labeled.csv | 点数4140→4224（384的倍数）
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn134_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(14)_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4260
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4260
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4260]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4260, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4260
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4260
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4260]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4260, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1543，校正前pad范围: [0, 1542]，校正后范围: [0, 1542]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1543]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1543, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1543，校正前pad范围: [0, 1542]，校正后范围: [0, 1542]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1543]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1543, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1543，校正前pad范围: [0, 1542]，校正后范围: [0, 1542]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1543]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1543, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1543，校正前pad范围: [0, 1542]，校正后范围: [0, 1542]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1543]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1543, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1543，校正前pad范围: [0, 1542]，校正后范围: [0, 1542]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1543]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1543, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1543，校正前pad范围: [0, 1542]，校正后范围: [0, 1542]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1543]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1543, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 17:37:12 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 816]
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 480], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:12 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 816]
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=430，校正前pad范围: [0, 429]，校正后范围: [0, 429]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 430
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 430
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([430]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([430, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 17:37:12 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为336（小于384），offset=[0, 336, 816]
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 480], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=430，校正前pad范围: [0, 429]，校正后范围: [0, 429]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 430
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 430
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([430]), 最大索引: 336, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([430, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1543，校正前pad范围: [0, 1542]，校正后范围: [0, 1542]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1543]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1543, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1543，校正前pad范围: [0, 1542]，校正后范围: [0, 1542]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1543
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1543]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1543, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4260
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4260
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4260]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4260, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4260
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4260
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4260]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4260, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] nn134_labeled.csv | 点数4797→4992（384的倍数）
2025-09-20 17:37:12 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:12 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:12 - misc:366 - INFO -    各样本点数：[4224, 4992]（均为384的倍数）
2025-09-20 17:37:12 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:12 - misc:368 - INFO -    Offset：[0, 4224, 9216]
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] bbbbb(14)_labeled.csv | 点数4084→4224（384的倍数）
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas2/pp92_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas3/k30_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2526，校正前pad范围: [0, 2525]，校正后范围: [0, 2525]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2526
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2526
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2526]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2526, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2526，校正前pad范围: [0, 2525]，校正后范围: [0, 2525]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2526
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2526
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2526]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2526, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=980，校正前pad范围: [0, 979]，校正后范围: [0, 979]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([980, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=980，校正前pad范围: [0, 979]，校正后范围: [0, 979]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([980, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=980，校正前pad范围: [0, 979]，校正后范围: [0, 979]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([980, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=980，校正前pad范围: [0, 979]，校正后范围: [0, 979]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([980, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=980，校正前pad范围: [0, 979]，校正后范围: [0, 979]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([980, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=980，校正前pad范围: [0, 979]，校正后范围: [0, 979]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([980, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=320，校正前pad范围: [0, 319]，校正后范围: [0, 319]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 320
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 320
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([320]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([320, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=320，校正前pad范围: [0, 319]，校正后范围: [0, 319]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 320
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 320
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([320]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([320, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=980，校正前pad范围: [0, 979]，校正后范围: [0, 979]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([980, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=980，校正前pad范围: [0, 979]，校正后范围: [0, 979]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 980
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([980]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([980, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2526，校正前pad范围: [0, 2525]，校正后范围: [0, 2525]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2526
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2526
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2526]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2526, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2526，校正前pad范围: [0, 2525]，校正后范围: [0, 2525]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2526
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2526
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2526]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2526, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] k30_labeled.csv | 点数3815→3840（384的倍数）
2025-09-20 17:37:12 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:12 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:37:12 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 17:37:12 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:37:12 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas4/r72_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3123，校正前pad范围: [0, 3122]，校正后范围: [0, 3122]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3123，校正前pad范围: [0, 3122]，校正后范围: [0, 3122]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] pp92_labeled.csv | 点数5041→5376（384的倍数）
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1263，校正前pad范围: [0, 1262]，校正后范围: [0, 1262]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1263]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1263, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1263，校正前pad范围: [0, 1262]，校正后范围: [0, 1262]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1263]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1263, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1263，校正前pad范围: [0, 1262]，校正后范围: [0, 1262]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1263]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1263, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1263，校正前pad范围: [0, 1262]，校正后范围: [0, 1262]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1263]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas2/f1 (115)_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1263, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1263，校正前pad范围: [0, 1262]，校正后范围: [0, 1262]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1263]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1263, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1263，校正前pad范围: [0, 1262]，校正后范围: [0, 1262]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1263]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1263, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] r72_labeled.csv | 点数1595→1920（384的倍数）
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 576], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=409，校正前pad范围: [0, 408]，校正后范围: [0, 408]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 409
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 409
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([409]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([409, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 576], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=409，校正前pad范围: [0, 408]，校正后范围: [0, 408]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 409
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 409
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([409]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([409, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1263，校正前pad范围: [0, 1262]，校正后范围: [0, 1262]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1263]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1263, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1263，校正前pad范围: [0, 1262]，校正后范围: [0, 1262]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1263
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1263]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1263, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3123，校正前pad范围: [0, 3122]，校正后范围: [0, 3122]
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c146_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3123，校正前pad范围: [0, 3122]，校正后范围: [0, 3122]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3123
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3123
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3123]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3123, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas2/f1 (141)_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] f1 (115)_labeled.csv | 点数3586→3840（384的倍数）
2025-09-20 17:37:12 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:12 - misc:366 - INFO -    各样本点数：[5376, 3840]（均为384的倍数）
2025-09-20 17:37:12 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:12 - misc:368 - INFO -    Offset：[0, 5376, 9216]
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6078
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6078
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6078]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6078, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6078
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6078
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6078]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6078, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2410, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2410, 128])
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] c146_labeled.csv | 点数3708→3840（384的倍数）
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:12 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=5760
2025-09-20 17:37:12 - misc:366 - INFO -    各样本点数：[1920, 3840]（均为384的倍数）
2025-09-20 17:37:12 - misc:367 - INFO -    拼接后维度：coord=torch.Size([5760, 3])，feat=torch.Size([5760, 9])，label=torch.Size([5760])
2025-09-20 17:37:12 - misc:368 - INFO -    Offset：[0, 1920, 5760]
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2410, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2410, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2410, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2410, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=732，校正前pad范围: [0, 731]，校正后范围: [0, 731]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 732
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 732
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([732]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([732, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=732，校正前pad范围: [0, 731]，校正后范围: [0, 731]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 732
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 732
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([732]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([732, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2410, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2410
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2410]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2410, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6078
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6078
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6078]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6078, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6078
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6078
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6078]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6078, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] f1 (141)_labeled.csv | 点数3219→3456（384的倍数）
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d123_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:37:12 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c39_labeled.csv
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2974，校正前pad范围: [0, 2973]，校正后范围: [0, 2973]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2974
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2974
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2974]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2974, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2974，校正前pad范围: [0, 2973]，校正后范围: [0, 2973]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2974
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2974
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2974]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2974, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1233，校正前pad范围: [0, 1232]，校正后范围: [0, 1232]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1233]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1233, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1233，校正前pad范围: [0, 1232]，校正后范围: [0, 1232]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1233]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1233, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1233，校正前pad范围: [0, 1232]，校正后范围: [0, 1232]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1233]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1233, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1233，校正前pad范围: [0, 1232]，校正后范围: [0, 1232]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1233]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1233, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1233，校正前pad范围: [0, 1232]，校正后范围: [0, 1232]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1233]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1233, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1233，校正前pad范围: [0, 1232]，校正后范围: [0, 1232]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1233]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1233, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] d123_labeled.csv | 点数3850→4224（384的倍数）
2025-09-20 17:37:12 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:37:12 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:12 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:37:12 - misc:366 - INFO -    各样本点数：[3456, 4224]（均为384的倍数）
2025-09-20 17:37:12 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:37:12 - misc:368 - INFO -    Offset：[0, 3456, 7680]
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=395，校正前pad范围: [0, 394]，校正后范围: [0, 394]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 395
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 395
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([395]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([395, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=395，校正前pad范围: [0, 394]，校正后范围: [0, 394]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 395
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 395
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([395]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([395, 256])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1233，校正前pad范围: [0, 1232]，校正后范围: [0, 1232]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1233]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1233, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - wind_shear:161 - DEBUG - [补点] c39_labeled.csv | 点数2929→3072（384的倍数）
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1233，校正前pad范围: [0, 1232]，校正后范围: [0, 1232]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1233
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1233]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1233, 128])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:12 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2974，校正前pad范围: [0, 2973]，校正后范围: [0, 2973]
2025-09-20 17:37:12 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:12 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:12 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:12 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:12 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2974
2025-09-20 17:37:12 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2974
2025-09-20 17:37:12 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:12 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:12 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2974]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:12 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:12 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2974, 64])
2025-09-20 17:37:12 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:12 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:12 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2974，校正前pad范围: [0, 2973]，校正后范围: [0, 2973]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll67_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2974
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2974
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2974]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2974, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3429，校正前pad范围: [0, 3428]，校正后范围: [0, 3428]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3429
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3429
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3429]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas2/p3_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3429, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3429，校正前pad范围: [0, 3428]，校正后范围: [0, 3428]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3429
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3429
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3429]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3429, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1439，校正前pad范围: [0, 1438]，校正后范围: [0, 1438]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1439]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1439, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1439，校正前pad范围: [0, 1438]，校正后范围: [0, 1438]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1439]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1439, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1439，校正前pad范围: [0, 1438]，校正后范围: [0, 1438]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1439]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1439, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1439，校正前pad范围: [0, 1438]，校正后范围: [0, 1438]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1439]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1439, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1439，校正前pad范围: [0, 1438]，校正后范围: [0, 1438]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1439]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1439, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1439，校正前pad范围: [0, 1438]，校正后范围: [0, 1438]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1439]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1439, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=454，校正前pad范围: [0, 453]，校正后范围: [0, 453]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 454
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 454
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([454]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([454, 256])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=454，校正前pad范围: [0, 453]，校正后范围: [0, 453]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 454
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 454
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([454]), 最大索引: 0, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([454, 256])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1439，校正前pad范围: [0, 1438]，校正后范围: [0, 1438]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1439]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1439, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1439，校正前pad范围: [0, 1438]，校正后范围: [0, 1438]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1439
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1439]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1439, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3429，校正前pad范围: [0, 3428]，校正后范围: [0, 3428]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3429
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3429
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3429]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3429, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3429，校正前pad范围: [0, 3428]，校正后范围: [0, 3428]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3429
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3429
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3429]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3429, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:13 - wind_shear:161 - DEBUG - [补点] ll67_labeled.csv | 点数6023→6144（384的倍数）
2025-09-20 17:37:13 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:13 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:13 - misc:366 - INFO -    各样本点数：[3072, 6144]（均为384的倍数）
2025-09-20 17:37:13 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:13 - misc:368 - INFO -    Offset：[0, 3072, 9216]
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - wind_shear:161 - DEBUG - [补点] p3_labeled.csv | 点数3925→4224（384的倍数）
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee67_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6402
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6402
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6402]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6402, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d9_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6402
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6402
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6402]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6402, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2626]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2626, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2626]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2626, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2626]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2626, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2626]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2626, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2626]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2626, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2626]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2626, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=798，校正前pad范围: [0, 797]，校正后范围: [0, 797]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 798
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 798
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([798]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([798, 256])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=798，校正前pad范围: [0, 797]，校正后范围: [0, 797]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 798
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 798
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([798]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([798, 256])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2626]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2626, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2626
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2626]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2626, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6402
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6402
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6402]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6402, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6402
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6402
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6402]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6402, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:37:13 - wind_shear:161 - DEBUG - [补点] d9_labeled.csv | 点数4003→4224（384的倍数）
2025-09-20 17:37:13 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:13 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:13 - misc:366 - INFO -    各样本点数：[4224, 4224]（均为384的倍数）
2025-09-20 17:37:13 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:13 - misc:368 - INFO -    Offset：[0, 4224, 8448]
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas1/hhhh (84)_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6863
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6863
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6863]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6863, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6863
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6863
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6863]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6863, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:13 - wind_shear:161 - DEBUG - [补点] ee67_labeled.csv | 点数5704→5760（384的倍数）
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2770]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2770, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2770]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2770, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2770]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2770, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (7)_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2770]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2770, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2770]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2770, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2770]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2770, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=817，校正前pad范围: [0, 816]，校正后范围: [0, 816]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 817
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 817
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([817]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([817, 256])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 624], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=817，校正前pad范围: [0, 816]，校正后范围: [0, 816]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1152], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 817
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 817
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([817]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([817, 256])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2770]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2770, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1248], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2304], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2770
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2770]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2770, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6863
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6863
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6863]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6863, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2496], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4608], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6863
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6863
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6863]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6863, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4992], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:13 - wind_shear:161 - DEBUG - [补点] hhhh (84)_labeled.csv | 点数4437→4608（384的倍数）
2025-09-20 17:37:13 - wind_shear:161 - DEBUG - [补点] eeee (7)_labeled.csv | 点数3217→3456（384的倍数）
2025-09-20 17:37:13 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:13 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:37:13 - misc:366 - INFO -    各样本点数：[5760, 3456]（均为384的倍数）
2025-09-20 17:37:13 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:37:13 - misc:368 - INFO -    Offset：[0, 5760, 9216]
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d34_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5876
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5876
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5876]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5876, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5876
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5876
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5876]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5876, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2298]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2298, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo21_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2298]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2298, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2298]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2298, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2298]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2298, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2298]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2298, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2298]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2298, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=682，校正前pad范围: [0, 681]，校正后范围: [0, 681]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 682
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 682
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([682]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([682, 256])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:13 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=682，校正前pad范围: [0, 681]，校正后范围: [0, 681]
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 682
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 682
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([682]), 最大索引: 528, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([682, 256])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2298]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2298, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2298
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2298]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2298, 128])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5876
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5876
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5876]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5876, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5876
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5876
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5876]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5876, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:37:13 - wind_shear:161 - DEBUG - [补点] d34_labeled.csv | 点数3839→3840（384的倍数）
2025-09-20 17:37:13 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:13 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:13 - misc:366 - INFO -    各样本点数：[4608, 3840]（均为384的倍数）
2025-09-20 17:37:13 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:13 - misc:368 - INFO -    Offset：[0, 4608, 8448]
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:13 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:13 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:13 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:13 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:13 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:13 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:37:13 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:13 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:13 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:13 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:13 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn83_labeled.csv
2025-09-20 17:37:13 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:13 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6646
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6646
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6646]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6646, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6646
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6646
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6646]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6646, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2745]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2745, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2745]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2745, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2745]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2745, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2745]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2745, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2745]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2745, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2745]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2745, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=834，校正前pad范围: [0, 833]，校正后范围: [0, 833]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 834
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 834
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([834]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([834, 256])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 480], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=834，校正前pad范围: [0, 833]，校正后范围: [0, 833]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1152], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 834
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 834
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([834]), 最大索引: 672, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([834, 256])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2745]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2745, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344,  960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2745
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2745]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2745, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - wind_shear:161 - DEBUG - [补点] oo21_labeled.csv | 点数4292→4608（384的倍数）
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6646
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6646
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6646]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6646, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6646
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6646
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6646]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6646, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:14 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d164_labeled.csv
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt83_labeled.csv
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5760, unpad长度将设为=5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 32])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2880, unpad长度将设为=2880
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3428
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3428
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3428]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3428, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3428
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3428
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3428]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3428, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1440, unpad长度将设为=1440
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1286，校正前pad范围: [0, 1285]，校正后范围: [0, 1285]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1286]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1286, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1286，校正前pad范围: [0, 1285]，校正后范围: [0, 1285]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1286]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1286, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1286，校正前pad范围: [0, 1285]，校正后范围: [0, 1285]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1286]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1286, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1286，校正前pad范围: [0, 1285]，校正后范围: [0, 1285]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1286]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1286, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1286，校正前pad范围: [0, 1285]，校正后范围: [0, 1285]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1286]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1286, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1286，校正前pad范围: [0, 1285]，校正后范围: [0, 1285]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1286]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1286, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 720], device='cuda:0')
2025-09-20 17:37:14 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 720]
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 480], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:14 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 720]
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=720, unpad长度将设为=720
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=376，校正前pad范围: [0, 375]，校正后范围: [0, 375]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 720], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 376
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 376
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([376]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([376, 256])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 720], device='cuda:0')
2025-09-20 17:37:14 - misc:436 - DEBUG - [注意] 下采样后样本最小点数为240（小于384），offset=[0, 240, 720]
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 480], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=376，校正前pad范围: [0, 375]，校正后范围: [0, 375]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 720], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 376
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 376
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([376]), 最大索引: 240, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([376, 256])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1286，校正前pad范围: [0, 1285]，校正后范围: [0, 1285]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1286]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1286, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1286，校正前pad范围: [0, 1285]，校正后范围: [0, 1285]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1440], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:37:14 - wind_shear:161 - DEBUG - [补点] nn83_labeled.csv | 点数5612→5760（384的倍数）
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1286
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1286]), 最大索引: 480, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1286, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3428
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3428
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3428]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3428, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2880], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3428
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3428
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3428]), 最大索引: 960, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3428, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:37:14 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas2/p87_labeled.csv
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5760], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5760
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5760]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5760, 64])
2025-09-20 17:37:14 - wind_shear:161 - DEBUG - [补点] tt83_labeled.csv | 点数3379→3456（384的倍数）
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:14 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (117)_labeled.csv
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:37:14 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn193_labeled.csv
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5210
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5210
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5210]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5210, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5210
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5210
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5210]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5210, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - wind_shear:161 - DEBUG - [补点] d164_labeled.csv | 点数4798→4992（384的倍数）
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:14 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:14 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:37:14 - misc:366 - INFO -    各样本点数：[4608, 4992]（均为384的倍数）
2025-09-20 17:37:14 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:37:14 - misc:368 - INFO -    Offset：[0, 4608, 9600]
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1997]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1997, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1997]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1997, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1997]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1997, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1997]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1997, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1997]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - wind_shear:161 - DEBUG - [补点] p87_labeled.csv | 点数2965→3072（384的倍数）
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1997, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:14 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:37:14 - misc:366 - INFO -    各样本点数：[5760, 3072]（均为384的倍数）
2025-09-20 17:37:14 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - misc:368 - INFO -    Offset：[0, 5760, 8832]
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1997]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1997, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=584，校正前pad范围: [0, 583]，校正后范围: [0, 583]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 584
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 584
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([584]), 最大索引: 432, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([584, 256])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 528], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=584，校正前pad范围: [0, 583]，校正后范围: [0, 583]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 960], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 584
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 584
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([584]), 最大索引: 432, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([584, 256])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1997]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1997, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 864, 1056], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1920], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1997
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1997]), 最大索引: 864, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1997, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5210
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5210
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5210]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5210, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 2112], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3840], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5210
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5210
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5210]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5210, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 4224], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7680], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:37:14 - wind_shear:161 - DEBUG - [补点] iiii (117)_labeled.csv | 点数4150→4224（384的倍数）
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 6144], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 6144], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas2/j83_labeled.csv
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 3072], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7085
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7085
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7085]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7085, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:37:14 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(183)_labeled.csv
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 3072], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7085
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7085
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7085]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7085, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3039]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3039, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3039]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3039, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3039]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3039, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:14 - wind_shear:161 - DEBUG - [补点] nn193_labeled.csv | 点数4929→4992（384的倍数）
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:37:14 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:37:14 - misc:366 - INFO -    各样本点数：[3456, 4992]（均为384的倍数）
2025-09-20 17:37:14 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:37:14 - misc:368 - INFO -    Offset：[0, 3456, 8448]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3039]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3039, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3039]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3039, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3039]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3039, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 1152], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 768], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:14 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=923，校正前pad范围: [0, 922]，校正后范围: [0, 922]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 1152], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 923
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 923
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([923]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([923, 256])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  384, 1152], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 768], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:37:14 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=923，校正前pad范围: [0, 922]，校正后范围: [0, 922]
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  384, 1152], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 923
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 923
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([923]), 最大索引: 384, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([923, 256])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3039]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3039, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1536], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 2304], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3039
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3039]), 最大索引: 768, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3039, 128])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 3072], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7085
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7085
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7085]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7085, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 3072], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:37:14 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 4608], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7085
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7085
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7085]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7085, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 6144], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:37:14 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:37:14 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:37:14 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 6144], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:37:14 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:37:14 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 9216], device='cuda:0')
2025-09-20 17:37:14 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:37:14 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 17:37:14 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:37:14 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:37:14 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:37:14 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
