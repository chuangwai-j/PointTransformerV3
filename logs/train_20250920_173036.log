2025-09-20 17:30:37 - wind_shear:30 - INFO - WindShearDataset train split: 8935 scenes
2025-09-20 17:30:37 - wind_shear:30 - INFO - WindShearDataset val split: 2130 scenes
2025-09-20 17:30:37 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:37 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:30:37 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 17:30:37 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:30:37 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 17:30:37 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:37 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:30:37 - misc:366 - INFO -    各样本点数：[3840, 4608]（均为384的倍数）
2025-09-20 17:30:37 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:30:37 - misc:368 - INFO -    Offset：[0, 3840, 8448]
2025-09-20 17:30:37 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:37 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:30:37 - misc:366 - INFO -    各样本点数：[4608, 4224]（均为384的倍数）
2025-09-20 17:30:37 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:30:37 - misc:368 - INFO -    Offset：[0, 4608, 8832]
2025-09-20 17:30:38 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:38 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=11904
2025-09-20 17:30:38 - misc:366 - INFO -    各样本点数：[6144, 5760]（均为384的倍数）
2025-09-20 17:30:38 - misc:367 - INFO -    拼接后维度：coord=torch.Size([11904, 3])，feat=torch.Size([11904, 9])，label=torch.Size([11904])
2025-09-20 17:30:38 - misc:368 - INFO -    Offset：[0, 6144, 11904]
2025-09-20 17:30:38 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:38 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:30:38 - misc:366 - INFO -    各样本点数：[3456, 3456]（均为384的倍数）
2025-09-20 17:30:38 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:30:38 - misc:368 - INFO -    Offset：[0, 3456, 6912]
2025-09-20 17:30:38 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:38 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:30:38 - misc:366 - INFO -    各样本点数：[5376, 3456]（均为384的倍数）
2025-09-20 17:30:38 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:30:38 - misc:368 - INFO -    Offset：[0, 5376, 8832]
2025-09-20 17:30:38 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:38 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:30:38 - misc:366 - INFO -    各样本点数：[4224, 4608]（均为384的倍数）
2025-09-20 17:30:38 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:30:38 - misc:368 - INFO -    Offset：[0, 4224, 8832]
2025-09-20 17:30:38 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:38 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:30:38 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:30:38 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:30:38 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:30:38 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:38 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:30:38 - misc:366 - INFO -    各样本点数：[3456, 3456]（均为384的倍数）
2025-09-20 17:30:38 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:30:38 - misc:368 - INFO -    Offset：[0, 3456, 6912]
2025-09-20 17:30:38 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:38 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:30:38 - misc:366 - INFO -    各样本点数：[4224, 3072]（均为384的倍数）
2025-09-20 17:30:38 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:30:38 - misc:368 - INFO -    Offset：[0, 4224, 7296]
2025-09-20 17:30:38 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:38 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:30:38 - misc:366 - INFO -    各样本点数：[3456, 4224]（均为384的倍数）
2025-09-20 17:30:38 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:30:38 - misc:368 - INFO -    Offset：[0, 3456, 7680]
2025-09-20 17:30:39 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:39 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=11136
2025-09-20 17:30:39 - misc:366 - INFO -    各样本点数：[6144, 4992]（均为384的倍数）
2025-09-20 17:30:39 - misc:367 - INFO -    拼接后维度：coord=torch.Size([11136, 3])，feat=torch.Size([11136, 9])，label=torch.Size([11136])
2025-09-20 17:30:39 - misc:368 - INFO -    Offset：[0, 6144, 11136]
2025-09-20 17:30:39 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:39 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=11520
2025-09-20 17:30:39 - misc:366 - INFO -    各样本点数：[6144, 5376]（均为384的倍数）
2025-09-20 17:30:39 - misc:367 - INFO -    拼接后维度：coord=torch.Size([11520, 3])，feat=torch.Size([11520, 9])，label=torch.Size([11520])
2025-09-20 17:30:39 - misc:368 - INFO -    Offset：[0, 6144, 11520]
2025-09-20 17:30:39 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:39 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:30:39 - misc:366 - INFO -    各样本点数：[2688, 4224]（均为384的倍数）
2025-09-20 17:30:39 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:30:39 - misc:368 - INFO -    Offset：[0, 2688, 6912]
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4992], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:30:39 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=11136, unpad长度将设为=11136
2025-09-20 17:30:39 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:39 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:30:39 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 17:30:39 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:30:39 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 32])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4992], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 32])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2496], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:30:39 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5568, unpad长度将设为=5568
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5216，校正前pad范围: [0, 5215]，校正后范围: [0, 5215]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5216
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5216
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5216, 64])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2496], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5216，校正前pad范围: [0, 5215]，校正后范围: [0, 5215]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5216
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5216
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5216, 64])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:39 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:30:39 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:30:39 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2784, unpad长度将设为=2784
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2332，校正前pad范围: [0, 2331]，校正后范围: [0, 2331]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2332，校正前pad范围: [0, 2331]，校正后范围: [0, 2331]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:30:39 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:39 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2332，校正前pad范围: [0, 2331]，校正后范围: [0, 2331]
2025-09-20 17:30:39 - misc:366 - INFO -    各样本点数：[4608, 4608]（均为384的倍数）
2025-09-20 17:30:39 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:30:39 - misc:368 - INFO -    Offset：[0, 4608, 9216]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2332，校正前pad范围: [0, 2331]，校正后范围: [0, 2331]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2332，校正前pad范围: [0, 2331]，校正后范围: [0, 2331]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2332，校正前pad范围: [0, 2331]，校正后范围: [0, 2331]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1392], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 624], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:30:39 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1392, unpad长度将设为=1392
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=728，校正前pad范围: [0, 727]，校正后范围: [0, 727]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1392], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 728
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 728
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([728]), 最大索引: 0, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([728, 256])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1392], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 624], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=728，校正前pad范围: [0, 727]，校正后范围: [0, 727]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1392], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 728
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 728
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([728]), 最大索引: 0, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([728, 256])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2332，校正前pad范围: [0, 2331]，校正后范围: [0, 2331]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1248], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2332，校正前pad范围: [0, 2331]，校正后范围: [0, 2331]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2784], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2332
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2332]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2332, 128])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2496], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5216，校正前pad范围: [0, 5215]，校正后范围: [0, 5215]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5216
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5216
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5216, 64])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2496], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:30:39 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5216，校正前pad范围: [0, 5215]，校正后范围: [0, 5215]
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5568], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5216
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5216
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5216]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5216, 64])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4992], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 64])
2025-09-20 17:30:39 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:39 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:30:39 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 4992], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:30:39 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:39 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11136], device='cuda:0')
2025-09-20 17:30:39 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:30:39 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:30:39 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11136
2025-09-20 17:30:39 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11136]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:30:39 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:39 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11136, 64])
2025-09-20 17:30:39 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:30:39 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:30:39 - misc:366 - INFO -    各样本点数：[3456, 4992]（均为384的倍数）
2025-09-20 17:30:39 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:30:39 - misc:368 - INFO -    Offset：[0, 3456, 8448]
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 5376], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 17:30:40 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=11520, unpad长度将设为=11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 32])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 5376], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 32])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2688], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:30:40 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5760, unpad长度将设为=5760
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5760，校正前最大索引=5759, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8900
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8900
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8900]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8900, 64])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2688], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5760，校正前最大索引=5759, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8900
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8900
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8900]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8900, 64])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2880, unpad长度将设为=2880
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3944]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3944, 128])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3944]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3944, 128])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3944]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3944, 128])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3944]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3944, 128])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3944]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3944, 128])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3944]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3944, 128])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1440], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 672], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:30:40 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1440, unpad长度将设为=1440
2025-09-20 17:30:40 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1208，校正前pad范围: [0, 1207]，校正后范围: [0, 1207]
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1440], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 768, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 256])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1440], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 672], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:30:40 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1208，校正前pad范围: [0, 1207]，校正后范围: [0, 1207]
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1440], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1208
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1208
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1208]), 最大索引: 768, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1208, 256])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3944]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3944, 128])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1344], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2880，校正前最大索引=2879, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2880], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3944
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3944]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3944, 128])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2688], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5760，校正前最大索引=5759, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8900
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8900
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8900]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8900, 64])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 2688], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:30:40 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=5760，校正前最大索引=5759, 最小索引=0
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 5760], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8900
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8900
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8900]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8900, 64])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 5376], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 64])
2025-09-20 17:30:40 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:30:40 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:30:40 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 5376], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 17:30:40 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:30:40 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  6144, 11520], device='cuda:0')
2025-09-20 17:30:40 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:30:40 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:30:40 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 17:30:40 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:30:40 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:30:40 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 64])
