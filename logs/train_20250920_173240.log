2025-09-20 17:32:41 - wind_shear:30 - INFO - WindShearDataset train split: 8935 scenes
2025-09-20 17:32:41 - wind_shear:30 - INFO - WindShearDataset val split: 2130 scenes
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu154_labeled.csv
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas1/gg100_labeled.csv
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o85_labeled.csv
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z21_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] gg100_labeled.csv | 点数2410→2688（384的倍数）
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt126_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] uu154_labeled.csv | 点数2812→3072（384的倍数）
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a127_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] z21_labeled.csv | 点数4294→4608（384的倍数）
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] o85_labeled.csv | 点数5066→5376（384的倍数）
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas3/u40_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] tt126_labeled.csv | 点数2641→2688（384的倍数）
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m96_labeled.csv
2025-09-20 17:32:41 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:41 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=5376
2025-09-20 17:32:41 - misc:366 - INFO -    各样本点数：[2688, 2688]（均为384的倍数）
2025-09-20 17:32:41 - misc:367 - INFO -    拼接后维度：coord=torch.Size([5376, 3])，feat=torch.Size([5376, 9])，label=torch.Size([5376])
2025-09-20 17:32:41 - misc:368 - INFO -    Offset：[0, 2688, 5376]
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll16_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] a127_labeled.csv | 点数3482→3840（384的倍数）
2025-09-20 17:32:41 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:41 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:32:41 - misc:366 - INFO -    各样本点数：[3072, 3840]（均为384的倍数）
2025-09-20 17:32:41 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:32:41 - misc:368 - INFO -    Offset：[0, 3072, 6912]
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x108_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] u40_labeled.csv | 点数3923→4224（384的倍数）
2025-09-20 17:32:41 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:41 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:32:41 - misc:366 - INFO -    各样本点数：[4608, 4224]（均为384的倍数）
2025-09-20 17:32:41 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:32:41 - misc:368 - INFO -    Offset：[0, 4608, 8832]
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu27_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] m96_labeled.csv | 点数4313→4608（384的倍数）
2025-09-20 17:32:41 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:41 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:32:41 - misc:366 - INFO -    各样本点数：[5376, 4608]（均为384的倍数）
2025-09-20 17:32:41 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:32:41 - misc:368 - INFO -    Offset：[0, 5376, 9984]
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas2/vv174_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] x108_labeled.csv | 点数3759→3840（384的倍数）
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] uu27_labeled.csv | 点数1716→1920（384的倍数）
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee185_labeled.csv
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll94_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] ll16_labeled.csv | 点数5923→6144（384的倍数）
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll9_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] vv174_labeled.csv | 点数3187→3456（384的倍数）
2025-09-20 17:32:41 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y128_labeled.csv
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] ee185_labeled.csv | 点数4393→4608（384的倍数）
2025-09-20 17:32:41 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:41 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:32:41 - misc:366 - INFO -    各样本点数：[1920, 4608]（均为384的倍数）
2025-09-20 17:32:41 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:32:41 - misc:368 - INFO -    Offset：[0, 1920, 6528]
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] ll94_labeled.csv | 点数5319→5376（384的倍数）
2025-09-20 17:32:41 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:41 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:32:41 - misc:366 - INFO -    各样本点数：[3840, 5376]（均为384的倍数）
2025-09-20 17:32:41 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:32:41 - misc:368 - INFO -    Offset：[0, 3840, 9216]
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] ll9_labeled.csv | 点数6067→6144（384的倍数）
2025-09-20 17:32:41 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:41 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=12288
2025-09-20 17:32:41 - misc:366 - INFO -    各样本点数：[6144, 6144]（均为384的倍数）
2025-09-20 17:32:41 - misc:367 - INFO -    拼接后维度：coord=torch.Size([12288, 3])，feat=torch.Size([12288, 9])，label=torch.Size([12288])
2025-09-20 17:32:41 - misc:368 - INFO -    Offset：[0, 6144, 12288]
2025-09-20 17:32:41 - wind_shear:161 - DEBUG - [补点] y128_labeled.csv | 点数3530→3840（384的倍数）
2025-09-20 17:32:41 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:41 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:32:41 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 17:32:41 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:32:41 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (37)_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] eeee (37)_labeled.csv | 点数4072→4224（384的倍数）
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b18_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] b18_labeled.csv | 点数4412→4608（384的倍数）
2025-09-20 17:32:42 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:42 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:32:42 - misc:366 - INFO -    各样本点数：[4224, 4608]（均为384的倍数）
2025-09-20 17:32:42 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:32:42 - misc:368 - INFO -    Offset：[0, 4224, 8832]
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc125_labeled.csv
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/q2_labeled.csv
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll106_labeled.csv
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll59_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] q2_labeled.csv | 点数2439→2688（384的倍数）
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w96_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] cc125_labeled.csv | 点数3445→3456（384的倍数）
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(94)_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] ll106_labeled.csv | 点数5550→5760（384的倍数）
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] ll59_labeled.csv | 点数5830→6144（384的倍数）
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g158_labeled.csv
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss147_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] w96_labeled.csv | 点数3461→3840（384的倍数）
2025-09-20 17:32:42 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:42 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:32:42 - misc:366 - INFO -    各样本点数：[2688, 3840]（均为384的倍数）
2025-09-20 17:32:42 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:32:42 - misc:368 - INFO -    Offset：[0, 2688, 6528]
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c133_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] bbbbb(94)_labeled.csv | 点数3564→3840（384的倍数）
2025-09-20 17:32:42 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:42 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:32:42 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 17:32:42 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:32:42 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas2/aaaa (22)_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] ss147_labeled.csv | 点数3344→3456（384的倍数）
2025-09-20 17:32:42 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:42 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:42 - misc:366 - INFO -    各样本点数：[6144, 3456]（均为384的倍数）
2025-09-20 17:32:42 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:42 - misc:368 - INFO -    Offset：[0, 6144, 9600]
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb174_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] g158_labeled.csv | 点数4776→4992（384的倍数）
2025-09-20 17:32:42 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:42 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10752
2025-09-20 17:32:42 - misc:366 - INFO -    各样本点数：[5760, 4992]（均为384的倍数）
2025-09-20 17:32:42 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10752, 3])，feat=torch.Size([10752, 9])，label=torch.Size([10752])
2025-09-20 17:32:42 - misc:368 - INFO -    Offset：[0, 5760, 10752]
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] c133_labeled.csv | 点数3615→3840（384的倍数）
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll36_labeled.csv
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk29_labeled.csv
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] aaaa (22)_labeled.csv | 点数4368→4608（384的倍数）
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas4/l51_labeled.csv
2025-09-20 17:32:42 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] bb174_labeled.csv | 点数4457→4608（384的倍数）
2025-09-20 17:32:42 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:42 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:42 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:32:42 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:42 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:42 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas1/e48_labeled.csv
2025-09-20 17:32:42 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:42 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:42 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:42 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:42 - wind_shear:161 - DEBUG - [补点] kk29_labeled.csv | 点数4867→4992（384的倍数）
2025-09-20 17:32:42 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:42 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:32:42 - misc:366 - INFO -    各样本点数：[3840, 4992]（均为384的倍数）
2025-09-20 17:32:42 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:32:42 - misc:368 - INFO -    Offset：[0, 3840, 8832]
2025-09-20 17:32:42 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:32:42 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:42 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:42 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:42 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:42 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:42 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:42 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:42 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:42 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:42 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:42 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:42 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:32:42 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:42 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:42 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:42 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:42 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:42 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:32:42 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:42 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:42 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:42 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:42 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:42 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:42 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:42 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:42 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - wind_shear:161 - DEBUG - [补点] ll36_labeled.csv | 点数5982→6144（384的倍数）
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:43 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7244
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7244
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7244]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7244, 64])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7244
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7244
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7244]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7244, 64])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh98_labeled.csv
2025-09-20 17:32:43 - wind_shear:161 - DEBUG - [补点] l51_labeled.csv | 点数4753→4992（384的倍数）
2025-09-20 17:32:43 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:43 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:43 - misc:366 - INFO -    各样本点数：[4608, 4992]（均为384的倍数）
2025-09-20 17:32:43 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:43 - misc:368 - INFO -    Offset：[0, 4608, 9600]
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:43 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3046]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3046, 128])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3046]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3046, 128])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3046]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3046, 128])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3046]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3046, 128])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3046]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3046, 128])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3046]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3046, 128])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - wind_shear:161 - DEBUG - [补点] e48_labeled.csv | 点数5051→5376（384的倍数）
2025-09-20 17:32:43 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:43 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:32:43 - misc:366 - INFO -    各样本点数：[4608, 5376]（均为384的倍数）
2025-09-20 17:32:43 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:32:43 - misc:368 - INFO -    Offset：[0, 4608, 9984]
2025-09-20 17:32:43 - wind_shear:161 - DEBUG - [补点] hh98_labeled.csv | 点数2123→2304（384的倍数）
2025-09-20 17:32:43 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:43 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:32:43 - misc:366 - INFO -    各样本点数：[6144, 2304]（均为384的倍数）
2025-09-20 17:32:43 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:32:43 - misc:368 - INFO -    Offset：[0, 6144, 8448]
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 432], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:43 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:43 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa90_labeled.csv
2025-09-20 17:32:43 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=903，校正前pad范围: [0, 902]，校正后范围: [0, 902]
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 903
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 903
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([903]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([903, 256])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 432], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:43 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=903，校正前pad范围: [0, 902]，校正后范围: [0, 902]
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 903
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 903
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([903]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([903, 256])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3046]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3046, 128])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3046
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3046]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3046, 128])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7244
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7244
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7244]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7244, 64])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:43 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7244
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7244
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7244]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7244, 64])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:43 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:43 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:43 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:43 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:43 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:43 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:32:43 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:43 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:43 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:43 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:43 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:43 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:43 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:43 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:43 - wind_shear:161 - DEBUG - [补点] aa90_labeled.csv | 点数3499→3840（384的倍数）
2025-09-20 17:32:43 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a17_labeled.csv
2025-09-20 17:32:43 - wind_shear:161 - DEBUG - [补点] a17_labeled.csv | 点数4128→4224（384的倍数）
2025-09-20 17:32:43 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:43 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:32:43 - misc:366 - INFO -    各样本点数：[3840, 4224]（均为384的倍数）
2025-09-20 17:32:43 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:32:43 - misc:368 - INFO -    Offset：[0, 3840, 8064]
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2242，校正前pad范围: [0, 2241]，校正后范围: [0, 2241]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2242
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2242
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2242]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2242, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2242，校正前pad范围: [0, 2241]，校正后范围: [0, 2241]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2242
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2242
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2242]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2242, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=829，校正前pad范围: [0, 828]，校正后范围: [0, 828]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=829，校正前pad范围: [0, 828]，校正后范围: [0, 828]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=829，校正前pad范围: [0, 828]，校正后范围: [0, 828]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=829，校正前pad范围: [0, 828]，校正后范围: [0, 828]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=829，校正前pad范围: [0, 828]，校正后范围: [0, 828]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=829，校正前pad范围: [0, 828]，校正后范围: [0, 828]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 480], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=261，校正前pad范围: [0, 260]，校正后范围: [0, 260]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 261
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 261
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([261]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([261, 256])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([336, 480], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=261，校正前pad范围: [0, 260]，校正后范围: [0, 260]
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo79_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 336, 816], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(336, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数336，K=21
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 261
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 261
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([261]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([261, 256])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=829，校正前pad范围: [0, 828]，校正后范围: [0, 828]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=829，校正前pad范围: [0, 828]，校正后范围: [0, 828]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1632], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=84
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 829
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([829]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([829, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2242，校正前pad范围: [0, 2241]，校正后范围: [0, 2241]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2242
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2242
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2242]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2242, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1920], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2242，校正前pad范围: [0, 2241]，校正后范围: [0, 2241]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 3264], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=336
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2242
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2242
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2242]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2242, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3840], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 6528], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10752], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10752, unpad长度将设为=10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10752], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10752], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10752], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 32])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas2/dd8_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4994，校正前pad范围: [0, 4993]，校正后范围: [0, 4993]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4994
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4994
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4994]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4994, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4994，校正前pad范围: [0, 4993]，校正后范围: [0, 4993]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4994
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4994
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4994]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4994, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2185，校正前pad范围: [0, 2184]，校正后范围: [0, 2184]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2185]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2185, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2185，校正前pad范围: [0, 2184]，校正后范围: [0, 2184]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2185]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2185, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2185，校正前pad范围: [0, 2184]，校正后范围: [0, 2184]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2185]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2185, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2185，校正前pad范围: [0, 2184]，校正后范围: [0, 2184]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2185]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2185, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2185，校正前pad范围: [0, 2184]，校正后范围: [0, 2184]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - wind_shear:161 - DEBUG - [补点] oo79_labeled.csv | 点数4647→4992（384的倍数）
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2185]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2185, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2185，校正前pad范围: [0, 2184]，校正后范围: [0, 2184]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2185]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2185, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 624], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=669，校正前pad范围: [0, 668]，校正后范围: [0, 668]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 669
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 669
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([669]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([669, 256])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 624], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=669，校正前pad范围: [0, 668]，校正后范围: [0, 668]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 669
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 669
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([669]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([669, 256])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2185，校正前pad范围: [0, 2184]，校正后范围: [0, 2184]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2185]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2185, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2185，校正前pad范围: [0, 2184]，校正后范围: [0, 2184]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2185
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2185]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2185, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4994，校正前pad范围: [0, 4993]，校正后范围: [0, 4993]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4994
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4994
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4994]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4994, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4994，校正前pad范围: [0, 4993]，校正后范围: [0, 4993]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a141_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4994
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4994
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4994]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4994, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10752], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10752], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5760, 10752], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5760, 10752], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10752
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10752]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10752, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2437，校正前pad范围: [0, 2436]，校正后范围: [0, 2436]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas2/pp98_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2437
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2437
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2437]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2437, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2437，校正前pad范围: [0, 2436]，校正后范围: [0, 2436]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2437
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2437
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2437]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2437, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - wind_shear:161 - DEBUG - [补点] dd8_labeled.csv | 点数5663→5760（384的倍数）
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=944，校正前pad范围: [0, 943]，校正后范围: [0, 943]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([944]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([944, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=944，校正前pad范围: [0, 943]，校正后范围: [0, 943]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([944]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([944, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=944，校正前pad范围: [0, 943]，校正后范围: [0, 943]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([944]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([944, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=944，校正前pad范围: [0, 943]，校正后范围: [0, 943]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([944]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([944, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=944，校正前pad范围: [0, 943]，校正后范围: [0, 943]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas4/r18_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([944]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([944, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - wind_shear:161 - DEBUG - [补点] a141_labeled.csv | 点数4506→4608（384的倍数）
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:44 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:44 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:32:44 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:44 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=944，校正前pad范围: [0, 943]，校正后范围: [0, 943]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([944]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([944, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=304，校正前pad范围: [0, 303]，校正后范围: [0, 303]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 304
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 304
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([304]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([304, 256])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=304，校正前pad范围: [0, 303]，校正后范围: [0, 303]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 304
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 304
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([304]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([304, 256])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=944，校正前pad范围: [0, 943]，校正后范围: [0, 943]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([944]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([944, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=944，校正前pad范围: [0, 943]，校正后范围: [0, 943]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 944
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([944]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([944, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2437，校正前pad范围: [0, 2436]，校正后范围: [0, 2436]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2437
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2437
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2437]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2437, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2437，校正前pad范围: [0, 2436]，校正后范围: [0, 2436]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2437
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2437
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2437]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2437, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:44 - wind_shear:161 - DEBUG - [补点] r18_labeled.csv | 点数3173→3456（384的倍数）
2025-09-20 17:32:44 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:44 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:32:44 - misc:366 - INFO -    各样本点数：[5760, 3456]（均为384的倍数）
2025-09-20 17:32:44 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:32:44 - misc:368 - INFO -    Offset：[0, 5760, 9216]
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:44 - wind_shear:161 - DEBUG - [补点] pp98_labeled.csv | 点数4759→4992（384的倍数）
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (75)_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4422，校正前pad范围: [0, 4421]，校正后范围: [0, 4421]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4422
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4422
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4422]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4422, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4422，校正前pad范围: [0, 4421]，校正后范围: [0, 4421]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4422
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4422
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4422]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4422, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1859，校正前pad范围: [0, 1858]，校正后范围: [0, 1858]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo90_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1859]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1859, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1859，校正前pad范围: [0, 1858]，校正后范围: [0, 1858]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1859]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1859, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1859，校正前pad范围: [0, 1858]，校正后范围: [0, 1858]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1859]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1859, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1859，校正前pad范围: [0, 1858]，校正后范围: [0, 1858]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1859]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1859, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1859，校正前pad范围: [0, 1858]，校正后范围: [0, 1858]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1859]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1859, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1859，校正前pad范围: [0, 1858]，校正后范围: [0, 1858]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1859]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1859, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 672], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=577，校正前pad范围: [0, 576]，校正后范围: [0, 576]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 577
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 577
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([577]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([577, 256])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 672], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=577，校正前pad范围: [0, 576]，校正后范围: [0, 576]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 577
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 577
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([577]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([577, 256])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1859，校正前pad范围: [0, 1858]，校正后范围: [0, 1858]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1859]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1859, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1859，校正前pad范围: [0, 1858]，校正后范围: [0, 1858]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1859
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1859]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1859, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4422，校正前pad范围: [0, 4421]，校正后范围: [0, 4421]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4422
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4422
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4422]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4422, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4422，校正前pad范围: [0, 4421]，校正后范围: [0, 4421]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4422
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4422
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4422]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4422, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - wind_shear:161 - DEBUG - [补点] oo90_labeled.csv | 点数4231→4608（384的倍数）
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:32:44 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:44 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:44 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:32:44 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:44 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas1/gg23_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:44 - wind_shear:161 - DEBUG - [补点] iiii (75)_labeled.csv | 点数4675→4992（384的倍数）
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3405，校正前pad范围: [0, 3404]，校正后范围: [0, 3404]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3405
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3405
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3405]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3405, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3405，校正前pad范围: [0, 3404]，校正后范围: [0, 3404]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3405
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3405
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3405]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3405, 64])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:44 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:32:44 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas1/b45_labeled.csv
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1466，校正前pad范围: [0, 1465]，校正后范围: [0, 1465]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1466
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1466
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1466]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1466, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1466，校正前pad范围: [0, 1465]，校正后范围: [0, 1465]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1466
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1466
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1466]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1466, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1466，校正前pad范围: [0, 1465]，校正后范围: [0, 1465]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1466
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1466
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1466]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1466, 128])
2025-09-20 17:32:44 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:44 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:44 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:44 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1466，校正前pad范围: [0, 1465]，校正后范围: [0, 1465]
2025-09-20 17:32:44 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:44 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:44 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:44 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:44 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:44 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1466
2025-09-20 17:32:44 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1466
2025-09-20 17:32:44 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:44 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:44 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1466]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:44 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1466, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1466，校正前pad范围: [0, 1465]，校正后范围: [0, 1465]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1466
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1466
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1466]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1466, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1466，校正前pad范围: [0, 1465]，校正后范围: [0, 1465]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1466
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1466
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1466]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1466, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=474，校正前pad范围: [0, 473]，校正后范围: [0, 473]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 474
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 474
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([474]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([474, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 624], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=474，校正前pad范围: [0, 473]，校正后范围: [0, 473]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1104], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 474
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 474
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([474]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([474, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1466，校正前pad范围: [0, 1465]，校正后范围: [0, 1465]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1466
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1466
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1466]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1466, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1466，校正前pad范围: [0, 1465]，校正后范围: [0, 1465]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2208], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1466
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1466
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1466]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1466, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3405，校正前pad范围: [0, 3404]，校正后范围: [0, 3404]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3405
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3405
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3405]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3405, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2496], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3405，校正前pad范围: [0, 3404]，校正后范围: [0, 3404]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4416], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3405
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3405
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3405]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3405, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4992], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8832], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] b45_labeled.csv | 点数4322→4608（384的倍数）
2025-09-20 17:32:45 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:45 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:45 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:32:45 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:45 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 8448], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] gg23_labeled.csv | 点数5074→5376（384的倍数）
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 8448], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 8448], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 8448], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h54_labeled.csv
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6393
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6393
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6393]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6393, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6393
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6393
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6393]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6393, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas1/mm193_labeled.csv
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2780]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2780, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2780]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2780, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2780]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2780, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2780]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2780, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2780]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2780, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2780]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2780, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 288], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=832，校正前pad范围: [0, 831]，校正后范围: [0, 831]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 832
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 832
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([832]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([832, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 288], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=832，校正前pad范围: [0, 831]，校正后范围: [0, 831]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 832
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 832
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([832]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([832, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2780]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2780, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2780
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2780]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2780, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6393
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6393
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6393]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6393, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6393
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6393
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6393]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6393, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 8448], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 8448], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 8448], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 8448], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] h54_labeled.csv | 点数3332→3456（384的倍数）
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(189)_labeled.csv
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] mm193_labeled.csv | 点数4117→4224（384的倍数）
2025-09-20 17:32:45 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:45 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:45 - misc:366 - INFO -    各样本点数：[5376, 4224]（均为384的倍数）
2025-09-20 17:32:45 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:45 - misc:368 - INFO -    Offset：[0, 5376, 9600]
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4156，校正前pad范围: [0, 4155]，校正后范围: [0, 4155]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4156
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4156
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4156]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4156, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4156，校正前pad范围: [0, 4155]，校正后范围: [0, 4155]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4156
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4156
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4156]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4156, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1711，校正前pad范围: [0, 1710]，校正后范围: [0, 1710]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1711]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1711, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1711，校正前pad范围: [0, 1710]，校正后范围: [0, 1710]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1711]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1711, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1711，校正前pad范围: [0, 1710]，校正后范围: [0, 1710]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1711]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1711, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1711，校正前pad范围: [0, 1710]，校正后范围: [0, 1710]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1711]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1711, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1711，校正前pad范围: [0, 1710]，校正后范围: [0, 1710]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1711]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1711, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1711，校正前pad范围: [0, 1710]，校正后范围: [0, 1710]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1711]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1711, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn46_labeled.csv
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=534，校正前pad范围: [0, 533]，校正后范围: [0, 533]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] bbbbb(189)_labeled.csv | 点数3272→3456（384的倍数）
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 534
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 534
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([534]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:45 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:32:45 - misc:366 - INFO -    各样本点数：[3456, 3456]（均为384的倍数）
2025-09-20 17:32:45 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:32:45 - misc:368 - INFO -    Offset：[0, 3456, 6912]
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([534, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=534，校正前pad范围: [0, 533]，校正后范围: [0, 533]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 534
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 534
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([534]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([534, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1711，校正前pad范围: [0, 1710]，校正后范围: [0, 1710]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1711]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1711, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1711，校正前pad范围: [0, 1710]，校正后范围: [0, 1710]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1711
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1711]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1711, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4156，校正前pad范围: [0, 4155]，校正后范围: [0, 4155]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4156
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4156
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4156]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4156, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4156，校正前pad范围: [0, 4155]，校正后范围: [0, 4155]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4156
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4156
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4156]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4156, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2827，校正前pad范围: [0, 2826]，校正后范围: [0, 2826]
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o2_labeled.csv
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2827
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2827
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2827]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2827, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2827，校正前pad范围: [0, 2826]，校正后范围: [0, 2826]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2827
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2827
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2827]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2827, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1129，校正前pad范围: [0, 1128]，校正后范围: [0, 1128]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1129]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1129, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1129，校正前pad范围: [0, 1128]，校正后范围: [0, 1128]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1129]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1129, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1129，校正前pad范围: [0, 1128]，校正后范围: [0, 1128]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1129]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1129, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1129，校正前pad范围: [0, 1128]，校正后范围: [0, 1128]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1129]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1129, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1129，校正前pad范围: [0, 1128]，校正后范围: [0, 1128]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1129]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1129, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1129，校正前pad范围: [0, 1128]，校正后范围: [0, 1128]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1129]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1129, 128])
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] nn46_labeled.csv | 点数5459→5760（384的倍数）
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=356，校正前pad范围: [0, 355]，校正后范围: [0, 355]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 356
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 356
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([356]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([356, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 528], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=356，校正前pad范围: [0, 355]，校正后范围: [0, 355]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1008], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 356
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 356
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([356]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([356, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1129，校正前pad范围: [0, 1128]，校正后范围: [0, 1128]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1129]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1129, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1056], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1129，校正前pad范围: [0, 1128]，校正后范围: [0, 1128]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2016], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1129
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1129]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1129, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2827，校正前pad范围: [0, 2826]，校正后范围: [0, 2826]
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(210)_labeled.csv
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2827
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2827
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2827]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2827, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2112], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2827，校正前pad范围: [0, 2826]，校正后范围: [0, 2826]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4032], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2827
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2827
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2827]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2827, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4224], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8064], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu41_labeled.csv
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] o2_labeled.csv | 点数4014→4224（384的倍数）
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3377，校正前pad范围: [0, 3376]，校正后范围: [0, 3376]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3377
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3377
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3377]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3377, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3377，校正前pad范围: [0, 3376]，校正后范围: [0, 3376]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3377
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3377
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3377]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3377, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(36)_labeled.csv
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1421，校正前pad范围: [0, 1420]，校正后范围: [0, 1420]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1421]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1421, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1421，校正前pad范围: [0, 1420]，校正后范围: [0, 1420]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1421]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1421, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1421，校正前pad范围: [0, 1420]，校正后范围: [0, 1420]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1421]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1421, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1421，校正前pad范围: [0, 1420]，校正后范围: [0, 1420]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1421]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1421, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] bbbbb(210)_labeled.csv | 点数3431→3456（384的倍数）
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1421，校正前pad范围: [0, 1420]，校正后范围: [0, 1420]
2025-09-20 17:32:45 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:45 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:32:45 - misc:366 - INFO -    各样本点数：[5760, 3456]（均为384的倍数）
2025-09-20 17:32:45 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:32:45 - misc:368 - INFO -    Offset：[0, 5760, 9216]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1421]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1421, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1421，校正前pad范围: [0, 1420]，校正后范围: [0, 1420]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1421]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1421, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] uu41_labeled.csv | 点数1817→1920（384的倍数）
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=452，校正前pad范围: [0, 451]，校正后范围: [0, 451]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 452
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 452
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([452]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([452, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=452，校正前pad范围: [0, 451]，校正后范围: [0, 451]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 452
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 452
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([452]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([452, 256])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i25_labeled.csv
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1421，校正前pad范围: [0, 1420]，校正后范围: [0, 1420]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1421]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1421, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1421，校正前pad范围: [0, 1420]，校正后范围: [0, 1420]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1421
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1421]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1421, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3377，校正前pad范围: [0, 3376]，校正后范围: [0, 3376]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3377
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3377
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3377]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3377, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3377，校正前pad范围: [0, 3376]，校正后范围: [0, 3376]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3377
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3377
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3377]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3377, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:32:45 - wind_shear:161 - DEBUG - [补点] bbbbb(36)_labeled.csv | 点数4391→4608（384的倍数）
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:45 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:45 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:32:45 - misc:366 - INFO -    各样本点数：[4224, 4608]（均为384的倍数）
2025-09-20 17:32:45 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:32:45 - misc:368 - INFO -    Offset：[0, 4224, 8832]
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:32:45 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn214_labeled.csv
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4995
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4995
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4995]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4995, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:45 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4995
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4995
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4995]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4995, 64])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:45 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2218，校正前pad范围: [0, 2217]，校正后范围: [0, 2217]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2218
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2218
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2218]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2218, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2218，校正前pad范围: [0, 2217]，校正后范围: [0, 2217]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2218
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2218
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2218]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2218, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2218，校正前pad范围: [0, 2217]，校正后范围: [0, 2217]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2218
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2218
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2218]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2218, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2218，校正前pad范围: [0, 2217]，校正后范围: [0, 2217]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:45 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:45 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:45 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2218
2025-09-20 17:32:45 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2218
2025-09-20 17:32:45 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:45 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:45 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2218]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:45 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2218, 128])
2025-09-20 17:32:45 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:45 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:45 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:45 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:45 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2218，校正前pad范围: [0, 2217]，校正后范围: [0, 2217]
2025-09-20 17:32:45 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:45 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2218
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2218
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2218]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2218, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2218，校正前pad范围: [0, 2217]，校正后范围: [0, 2217]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2218
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2218
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2218]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2218, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 432], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=693，校正前pad范围: [0, 692]，校正后范围: [0, 692]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 693
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 693
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([693]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([693, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 432], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=693，校正前pad范围: [0, 692]，校正后范围: [0, 692]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 693
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 693
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([693]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([693, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2218，校正前pad范围: [0, 2217]，校正后范围: [0, 2217]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] i25_labeled.csv | 点数5003→5376（384的倍数）
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:46 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:32:46 - misc:366 - INFO -    各样本点数：[1920, 5376]（均为384的倍数）
2025-09-20 17:32:46 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:32:46 - misc:368 - INFO -    Offset：[0, 1920, 7296]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2218
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2218
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2218]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2218, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2218，校正前pad范围: [0, 2217]，校正后范围: [0, 2217]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2218
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2218
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2218]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2218, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4995
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4995
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4995]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4995, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4995
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4995
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4995]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4995, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v61_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] nn214_labeled.csv | 点数5238→5376（384的倍数）
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6887
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6887
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6887]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6887, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6887
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6887
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6887]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6887, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas2/dd99_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=848，校正前pad范围: [0, 847]，校正后范围: [0, 847]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 848
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 848
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([848]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([848, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=848，校正前pad范围: [0, 847]，校正后范围: [0, 847]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 848
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 848
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([848]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([848, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6887
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6887
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6887]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6887, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6887
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6887
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6887]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6887, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] v61_labeled.csv | 点数4257→4608（384的倍数）
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas2/vv52_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo140_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4152，校正前pad范围: [0, 4151]，校正后范围: [0, 4151]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4152
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4152
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4152]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4152, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4152，校正前pad范围: [0, 4151]，校正后范围: [0, 4151]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4152
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4152
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4152]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4152, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1706，校正前pad范围: [0, 1705]，校正后范围: [0, 1705]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1706，校正前pad范围: [0, 1705]，校正后范围: [0, 1705]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] dd99_labeled.csv | 点数4827→4992（384的倍数）
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:32:46 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:46 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=10368
2025-09-20 17:32:46 - misc:366 - INFO -    各样本点数：[5376, 4992]（均为384的倍数）
2025-09-20 17:32:46 - misc:367 - INFO -    拼接后维度：coord=torch.Size([10368, 3])，feat=torch.Size([10368, 9])，label=torch.Size([10368])
2025-09-20 17:32:46 - misc:368 - INFO -    Offset：[0, 5376, 10368]
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1706，校正前pad范围: [0, 1705]，校正后范围: [0, 1705]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1706，校正前pad范围: [0, 1705]，校正后范围: [0, 1705]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1706，校正前pad范围: [0, 1705]，校正后范围: [0, 1705]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1706，校正前pad范围: [0, 1705]，校正后范围: [0, 1705]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=531，校正前pad范围: [0, 530]，校正后范围: [0, 530]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 531
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 531
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([531]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([531, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=531，校正前pad范围: [0, 530]，校正后范围: [0, 530]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 531
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 531
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([531]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([531, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1706，校正前pad范围: [0, 1705]，校正后范围: [0, 1705]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1706，校正前pad范围: [0, 1705]，校正后范围: [0, 1705]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1706
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1706]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1706, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4152，校正前pad范围: [0, 4151]，校正后范围: [0, 4151]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4152
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4152
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4152]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4152, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] vv52_labeled.csv | 点数2361→2688（384的倍数）
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4152，校正前pad范围: [0, 4151]，校正后范围: [0, 4151]
2025-09-20 17:32:46 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:46 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:32:46 - misc:366 - INFO -    各样本点数：[4608, 2688]（均为384的倍数）
2025-09-20 17:32:46 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:32:46 - misc:368 - INFO -    Offset：[0, 4608, 7296]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4152
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4152
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4152]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4152, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] oo140_labeled.csv | 点数4244→4608（384的倍数）
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v54_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230315/datas1/cc71_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7122
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7122
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7122]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7122, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7122
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7122
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7122]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7122, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 528], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=901，校正前pad范围: [0, 900]，校正后范围: [0, 900]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 901
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 901
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([901]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([901, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 528], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=901，校正前pad范围: [0, 900]，校正后范围: [0, 900]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 901
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 901
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([901]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([901, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2937
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2937]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2937, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7122
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7122
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7122]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7122, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7122
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7122
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7122]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7122, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] v54_labeled.csv | 点数4365→4608（384的倍数）
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas3/u6_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 6912], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 6912], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 6912], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 6912], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] cc71_labeled.csv | 点数4893→4992（384的倍数）
2025-09-20 17:32:46 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:46 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:46 - misc:366 - INFO -    各样本点数：[4608, 4992]（均为384的倍数）
2025-09-20 17:32:46 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:46 - misc:368 - INFO -    Offset：[0, 4608, 9600]
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3456], device='cuda:0')
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas1/period2_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2304，校正前pad范围: [0, 2303]，校正后范围: [0, 2303]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2304]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2304, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2304，校正前pad范围: [0, 2303]，校正后范围: [0, 2303]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2304]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2304, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 432], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=266，校正前pad范围: [0, 265]，校正后范围: [0, 265]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 266
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 266
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([266]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([266, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 432], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=266，校正前pad范围: [0, 265]，校正后范围: [0, 265]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 266
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 266
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([266]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([266, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=860，校正前pad范围: [0, 859]，校正后范围: [0, 859]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 860
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([860]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([860, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2304，校正前pad范围: [0, 2303]，校正后范围: [0, 2303]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2304]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2304, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2304，校正前pad范围: [0, 2303]，校正后范围: [0, 2303]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2304]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2304, 64])
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] u6_labeled.csv | 点数3967→4224（384的倍数）
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:46 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:32:46 - misc:366 - INFO -    各样本点数：[4608, 4224]（均为384的倍数）
2025-09-20 17:32:46 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:32:46 - misc:368 - INFO -    Offset：[0, 4608, 8832]
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 6912], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 6912], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 6912], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 6912], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:32:46 - wind_shear:161 - DEBUG - [补点] period2_labeled.csv | 点数3461→3840（384的倍数）
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(73)_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:32:46 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h112_labeled.csv
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=2880
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6935
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6935
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6935]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6935, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6935
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6935
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6935]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6935, 64])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2875]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2875, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2875]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2875, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2875]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2875, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2875]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2875, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2875]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2875, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:46 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2875
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2875]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2875, 128])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 432], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:46 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=872，校正前pad范围: [0, 871]，校正后范围: [0, 871]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:32:46 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:46 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 872
2025-09-20 17:32:46 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 872
2025-09-20 17:32:46 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:46 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:46 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([872]), 最大索引: 720, 最小索引: 0
2025-09-20 17:32:46 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([872, 256])
2025-09-20 17:32:46 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:46 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:46 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([720, 432], device='cuda:0')
2025-09-20 17:32:46 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:46 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=872，校正前pad范围: [0, 871]，校正后范围: [0, 871]
2025-09-20 17:32:46 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:46 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:46 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  720, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(720, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数720，K=45
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 872
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 872
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([872]), 最大索引: 720, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([872, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2875
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2875
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2875]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2875, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1440,  864], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1440, 2304], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1440, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1440，K=180
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2875
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2875
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2875]), 最大索引: 1440, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2875, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6935
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6935
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6935]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6935, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2880, 1728], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2880, 4608], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2880, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2880，K=720
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6935
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6935
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6935]), 最大索引: 2880, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6935, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5760, 3456], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5760, 9216], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5760, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5760，K=1440
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 5760, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] bbbbb(73)_labeled.csv | 点数3802→3840（384的倍数）
2025-09-20 17:32:47 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:47 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:32:47 - misc:366 - INFO -    各样本点数：[3840, 3840]（均为384的倍数）
2025-09-20 17:32:47 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:32:47 - misc:368 - INFO -    Offset：[0, 3840, 7680]
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] h112_labeled.csv | 点数3626→3840（384的倍数）
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu111_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas3/gh1 (104)_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3804，校正前pad范围: [0, 3803]，校正后范围: [0, 3803]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3804
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3804
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3804]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3804, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3804，校正前pad范围: [0, 3803]，校正后范围: [0, 3803]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3804
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3804
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3804]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3804, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] uu111_labeled.csv | 点数2355→2688（384的倍数）
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1509，校正前pad范围: [0, 1508]，校正后范围: [0, 1508]
2025-09-20 17:32:47 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:47 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:32:47 - misc:366 - INFO -    各样本点数：[3840, 2688]（均为384的倍数）
2025-09-20 17:32:47 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:32:47 - misc:368 - INFO -    Offset：[0, 3840, 6528]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1509]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1509, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1509，校正前pad范围: [0, 1508]，校正后范围: [0, 1508]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1509]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1509, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1509，校正前pad范围: [0, 1508]，校正后范围: [0, 1508]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1509]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1509, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1509，校正前pad范围: [0, 1508]，校正后范围: [0, 1508]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1509]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1509, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1509，校正前pad范围: [0, 1508]，校正后范围: [0, 1508]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1509]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1509, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1509，校正前pad范围: [0, 1508]，校正后范围: [0, 1508]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1509]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1509, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 576], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=454，校正前pad范围: [0, 453]，校正后范围: [0, 453]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 454
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 454
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([454]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([454, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 576], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=454，校正前pad范围: [0, 453]，校正后范围: [0, 453]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1104], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 454
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 454
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([454]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([454, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1509，校正前pad范围: [0, 1508]，校正后范围: [0, 1508]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1509]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1509, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1152], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1509，校正前pad范围: [0, 1508]，校正后范围: [0, 1508]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2208], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1509
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1509]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1509, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3804，校正前pad范围: [0, 3803]，校正后范围: [0, 3803]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3804
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3804
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3804]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3804, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2304], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3804，校正前pad范围: [0, 3803]，校正后范围: [0, 3803]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4416], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3804
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3804
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3804]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3804, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4608], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8832], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] gh1 (104)_labeled.csv | 点数4313→4608（384的倍数）
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 5376], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 5376], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g181_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas3/gh1 (155)_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2688], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5210
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5210
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5210]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5210, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2688], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5210
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5210
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5210]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5210, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2080]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2080, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2080]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2080, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2080]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2080, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2080]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2080, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2080]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2080, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2080]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2080, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 912], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=624，校正前pad范围: [0, 623]，校正后范围: [0, 623]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 912], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 624
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 624
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([624]), 最大索引: 240, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([624, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 912], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=624，校正前pad范围: [0, 623]，校正后范围: [0, 623]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 912], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 624
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 624
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([624]), 最大索引: 240, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([624, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2080]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2080, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 480, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2080
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2080]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2080, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2688], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5210
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5210
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5210]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5210, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 2688], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:47 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5210
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5210
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5210]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5210, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 5376], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 5376], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] gh1 (155)_labeled.csv | 点数4403→4608（384的倍数）
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4992], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=10368, unpad长度将设为=10368
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn8_labeled.csv
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] g181_labeled.csv | 点数4060→4224（384的倍数）
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:32:47 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:47 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:32:47 - misc:366 - INFO -    各样本点数：[4608, 4224]（均为384的倍数）
2025-09-20 17:32:47 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:32:47 - misc:368 - INFO -    Offset：[0, 4608, 8832]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (81)_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4992], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 32])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2496], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5184, unpad长度将设为=5184
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4635，校正前pad范围: [0, 4634]，校正后范围: [0, 4634]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4635
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4635
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4635]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4635, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2496], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4635，校正前pad范围: [0, 4634]，校正后范围: [0, 4634]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4635
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4635
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4635]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4635, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2592, unpad长度将设为=2592
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2004，校正前pad范围: [0, 2003]，校正后范围: [0, 2003]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2004]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2004, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2004，校正前pad范围: [0, 2003]，校正后范围: [0, 2003]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2004]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2004, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2004，校正前pad范围: [0, 2003]，校正后范围: [0, 2003]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2004]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2004, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2004，校正前pad范围: [0, 2003]，校正后范围: [0, 2003]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2004]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2004, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2004，校正前pad范围: [0, 2003]，校正后范围: [0, 2003]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2004]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2004, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2004，校正前pad范围: [0, 2003]，校正后范围: [0, 2003]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2004]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2004, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 624], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1296, unpad长度将设为=1296
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=622，校正前pad范围: [0, 621]，校正后范围: [0, 621]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 622
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 622
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([622]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([622, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 624], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=622，校正前pad范围: [0, 621]，校正后范围: [0, 621]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 622
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 622
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([622]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([622, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2004，校正前pad范围: [0, 2003]，校正后范围: [0, 2003]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2004]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2004, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2004，校正前pad范围: [0, 2003]，校正后范围: [0, 2003]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2592], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2004
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2004]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2004, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2496], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4635，校正前pad范围: [0, 4634]，校正后范围: [0, 4634]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4635
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4635
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4635]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4635, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2496], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4635，校正前pad范围: [0, 4634]，校正后范围: [0, 4634]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5184], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4635
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4635
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4635]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4635, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4992], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4992], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 10368], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 10368
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([10368]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([10368, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 2688], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] eeee (81)_labeled.csv | 点数4724→4992（384的倍数）
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 2688], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] nn8_labeled.csv | 点数5345→5376（384的倍数）
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:47 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:32:47 - misc:366 - INFO -    各样本点数：[4608, 5376]（均为384的倍数）
2025-09-20 17:32:47 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:32:47 - misc:368 - INFO -    Offset：[0, 4608, 9984]
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3570，校正前pad范围: [0, 3569]，校正后范围: [0, 3569]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3570
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3570
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3570]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3570, 64])
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas1/kk41_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3570，校正前pad范围: [0, 3569]，校正后范围: [0, 3569]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3570
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3570
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3570]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3570, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1428，校正前pad范围: [0, 1427]，校正后范围: [0, 1427]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1428]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1428, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (47)_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1428，校正前pad范围: [0, 1427]，校正后范围: [0, 1427]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1428]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1428, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1428，校正前pad范围: [0, 1427]，校正后范围: [0, 1427]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1428]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1428, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1428，校正前pad范围: [0, 1427]，校正后范围: [0, 1427]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1428]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1428, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1428，校正前pad范围: [0, 1427]，校正后范围: [0, 1427]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1428]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1428, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1428，校正前pad范围: [0, 1427]，校正后范围: [0, 1427]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1428]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1428, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 576, 912], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 336], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=449，校正前pad范围: [0, 448]，校正后范围: [0, 448]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 576, 912], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 449
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 449
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([449]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([449, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 576, 912], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 336], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=449，校正前pad范围: [0, 448]，校正后范围: [0, 448]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 576, 912], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 449
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 449
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([449]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([449, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1428，校正前pad范围: [0, 1427]，校正后范围: [0, 1427]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1428]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1428, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1428，校正前pad范围: [0, 1427]，校正后范围: [0, 1427]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1428
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1428]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1428, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3570，校正前pad范围: [0, 3569]，校正后范围: [0, 3569]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3570
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3570
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3570]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3570, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1344], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3570，校正前pad范围: [0, 3569]，校正后范围: [0, 3569]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3570
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3570
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3570]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3570, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 2688], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 2688], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] kk41_labeled.csv | 点数4707→4992（384的倍数）
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas2/iiii (159)_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3505，校正前pad范围: [0, 3504]，校正后范围: [0, 3504]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3505
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3505
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3505]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3505, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:47 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g206_labeled.csv
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3505，校正前pad范围: [0, 3504]，校正后范围: [0, 3504]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3505
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3505
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3505]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3505, 64])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1503，校正前pad范围: [0, 1502]，校正后范围: [0, 1502]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1503]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1503, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1503，校正前pad范围: [0, 1502]，校正后范围: [0, 1502]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1503]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1503, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1503，校正前pad范围: [0, 1502]，校正后范围: [0, 1502]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1503]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1503, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:47 - wind_shear:161 - DEBUG - [补点] gggg (47)_labeled.csv | 点数4885→4992（384的倍数）
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1503，校正前pad范围: [0, 1502]，校正后范围: [0, 1502]
2025-09-20 17:32:47 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:47 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:32:47 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 17:32:47 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:32:47 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1503]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1503, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1503，校正前pad范围: [0, 1502]，校正后范围: [0, 1502]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1503]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1503, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1503，校正前pad范围: [0, 1502]，校正后范围: [0, 1502]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1503
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1503]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1503, 128])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:47 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=475，校正前pad范围: [0, 474]，校正后范围: [0, 474]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 475
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 475
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([475]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([475, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:47 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:47 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:47 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=475，校正前pad范围: [0, 474]，校正后范围: [0, 474]
2025-09-20 17:32:47 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:47 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:47 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:47 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:47 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 475
2025-09-20 17:32:47 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 475
2025-09-20 17:32:47 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:47 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:47 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([475]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:47 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:47 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([475, 256])
2025-09-20 17:32:47 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1503，校正前pad范围: [0, 1502]，校正后范围: [0, 1502]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1503
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1503
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1503]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1503, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1503，校正前pad范围: [0, 1502]，校正后范围: [0, 1502]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1503
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1503
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1503]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1503, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3505，校正前pad范围: [0, 3504]，校正后范围: [0, 3504]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3505
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3505
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3505]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3505, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3505，校正前pad范围: [0, 3504]，校正后范围: [0, 3504]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3505
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3505
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3505]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3505, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] g206_labeled.csv | 点数4247→4608（384的倍数）
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas4/jj61_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] iiii (159)_labeled.csv | 点数4899→4992（384的倍数）
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:48 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:48 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:32:48 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 17:32:48 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:32:48 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o136_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6284
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6284
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6284]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6284, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6284
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6284
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6284]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6284, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2476]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2476, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2476]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2476, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2476]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2476, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2476]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2476, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2476]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2476, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2476]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2476, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=747，校正前pad范围: [0, 746]，校正后范围: [0, 746]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 747
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 747
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([747]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([747, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=747，校正前pad范围: [0, 746]，校正后范围: [0, 746]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 747
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 747
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([747]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([747, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2476]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2476, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2476
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2476]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2476, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6284
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6284
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6284]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6284, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6284
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6284
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6284]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6284, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] jj61_labeled.csv | 点数4680→4992（384的倍数）
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] o136_labeled.csv | 点数4597→4608（384的倍数）
2025-09-20 17:32:48 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:48 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:32:48 - misc:366 - INFO -    各样本点数：[4608, 4608]（均为384的倍数）
2025-09-20 17:32:48 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:32:48 - misc:368 - INFO -    Offset：[0, 4608, 9216]
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m133_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh36_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2533，校正前pad范围: [0, 2532]，校正后范围: [0, 2532]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2533
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2533
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2533]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2533, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2533，校正前pad范围: [0, 2532]，校正后范围: [0, 2532]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2533
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2533
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2533]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2533, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=979，校正前pad范围: [0, 978]，校正后范围: [0, 978]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([979]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([979, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=979，校正前pad范围: [0, 978]，校正后范围: [0, 978]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([979]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([979, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=979，校正前pad范围: [0, 978]，校正后范围: [0, 978]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([979]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([979, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=979，校正前pad范围: [0, 978]，校正后范围: [0, 978]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([979]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([979, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=979，校正前pad范围: [0, 978]，校正后范围: [0, 978]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([979]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([979, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=979，校正前pad范围: [0, 978]，校正后范围: [0, 978]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([979]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([979, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=304，校正前pad范围: [0, 303]，校正后范围: [0, 303]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 304
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 304
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([304]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([304, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 480], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=304，校正前pad范围: [0, 303]，校正后范围: [0, 303]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 304
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 304
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([304]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([304, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=979，校正前pad范围: [0, 978]，校正后范围: [0, 978]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([979]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([979, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 960], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=979，校正前pad范围: [0, 978]，校正后范围: [0, 978]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 979
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([979]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([979, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2533，校正前pad范围: [0, 2532]，校正后范围: [0, 2532]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2533
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2533
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2533]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2533, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1920], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2533，校正前pad范围: [0, 2532]，校正后范围: [0, 2532]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2533
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2533
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2533]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2533, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 3840], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 7680], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] m133_labeled.csv | 点数3933→4224（384的倍数）
2025-09-20 17:32:48 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:48 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:32:48 - misc:366 - INFO -    各样本点数：[4992, 4224]（均为384的倍数）
2025-09-20 17:32:48 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:32:48 - misc:368 - INFO -    Offset：[0, 4992, 9216]
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] hh36_labeled.csv | 点数4232→4608（384的倍数）
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2688], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas2/pp74_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2688], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2401，校正前pad范围: [0, 2400]，校正后范围: [0, 2400]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2401
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2401
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2401]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2401, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2401，校正前pad范围: [0, 2400]，校正后范围: [0, 2400]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2401
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2401
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2401]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2401, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y172_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=931，校正前pad范围: [0, 930]，校正后范围: [0, 930]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([931]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([931, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=931，校正前pad范围: [0, 930]，校正后范围: [0, 930]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([931]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([931, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=931，校正前pad范围: [0, 930]，校正后范围: [0, 930]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([931]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([931, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=931，校正前pad范围: [0, 930]，校正后范围: [0, 930]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([931]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([931, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=931，校正前pad范围: [0, 930]，校正后范围: [0, 930]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([931]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([931, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=931，校正前pad范围: [0, 930]，校正后范围: [0, 930]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([931]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([931, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 816], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 336], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=295，校正前pad范围: [0, 294]，校正后范围: [0, 294]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 816], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 295
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 295
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([295]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([295, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 480, 816], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 336], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=295，校正前pad范围: [0, 294]，校正后范围: [0, 294]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 480, 816], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 295
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 295
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([295]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([295, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=931，校正前pad范围: [0, 930]，校正后范围: [0, 930]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([931]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([931, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([960, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=931，校正前pad范围: [0, 930]，校正后范围: [0, 930]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 1632], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 931
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([931]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([931, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2401，校正前pad范围: [0, 2400]，校正后范围: [0, 2400]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2401
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2401
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2401]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2401, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2401，校正前pad范围: [0, 2400]，校正后范围: [0, 2400]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 3264], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2401
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2401
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2401]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2401, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2688], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 2688], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 6528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] y172_labeled.csv | 点数3297→3456（384的倍数）
2025-09-20 17:32:48 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:48 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:32:48 - misc:366 - INFO -    各样本点数：[4608, 3456]（均为384的倍数）
2025-09-20 17:32:48 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:32:48 - misc:368 - INFO -    Offset：[0, 4608, 8064]
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230303/datas1/hhhh (65)_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3877，校正前pad范围: [0, 3876]，校正后范围: [0, 3876]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3877
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3877
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3877]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3877, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3877，校正前pad范围: [0, 3876]，校正后范围: [0, 3876]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3877
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3877
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3877]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3877, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1561，校正前pad范围: [0, 1560]，校正后范围: [0, 1560]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1561]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1561, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1561，校正前pad范围: [0, 1560]，校正后范围: [0, 1560]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1561]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1561, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1561，校正前pad范围: [0, 1560]，校正后范围: [0, 1560]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1561]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1561, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1561，校正前pad范围: [0, 1560]，校正后范围: [0, 1560]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1561]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1561, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1561，校正前pad范围: [0, 1560]，校正后范围: [0, 1560]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1561]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1561, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1561，校正前pad范围: [0, 1560]，校正后范围: [0, 1560]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1561]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1561, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=480，校正前pad范围: [0, 479]，校正后范围: [0, 479]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 480
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 480
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([480]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([480, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 528], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=480，校正前pad范围: [0, 479]，校正后范围: [0, 479]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1104], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 480
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 480
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([480]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([480, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] pp74_labeled.csv | 点数6113→6144（384的倍数）
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1561，校正前pad范围: [0, 1560]，校正后范围: [0, 1560]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1561]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1561, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1056], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1561，校正前pad范围: [0, 1560]，校正后范围: [0, 1560]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2208], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1561
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1561]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1561, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3877，校正前pad范围: [0, 3876]，校正后范围: [0, 3876]
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas1/c99_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3877
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3877
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3877]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3877, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2112], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3877，校正前pad范围: [0, 3876]，校正后范围: [0, 3876]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4416], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3877
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3877
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3877]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3877, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4224], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8832], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] hhhh (65)_labeled.csv | 点数3806→3840（384的倍数）
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m48_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=2688
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss44_labeled.csv
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4656，校正前pad范围: [0, 4655]，校正后范围: [0, 4655]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4656
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4656
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4656]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4656, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] c99_labeled.csv | 点数3337→3456（384的倍数）
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:48 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:48 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:48 - misc:366 - INFO -    各样本点数：[6144, 3456]（均为384的倍数）
2025-09-20 17:32:48 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:48 - misc:368 - INFO -    Offset：[0, 6144, 9600]
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4656，校正前pad范围: [0, 4655]，校正后范围: [0, 4655]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4656
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4656
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4656]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4656, 64])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2024，校正前pad范围: [0, 2023]，校正后范围: [0, 2023]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2024]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2024, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2024，校正前pad范围: [0, 2023]，校正后范围: [0, 2023]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2024]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2024, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2024，校正前pad范围: [0, 2023]，校正后范围: [0, 2023]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2024]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2024, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2024，校正前pad范围: [0, 2023]，校正后范围: [0, 2023]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2024]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2024, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2024，校正前pad范围: [0, 2023]，校正后范围: [0, 2023]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2024]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2024, 128])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2024，校正前pad范围: [0, 2023]，校正后范围: [0, 2023]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2024
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2024]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2024, 128])
2025-09-20 17:32:48 - wind_shear:161 - DEBUG - [补点] ss44_labeled.csv | 点数1855→1920（384的倍数）
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:48 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=633，校正前pad范围: [0, 632]，校正后范围: [0, 632]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 633
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 633
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([633]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:48 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([633, 256])
2025-09-20 17:32:48 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:48 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:48 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 672], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:48 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=633，校正前pad范围: [0, 632]，校正后范围: [0, 632]
2025-09-20 17:32:48 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:48 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:48 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1248], device='cuda:0')
2025-09-20 17:32:48 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:48 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=42
2025-09-20 17:32:48 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 633
2025-09-20 17:32:48 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 633
2025-09-20 17:32:48 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:48 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:48 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([633]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([633, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2024，校正前pad范围: [0, 2023]，校正后范围: [0, 2023]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2024
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2024
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2024]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2024, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1344], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2024，校正前pad范围: [0, 2023]，校正后范围: [0, 2023]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=168
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2024
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2024
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas4/r37_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2024]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2024, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4656，校正前pad范围: [0, 4655]，校正后范围: [0, 4655]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4656
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4656
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4656]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4656, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2688], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4656，校正前pad范围: [0, 4655]，校正后范围: [0, 4655]
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] m48_labeled.csv | 点数4225→4608（384的倍数）
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:49 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:32:49 - misc:366 - INFO -    各样本点数：[3840, 4608]（均为384的倍数）
2025-09-20 17:32:49 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:32:49 - misc:368 - INFO -    Offset：[0, 3840, 8448]
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4656
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4656
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4656]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4656, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 5376], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(5376, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5376，K=1344
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] r37_labeled.csv | 点数3281→3456（384的倍数）
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:49 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=5376
2025-09-20 17:32:49 - misc:366 - INFO -    各样本点数：[1920, 3456]（均为384的倍数）
2025-09-20 17:32:49 - misc:367 - INFO -    拼接后维度：coord=torch.Size([5376, 3])，feat=torch.Size([5376, 9])，label=torch.Size([5376])
2025-09-20 17:32:49 - misc:368 - INFO -    Offset：[0, 1920, 5376]
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (41)_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7389
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7389
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7389]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7389, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7389
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7389
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7389]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7389, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3072]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3072, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3072]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3072, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3072]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3072, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3072]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3072, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3072]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3072, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3072]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3072, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=935，校正前pad范围: [0, 934]，校正后范围: [0, 934]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 935
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 935
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([935]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([935, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=935，校正前pad范围: [0, 934]，校正后范围: [0, 934]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 935
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 935
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([935]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([935, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3072]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3072, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3072
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3072]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3072, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7389
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7389
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7389]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7389, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7389
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7389
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7389]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7389, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9984, unpad长度将设为=9984
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] gggg (41)_labeled.csv | 点数5216→5376（384的倍数）
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(112)_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 32])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4992, unpad长度将设为=4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7435
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7435
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7435]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7435, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn76_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7435
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7435
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7435]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7435, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2496, unpad长度将设为=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3138]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3138, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3138]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3138, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3138]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3138, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3138]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3138, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3138]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3138, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3138]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3138, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1248, unpad长度将设为=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=976，校正前pad范围: [0, 975]，校正后范围: [0, 975]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 976
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 976
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([976]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([976, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 624], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 624
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=976，校正前pad范围: [0, 975]，校正后范围: [0, 975]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 976
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 976
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([976]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([976, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3138]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3138, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1248], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2496，校正前最大索引=2495, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3138
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3138]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3138, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7435
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7435
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7435]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7435, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2496], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4992，校正前最大索引=4991, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7435
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7435
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7435]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7435, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4992], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4992
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9984], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9984
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9984]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9984, 64])
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] bbbbb(112)_labeled.csv | 点数2983→3072（384的倍数）
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x49_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i23_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4067，校正前pad范围: [0, 4066]，校正后范围: [0, 4066]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4067
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4067
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4067]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4067, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4067，校正前pad范围: [0, 4066]，校正后范围: [0, 4066]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4067
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4067
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4067]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4067, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1681，校正前pad范围: [0, 1680]，校正后范围: [0, 1680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1681]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1681, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] nn76_labeled.csv | 点数5958→6144（384的倍数）
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:49 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=11520
2025-09-20 17:32:49 - misc:366 - INFO -    各样本点数：[5376, 6144]（均为384的倍数）
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:32:49 - misc:367 - INFO -    拼接后维度：coord=torch.Size([11520, 3])，feat=torch.Size([11520, 9])，label=torch.Size([11520])
2025-09-20 17:32:49 - misc:368 - INFO -    Offset：[0, 5376, 11520]
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1681，校正前pad范围: [0, 1680]，校正后范围: [0, 1680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1681]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1681, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1681，校正前pad范围: [0, 1680]，校正后范围: [0, 1680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1681]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1681, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1681，校正前pad范围: [0, 1680]，校正后范围: [0, 1680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1681]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1681, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1681，校正前pad范围: [0, 1680]，校正后范围: [0, 1680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1681]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1681, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1681，校正前pad范围: [0, 1680]，校正后范围: [0, 1680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1681]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1681, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=522，校正前pad范围: [0, 521]，校正后范围: [0, 521]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 522
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 522
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([522]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([522, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 576], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=522，校正前pad范围: [0, 521]，校正后范围: [0, 521]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 522
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 522
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([522]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([522, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1681，校正前pad范围: [0, 1680]，校正后范围: [0, 1680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1681]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1681, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1681，校正前pad范围: [0, 1680]，校正后范围: [0, 1680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1681
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1681]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1681, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4067，校正前pad范围: [0, 4066]，校正后范围: [0, 4066]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4067
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4067
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4067]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4067, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4067，校正前pad范围: [0, 4066]，校正后范围: [0, 4066]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] x49_labeled.csv | 点数4568→4608（384的倍数）
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4067
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4067
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:49 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:32:49 - misc:366 - INFO -    各样本点数：[3072, 4608]（均为384的倍数）
2025-09-20 17:32:49 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4067]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:49 - misc:368 - INFO -    Offset：[0, 3072, 7680]
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4067, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] i23_labeled.csv | 点数4864→4992（384的倍数）
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9216, unpad长度将设为=9216
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230316/datas1/ee129_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 32])
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas1/eeee (162)_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4608, unpad长度将设为=4608
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6541
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6541
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6541]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6541, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6541
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6541
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6541]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6541, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2304, unpad长度将设为=2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1152, unpad长度将设为=1152
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=795，校正前pad范围: [0, 794]，校正后范围: [0, 794]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 795
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 795
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([795]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([795, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 528], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=795，校正前pad范围: [0, 794]，校正后范围: [0, 794]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1152], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 795
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 795
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([795]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([795, 256])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1056], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2304，校正前最大索引=2303, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2304], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2633
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2633]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2633, 128])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6541
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6541
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6541]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6541, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2112], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:49 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4608，校正前最大索引=4607, 最小索引=0
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4608], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6541
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6541
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6541]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6541, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4224], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9216], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9216
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9216]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9216, 64])
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] ee129_labeled.csv | 点数4384→4608（384的倍数）
2025-09-20 17:32:49 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:49 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:49 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:32:49 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:49 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - wind_shear:161 - DEBUG - [补点] eeee (162)_labeled.csv | 点数4105→4224（384的倍数）
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss122_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:49 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:49 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:49 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:32:49 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2872，校正前pad范围: [0, 2871]，校正后范围: [0, 2871]
2025-09-20 17:32:49 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:49 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas4/rr56_labeled.csv
2025-09-20 17:32:49 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:32:49 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:49 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:49 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2872
2025-09-20 17:32:49 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2872
2025-09-20 17:32:49 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:49 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:49 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2872]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:49 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:49 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2872, 64])
2025-09-20 17:32:49 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2872，校正前pad范围: [0, 2871]，校正后范围: [0, 2871]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2872
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2872
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2872]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2872, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1156，校正前pad范围: [0, 1155]，校正后范围: [0, 1155]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1156]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1156, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1156，校正前pad范围: [0, 1155]，校正后范围: [0, 1155]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1156]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1156, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1156，校正前pad范围: [0, 1155]，校正后范围: [0, 1155]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1156]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1156, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1156，校正前pad范围: [0, 1155]，校正后范围: [0, 1155]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1156]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1156, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1156，校正前pad范围: [0, 1155]，校正后范围: [0, 1155]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1156]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1156, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1156，校正前pad范围: [0, 1155]，校正后范围: [0, 1155]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1156]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1156, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=367，校正前pad范围: [0, 366]，校正后范围: [0, 366]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 367
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 367
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([367]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([367, 256])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 432], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=367，校正前pad范围: [0, 366]，校正后范围: [0, 366]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1008], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 367
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 367
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([367]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([367, 256])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - wind_shear:161 - DEBUG - [补点] ss122_labeled.csv | 点数1946→2304（384的倍数）
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:50 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:32:50 - misc:366 - INFO -    各样本点数：[4224, 2304]（均为384的倍数）
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:32:50 - misc:368 - INFO -    Offset：[0, 4224, 6528]
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1156，校正前pad范围: [0, 1155]，校正后范围: [0, 1155]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1156]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1156, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1156，校正前pad范围: [0, 1155]，校正后范围: [0, 1155]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2016], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1156
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1156]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1156, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2872，校正前pad范围: [0, 2871]，校正后范围: [0, 2871]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2872
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2872
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2872]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2872, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2872，校正前pad范围: [0, 2871]，校正后范围: [0, 2871]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4032], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2872
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2872
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2872]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2872, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8064], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - wind_shear:161 - DEBUG - [补点] rr56_labeled.csv | 点数4791→4992（384的倍数）
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=3072
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230304/datas2/a90_labeled.csv
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7503
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7503
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7503]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7503, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:50 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh53_labeled.csv
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7503
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7503
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7503]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7503, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3265]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3265, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3265]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3265, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3265]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3265, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3265]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3265, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3265]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3265, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3265]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3265, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 432], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=982，校正前pad范围: [0, 981]，校正后范围: [0, 981]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 982
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 982
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([982]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([982, 256])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 432], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=982，校正前pad范围: [0, 981]，校正后范围: [0, 981]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1200], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=48
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 982
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 982
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([982]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([982, 256])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3265]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3265, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536,  864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 2400], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3265
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3265]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3265, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7503
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7503
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7503]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7503, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 4800], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7503
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7503
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7503]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7503, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([6144, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 6144, 9600], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(6144, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数6144，K=1536
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 6144, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:50 - wind_shear:161 - DEBUG - [补点] hh53_labeled.csv | 点数3531→3840（384的倍数）
2025-09-20 17:32:50 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:50 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:32:50 - misc:366 - INFO -    各样本点数：[4992, 3840]（均为384的倍数）
2025-09-20 17:32:50 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:32:50 - misc:368 - INFO -    Offset：[0, 4992, 8832]
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:32:50 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas1/e139_labeled.csv
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2931，校正前pad范围: [0, 2930]，校正后范围: [0, 2930]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2931
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2931
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2931]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2931, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2931，校正前pad范围: [0, 2930]，校正后范围: [0, 2930]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2931
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2931
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2931]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2931, 64])
2025-09-20 17:32:50 - wind_shear:161 - DEBUG - [补点] a90_labeled.csv | 点数4071→4224（384的倍数）
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1195，校正前pad范围: [0, 1194]，校正后范围: [0, 1194]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1195]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1195, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1195，校正前pad范围: [0, 1194]，校正后范围: [0, 1194]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1195]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1195, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1195，校正前pad范围: [0, 1194]，校正后范围: [0, 1194]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas2/h186_labeled.csv
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1195]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1195, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1195，校正前pad范围: [0, 1194]，校正后范围: [0, 1194]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1195]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1195, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1195，校正前pad范围: [0, 1194]，校正后范围: [0, 1194]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1195]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1195, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1195，校正前pad范围: [0, 1194]，校正后范围: [0, 1194]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1195]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1195, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=374，校正前pad范围: [0, 373]，校正后范围: [0, 373]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 374
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 374
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([374]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([374, 256])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 576], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=374，校正前pad范围: [0, 373]，校正后范围: [0, 373]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1056], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 374
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 374
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([374]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([374, 256])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1195，校正前pad范围: [0, 1194]，校正后范围: [0, 1194]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1195]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1195, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1152], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1195，校正前pad范围: [0, 1194]，校正后范围: [0, 1194]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2112], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1195
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1195]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1195, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2931，校正前pad范围: [0, 2930]，校正后范围: [0, 2930]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2931
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2931
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2931]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2931, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2304], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2931，校正前pad范围: [0, 2930]，校正后范围: [0, 2930]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4224], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2931
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2931
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2931]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2931, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 4608], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 8448], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:50 - wind_shear:161 - DEBUG - [补点] h186_labeled.csv | 点数3381→3456（384的倍数）
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:50 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:32:50 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 17:32:50 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:32:50 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5376, unpad长度将设为=5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 32])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=960
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 32])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2688, unpad长度将设为=2688
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3557
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3557
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3557, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3557
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3557
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3557, 64])
2025-09-20 17:32:50 - wind_shear:161 - DEBUG - [补点] e139_labeled.csv | 点数4254→4608（384的倍数）
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1344, unpad长度将设为=1344
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1258，校正前pad范围: [0, 1257]，校正后范围: [0, 1257]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1258]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1258, 128])
2025-09-20 17:32:50 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z89_labeled.csv
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1258，校正前pad范围: [0, 1257]，校正后范围: [0, 1257]
2025-09-20 17:32:50 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas2/o98_labeled.csv
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1258]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1258, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1258，校正前pad范围: [0, 1257]，校正后范围: [0, 1257]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1258]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1258, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1258，校正前pad范围: [0, 1257]，校正后范围: [0, 1257]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1258]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1258, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1258，校正前pad范围: [0, 1257]，校正后范围: [0, 1257]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1258]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1258, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1258，校正前pad范围: [0, 1257]，校正后范围: [0, 1257]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1258]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1258, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 432], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=672, unpad长度将设为=672
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=358，校正前pad范围: [0, 357]，校正后范围: [0, 357]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 358
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 358
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([358]), 最大索引: 240, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([358, 256])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([240, 432], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=358，校正前pad范围: [0, 357]，校正后范围: [0, 357]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 240, 672], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(240, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数240，K=15
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 358
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 358
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([358]), 最大索引: 240, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([358, 256])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1258，校正前pad范围: [0, 1257]，校正后范围: [0, 1257]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1258]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1258, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 864], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1258，校正前pad范围: [0, 1257]，校正后范围: [0, 1257]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1344], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=60
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1258
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1258]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1258, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3557
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3557
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3557, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1728], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:50 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2688，校正前最大索引=2687, 最小索引=0
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2688], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=240
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3557
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3557
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3557]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3557, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 3456], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 5376], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5376]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5376, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 11520], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 6144], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=11520, unpad长度将设为=11520
2025-09-20 17:32:50 - wind_shear:161 - DEBUG - [补点] z89_labeled.csv | 点数3812→3840（384的倍数）
2025-09-20 17:32:50 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:50 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:32:50 - misc:366 - INFO -    各样本点数：[4608, 3840]（均为384的倍数）
2025-09-20 17:32:50 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:32:50 - misc:368 - INFO -    Offset：[0, 4608, 8448]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 11520], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 32])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas2/vv125_labeled.csv
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 11520], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 6144], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 11520], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=3072
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 32])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5760], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3072], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=5760, unpad长度将设为=5760
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5268，校正前pad范围: [0, 5267]，校正后范围: [0, 5267]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5760], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5268
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5268
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5268]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5268, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5760], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3072], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5268，校正前pad范围: [0, 5267]，校正后范围: [0, 5267]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5760], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5268
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5268
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5268]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5268, 64])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1536], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:50 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2880, unpad长度将设为=2880
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2396，校正前pad范围: [0, 2395]，校正后范围: [0, 2395]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2396]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2396, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1536], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2396，校正前pad范围: [0, 2395]，校正后范围: [0, 2395]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2396]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2396, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - wind_shear:161 - DEBUG - [补点] o98_labeled.csv | 点数5094→5376（384的倍数）
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1536], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2396，校正前pad范围: [0, 2395]，校正后范围: [0, 2395]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2396]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2396, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1536], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2396，校正前pad范围: [0, 2395]，校正后范围: [0, 2395]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2396]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2396, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:50 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:50 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1536], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:50 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2396，校正前pad范围: [0, 2395]，校正后范围: [0, 2395]
2025-09-20 17:32:50 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:50 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:50 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:50 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:32:50 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2396
2025-09-20 17:32:50 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:50 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:50 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2396]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:50 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:50 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2396, 128])
2025-09-20 17:32:50 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1536], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2396，校正前pad范围: [0, 2395]，校正后范围: [0, 2395]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2396
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2396
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2396]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2396, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1440], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 768], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1440, unpad长度将设为=1440
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=745，校正前pad范围: [0, 744]，校正后范围: [0, 744]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1440], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 745
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 745
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([745]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([745, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1440], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 768], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=745，校正前pad范围: [0, 744]，校正后范围: [0, 744]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1440], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=48
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 745
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 745
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([745]), 最大索引: 672, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([745, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1536], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2396，校正前pad范围: [0, 2395]，校正后范围: [0, 2395]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2396
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2396
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2396]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2396, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1536], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2396，校正前pad范围: [0, 2395]，校正后范围: [0, 2395]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2880], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=192
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2396
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2396
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2396]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2396, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5760], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3072], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5268，校正前pad范围: [0, 5267]，校正后范围: [0, 5267]
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230307/datas1/g87_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5760], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5268
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5268
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5268]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5268, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 5760], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 3072], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=5268，校正前pad范围: [0, 5267]，校正后范围: [0, 5267]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 5760], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5268
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5268
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5268]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5268, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 11520], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 6144], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 11520], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] vv125_labeled.csv | 点数3171→3456（384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([    0,  5376, 11520], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 6144], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 5376
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([    0,  5376, 11520], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(6144, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数6144，K=1536
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 11520
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 11520
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 11520
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 11520
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([11520]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([11520, 64])
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas2/j10_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas2/tt98_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5739
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5739
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5739]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5739, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5739
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5739
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5739]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5739, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2247]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2247, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2247]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2247, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2247]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2247, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2247]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] g87_labeled.csv | 点数4056→4224（384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2247, 128])
2025-09-20 17:32:51 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:51 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:51 - misc:366 - INFO -    各样本点数：[5376, 4224]（均为384的倍数）
2025-09-20 17:32:51 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:51 - misc:368 - INFO -    Offset：[0, 5376, 9600]
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2247]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2247, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2247]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2247, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=657，校正前pad范围: [0, 656]，校正后范围: [0, 656]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 657
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 657
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([657]), 最大索引: 384, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([657, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=657，校正前pad范围: [0, 656]，校正后范围: [0, 656]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 657
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 657
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([657]), 最大索引: 384, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([657, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2247]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] j10_labeled.csv | 点数3795→3840（384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2247, 128])
2025-09-20 17:32:51 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:51 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:32:51 - misc:366 - INFO -    各样本点数：[3456, 3840]（均为384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:32:51 - misc:368 - INFO -    Offset：[0, 3456, 7296]
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2247
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2247]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2247, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5739
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5739
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5739]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5739, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] tt98_labeled.csv | 点数2795→3072（384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5739
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5739
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5739]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5739, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4608], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m134_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (104)_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4269，校正前pad范围: [0, 4268]，校正后范围: [0, 4268]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4269
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4269
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4269]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4269, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4269，校正前pad范围: [0, 4268]，校正后范围: [0, 4268]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4269
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4269
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4269]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4269, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1775，校正前pad范围: [0, 1774]，校正后范围: [0, 1774]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1775]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1775, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1775，校正前pad范围: [0, 1774]，校正后范围: [0, 1774]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1775]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1775, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1775，校正前pad范围: [0, 1774]，校正后范围: [0, 1774]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1775]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1775, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1775，校正前pad范围: [0, 1774]，校正后范围: [0, 1774]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1775]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1775, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1775，校正前pad范围: [0, 1774]，校正后范围: [0, 1774]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1775]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1775, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1775，校正前pad范围: [0, 1774]，校正后范围: [0, 1774]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1775]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1775, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=542，校正前pad范围: [0, 541]，校正后范围: [0, 541]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 542
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 542
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([542]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([542, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=542，校正前pad范围: [0, 541]，校正后范围: [0, 541]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1200], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=36
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 542
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 542
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([542]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([542, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1775，校正前pad范围: [0, 1774]，校正后范围: [0, 1774]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1775]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1775, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1775，校正前pad范围: [0, 1774]，校正后范围: [0, 1774]
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] m134_labeled.csv | 点数3905→4224（384的倍数）
2025-09-20 17:32:51 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:51 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:32:51 - misc:366 - INFO -    各样本点数：[3072, 4224]（均为384的倍数）
2025-09-20 17:32:51 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:32:51 - misc:368 - INFO -    Offset：[0, 3072, 7296]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2400], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=144
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1775
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1775]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1775, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4269，校正前pad范围: [0, 4268]，校正后范围: [0, 4268]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4269
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4269
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4269]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4269, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4269，校正前pad范围: [0, 4268]，校正后范围: [0, 4268]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4800], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4269
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4269
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4269]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4269, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 4608], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 9600], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(4608, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4608，K=1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] gggg (104)_labeled.csv | 点数4758→4992（384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh52_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2774，校正前pad范围: [0, 2773]，校正后范围: [0, 2773]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2774
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2774
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2774]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas4/l17_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2774, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2774，校正前pad范围: [0, 2773]，校正后范围: [0, 2773]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2774
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2774
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2774]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2774, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1093，校正前pad范围: [0, 1092]，校正后范围: [0, 1092]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1093]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1093, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1093，校正前pad范围: [0, 1092]，校正后范围: [0, 1092]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1093]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1093, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1093，校正前pad范围: [0, 1092]，校正后范围: [0, 1092]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1093]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1093, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1093，校正前pad范围: [0, 1092]，校正后范围: [0, 1092]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1093]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1093, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1093，校正前pad范围: [0, 1092]，校正后范围: [0, 1092]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1093]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1093, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1093，校正前pad范围: [0, 1092]，校正后范围: [0, 1092]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1093]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1093, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 816], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 288], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=344，校正前pad范围: [0, 343]，校正后范围: [0, 343]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 816], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 344
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 344
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([344]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([344, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 816], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 288], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=344，校正前pad范围: [0, 343]，校正后范围: [0, 343]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 816], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(288, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数288，K=18
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 344
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 344
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([344]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([344, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1093，校正前pad范围: [0, 1092]，校正后范围: [0, 1092]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1093]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1093, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  576], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1093，校正前pad范围: [0, 1092]，校正后范围: [0, 1092]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1632], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(576, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数576，K=72
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1093
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1093]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1093, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2774，校正前pad范围: [0, 2773]，校正后范围: [0, 2773]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2774
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2774
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2774]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2774, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1152], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2774，校正前pad范围: [0, 2773]，校正后范围: [0, 2773]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3264], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1152, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1152，K=288
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2774
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2774
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2774]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2774, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2304], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6528], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2304, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2304，K=576
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] hh52_labeled.csv | 点数3359→3456（384的倍数）
2025-09-20 17:32:51 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:51 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:32:51 - misc:366 - INFO -    各样本点数：[4992, 3456]（均为384的倍数）
2025-09-20 17:32:51 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:32:51 - misc:368 - INFO -    Offset：[0, 4992, 8448]
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] l17_labeled.csv | 点数4456→4608（384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i72_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu5_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6345
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6345
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6345]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6345, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6345
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6345
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6345]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6345, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2571]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2571, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2571]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2571, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2571]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2571, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2571]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2571, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2571]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2571, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2571]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2571, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=757，校正前pad范围: [0, 756]，校正后范围: [0, 756]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 757
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 757
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([757]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([757, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=757，校正前pad范围: [0, 756]，校正后范围: [0, 756]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 757
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 757
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([757]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([757, 256])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2571]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2571, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2571
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2571]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2571, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6345
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6345
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6345]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6345, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:51 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6345
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6345
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6345]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6345, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] uu5_labeled.csv | 点数2536→2688（384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:32:51 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:51 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:32:51 - misc:366 - INFO -    各样本点数：[4608, 2688]（均为384的倍数）
2025-09-20 17:32:51 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:32:51 - misc:368 - INFO -    Offset：[0, 4608, 7296]
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:51 - wind_shear:161 - DEBUG - [补点] i72_labeled.csv | 点数4538→4608（384的倍数）
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d66_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas2/x35_labeled.csv
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2800，校正前pad范围: [0, 2799]，校正后范围: [0, 2799]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2800
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2800
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2800]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2800, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2800，校正前pad范围: [0, 2799]，校正后范围: [0, 2799]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2800
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2800
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2800]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2800, 64])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:51 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1120，校正前pad范围: [0, 1119]，校正后范围: [0, 1119]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1120
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1120
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1120]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1120, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1120，校正前pad范围: [0, 1119]，校正后范围: [0, 1119]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1120
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1120
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1120]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1120, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1120，校正前pad范围: [0, 1119]，校正后范围: [0, 1119]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:51 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1120
2025-09-20 17:32:51 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1120
2025-09-20 17:32:51 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:51 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:51 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1120]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:51 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1120, 128])
2025-09-20 17:32:51 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:51 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:51 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:51 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1120，校正前pad范围: [0, 1119]，校正后范围: [0, 1119]
2025-09-20 17:32:51 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:51 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:51 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:51 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:51 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1120]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1120, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1120，校正前pad范围: [0, 1119]，校正后范围: [0, 1119]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1120]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1120, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1120，校正前pad范围: [0, 1119]，校正后范围: [0, 1119]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1120]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1120, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=358，校正前pad范围: [0, 357]，校正后范围: [0, 357]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 358
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 358
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([358]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([358, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=358，校正前pad范围: [0, 357]，校正后范围: [0, 357]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 358
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 358
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([358]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([358, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1120，校正前pad范围: [0, 1119]，校正后范围: [0, 1119]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1120]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1120, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1120，校正前pad范围: [0, 1119]，校正后范围: [0, 1119]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1120
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1120]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1120, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2800，校正前pad范围: [0, 2799]，校正后范围: [0, 2799]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2800
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2800
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2800]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2800, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2800，校正前pad范围: [0, 2799]，校正后范围: [0, 2799]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2800
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2800
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2800]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2800, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] d66_labeled.csv | 点数3459→3840（384的倍数）
2025-09-20 17:32:52 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:32:52 - misc:366 - INFO -    各样本点数：[4608, 3840]（均为384的倍数）
2025-09-20 17:32:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:32:52 - misc:368 - INFO -    Offset：[0, 4608, 8448]
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] x35_labeled.csv | 点数4028→4224（384的倍数）
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m151_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3654，校正前pad范围: [0, 3653]，校正后范围: [0, 3653]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3654
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3654
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3654]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3654, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230306/datas2/f1 (33)_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3654，校正前pad范围: [0, 3653]，校正后范围: [0, 3653]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3654
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3654
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3654]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3654, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1462，校正前pad范围: [0, 1461]，校正后范围: [0, 1461]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1462]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1462, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1462，校正前pad范围: [0, 1461]，校正后范围: [0, 1461]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1462]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1462, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1462，校正前pad范围: [0, 1461]，校正后范围: [0, 1461]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1462]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1462, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1462，校正前pad范围: [0, 1461]，校正后范围: [0, 1461]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1462]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1462, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1462，校正前pad范围: [0, 1461]，校正后范围: [0, 1461]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1462]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1462, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1462，校正前pad范围: [0, 1461]，校正后范围: [0, 1461]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1462]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1462, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 480], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=447，校正前pad范围: [0, 446]，校正后范围: [0, 446]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 447
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 447
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([447]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([447, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 480], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=447，校正前pad范围: [0, 446]，校正后范围: [0, 446]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 447
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 447
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([447]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([447, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1462，校正前pad范围: [0, 1461]，校正后范围: [0, 1461]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1462]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1462, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1462，校正前pad范围: [0, 1461]，校正后范围: [0, 1461]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1462
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1462]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1462, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3654，校正前pad范围: [0, 3653]，校正后范围: [0, 3653]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3654
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3654
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3654]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3654, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3654，校正前pad范围: [0, 3653]，校正后范围: [0, 3653]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3654
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3654
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3654]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3654, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] m151_labeled.csv | 点数3661→3840（384的倍数）
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] f1 (33)_labeled.csv | 点数3871→4224（384的倍数）
2025-09-20 17:32:52 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:32:52 - misc:366 - INFO -    各样本点数：[4224, 4224]（均为384的倍数）
2025-09-20 17:32:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:32:52 - misc:368 - INFO -    Offset：[0, 4224, 8448]
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas4/rr8_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=2688
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (25)_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4546，校正前pad范围: [0, 4545]，校正后范围: [0, 4545]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4546
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4546
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4546]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4546, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4546，校正前pad范围: [0, 4545]，校正后范围: [0, 4545]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4546
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4546
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4546]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4546, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1946，校正前pad范围: [0, 1945]，校正后范围: [0, 1945]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1946]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1946, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1946，校正前pad范围: [0, 1945]，校正后范围: [0, 1945]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1946]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1946, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1946，校正前pad范围: [0, 1945]，校正后范围: [0, 1945]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1946]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1946, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1946，校正前pad范围: [0, 1945]，校正后范围: [0, 1945]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1946]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1946, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1946，校正前pad范围: [0, 1945]，校正后范围: [0, 1945]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1946]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1946, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1946，校正前pad范围: [0, 1945]，校正后范围: [0, 1945]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1946]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1946, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 528], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=608，校正前pad范围: [0, 607]，校正后范围: [0, 607]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 608
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 608
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([608]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([608, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([672, 528], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=608，校正前pad范围: [0, 607]，校正后范围: [0, 607]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  672, 1200], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(672, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数672，K=42
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 608
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 608
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([608]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([608, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1946，校正前pad范围: [0, 1945]，校正后范围: [0, 1945]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1946]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1946, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1344, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1946，校正前pad范围: [0, 1945]，校正后范围: [0, 1945]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1344, 2400], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1344, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1344，K=168
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1946
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1946]), 最大索引: 1344, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1946, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4546，校正前pad范围: [0, 4545]，校正后范围: [0, 4545]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4546
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4546
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4546]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4546, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2688, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4546，校正前pad范围: [0, 4545]，校正后范围: [0, 4545]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2688, 4800], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2688, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2688，K=672
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4546
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4546
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4546]), 最大索引: 2688, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4546, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([5376, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 5376, 9600], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(5376, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数5376，K=1344
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 5376, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] rr8_labeled.csv | 点数5684→5760（384的倍数）
2025-09-20 17:32:52 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:52 - misc:366 - INFO -    各样本点数：[3840, 5760]（均为384的倍数）
2025-09-20 17:32:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:52 - misc:368 - INFO -    Offset：[0, 3840, 9600]
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] gggg (25)_labeled.csv | 点数4945→4992（384的倍数）
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i99_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas1/y134_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4941
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4941
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4941]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4941, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4941
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4941
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4941]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4941, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1817，校正前pad范围: [0, 1816]，校正后范围: [0, 1816]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1817]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1817, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1817，校正前pad范围: [0, 1816]，校正后范围: [0, 1816]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1817]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1817, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1817，校正前pad范围: [0, 1816]，校正后范围: [0, 1816]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1817]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1817, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1817，校正前pad范围: [0, 1816]，校正后范围: [0, 1816]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1817]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1817, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1817，校正前pad范围: [0, 1816]，校正后范围: [0, 1816]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1817]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1817, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1817，校正前pad范围: [0, 1816]，校正后范围: [0, 1816]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1817]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1817, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=503，校正前pad范围: [0, 502]，校正后范围: [0, 502]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 503
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 503
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([503]), 最大索引: 432, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([503, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([432, 480], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=503，校正前pad范围: [0, 502]，校正后范围: [0, 502]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 432, 912], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(432, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数432，K=27
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 503
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 503
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([503]), 最大索引: 432, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([503, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1817，校正前pad范围: [0, 1816]，校正后范围: [0, 1816]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1817]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1817, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([864, 960], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1817，校正前pad范围: [0, 1816]，校正后范围: [0, 1816]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  864, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(864, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1817
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1817]), 最大索引: 864, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1817, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4941
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4941
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4941]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4941, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1728, 1920], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1728, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1728, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4941
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4941
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4941]), 最大索引: 1728, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4941, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3456, 3840], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3456, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3456, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3456，K=864
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3456, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] y134_labeled.csv | 点数3706→3840（384的倍数）
2025-09-20 17:32:52 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8832
2025-09-20 17:32:52 - misc:366 - INFO -    各样本点数：[4992, 3840]（均为384的倍数）
2025-09-20 17:32:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8832, 3])，feat=torch.Size([8832, 9])，label=torch.Size([8832])
2025-09-20 17:32:52 - misc:368 - INFO -    Offset：[0, 4992, 8832]
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] i99_labeled.csv | 点数4384→4608（384的倍数）
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230320/datas1/oo55_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4665
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4665
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4665]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4665, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4665
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4665
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v148_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4665]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4665, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1764，校正前pad范围: [0, 1763]，校正后范围: [0, 1763]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1764]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1764, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1764，校正前pad范围: [0, 1763]，校正后范围: [0, 1763]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1764]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1764, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1764，校正前pad范围: [0, 1763]，校正后范围: [0, 1763]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1764]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1764, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1764，校正前pad范围: [0, 1763]，校正后范围: [0, 1763]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1764]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1764, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1764，校正前pad范围: [0, 1763]，校正后范围: [0, 1763]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1764]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1764, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1764，校正前pad范围: [0, 1763]，校正后范围: [0, 1763]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1764]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1764, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 528], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=507，校正前pad范围: [0, 506]，校正后范围: [0, 506]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 507
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 507
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([507]), 最大索引: 384, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([507, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 528], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=507，校正前pad范围: [0, 506]，校正后范围: [0, 506]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 912], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 507
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 507
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([507]), 最大索引: 384, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([507, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1764，校正前pad范围: [0, 1763]，校正后范围: [0, 1763]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1764]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1764, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 768, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1764，校正前pad范围: [0, 1763]，校正后范围: [0, 1763]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1824], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1764
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1764]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1764, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4665
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4665
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4665]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4665, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3648], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4665
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4665
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4665]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4665, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 7296], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] v148_labeled.csv | 点数4726→4992（384的倍数）
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:52 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:52 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:52 - misc:366 - INFO -    各样本点数：[4608, 4992]（均为384的倍数）
2025-09-20 17:32:52 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:52 - misc:368 - INFO -    Offset：[0, 4608, 9600]
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - wind_shear:161 - DEBUG - [补点] oo55_labeled.csv | 点数4628→4992（384的倍数）
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas4/l100_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6194
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6194
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6194]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6194, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6194
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6194
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6194]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6194, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2432]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2432, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2432]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2432, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2432]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2432, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2432]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2432, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2432]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2432, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:52 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss30_labeled.csv
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2432]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2432, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 432], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:52 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=733，校正前pad范围: [0, 732]，校正后范围: [0, 732]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 733
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 733
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([733]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([733, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 432], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:52 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=733，校正前pad范围: [0, 732]，校正后范围: [0, 732]
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1056], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 733
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 733
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([733]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([733, 256])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2432]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2432, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  864], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2112], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2432
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2432]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2432, 128])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6194
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6194
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6194]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6194, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1728], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:52 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:52 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:52 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4224], device='cuda:0')
2025-09-20 17:32:52 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:52 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:52 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6194
2025-09-20 17:32:52 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6194
2025-09-20 17:32:52 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:52 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:52 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6194]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:52 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:52 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6194, 64])
2025-09-20 17:32:52 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:52 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:52 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3456], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] ss30_labeled.csv | 点数1905→1920（384的倍数）
2025-09-20 17:32:53 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:32:53 - misc:366 - INFO -    各样本点数：[4992, 1920]（均为384的倍数）
2025-09-20 17:32:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:32:53 - misc:368 - INFO -    Offset：[0, 4992, 6912]
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] l100_labeled.csv | 点数4101→4224（384的倍数）
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w99_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 2688], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 2688], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230309/datas1/m108_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1344], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5244
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5244
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5244]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5244, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1344], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5244
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5244
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5244]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5244, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2022]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2022, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2022]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2022, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2022]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2022, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2022]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2022, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2022]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2022, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2022]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2022, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 576, 912], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 336], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=610，校正前pad范围: [0, 609]，校正后范围: [0, 609]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 576, 912], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 610
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 610
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] w99_labeled.csv | 点数3266→3456（384的倍数）
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([610, 256])
2025-09-20 17:32:53 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:32:53 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 17:32:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:32:53 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 576, 912], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 336], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=610，校正前pad范围: [0, 609]，校正后范围: [0, 609]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 576, 912], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 610
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 610
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([610, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2022]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2022, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  672], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1824，校正前最大索引=1823, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 1824], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2022
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2022]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2022, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1344], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5244
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5244
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5244]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5244, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1344], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3648，校正前最大索引=3647, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 3648], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5244
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5244
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5244]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5244, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 2688], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 2688], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 7296], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] m108_labeled.csv | 点数4043→4224（384的倍数）
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas1/n107_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230322/datas1/uu98_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3913，校正前pad范围: [0, 3912]，校正后范围: [0, 3912]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3913
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3913
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3913]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3913, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3913，校正前pad范围: [0, 3912]，校正后范围: [0, 3912]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3913
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3913
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3913]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3913, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1593，校正前pad范围: [0, 1592]，校正后范围: [0, 1592]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1593]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1593, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1593，校正前pad范围: [0, 1592]，校正后范围: [0, 1592]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1593]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1593, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1593，校正前pad范围: [0, 1592]，校正后范围: [0, 1592]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1593]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1593, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1593，校正前pad范围: [0, 1592]，校正后范围: [0, 1592]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1593]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1593, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] n107_labeled.csv | 点数2530→2688（384的倍数）
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1593，校正前pad范围: [0, 1592]，校正后范围: [0, 1592]
2025-09-20 17:32:53 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:32:53 - misc:366 - INFO -    各样本点数：[4224, 2688]（均为384的倍数）
2025-09-20 17:32:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:32:53 - misc:368 - INFO -    Offset：[0, 4224, 6912]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1593]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1593, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1593，校正前pad范围: [0, 1592]，校正后范围: [0, 1592]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1593]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1593, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 480], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=489，校正前pad范围: [0, 488]，校正后范围: [0, 488]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 489
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 489
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([489]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([489, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 480], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] uu98_labeled.csv | 点数2167→2304（384的倍数）
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=489，校正前pad范围: [0, 488]，校正后范围: [0, 488]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 489
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 489
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([489]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([489, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1593，校正前pad范围: [0, 1592]，校正后范围: [0, 1592]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1593]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1593, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1593，校正前pad范围: [0, 1592]，校正后范围: [0, 1592]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1593
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1593]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1593, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3913，校正前pad范围: [0, 3912]，校正后范围: [0, 3912]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3913
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3913
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas1/i56_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3913]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3913, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 1920], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3913，校正前pad范围: [0, 3912]，校正后范围: [0, 3912]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3913
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3913
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3913]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3913, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 3840], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8448, unpad长度将设为=8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb98_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 32])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4224, unpad长度将设为=4224
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5865
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5865
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5865]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5865, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5865
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5865
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5865]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5865, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2112, unpad长度将设为=2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2295, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2295, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2295, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2295, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2295, 128])
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] i56_labeled.csv | 点数3915→4224（384的倍数）
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6528
2025-09-20 17:32:53 - misc:366 - INFO -    各样本点数：[2304, 4224]（均为384的倍数）
2025-09-20 17:32:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6528, 3])，feat=torch.Size([6528, 9])，label=torch.Size([6528])
2025-09-20 17:32:53 - misc:368 - INFO -    Offset：[0, 2304, 6528]
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2295, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1056, unpad长度将设为=1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=677，校正前pad范围: [0, 676]，校正后范围: [0, 676]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 677
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 677
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([677]), 最大索引: 528, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([677, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 528], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 528
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=677，校正前pad范围: [0, 676]，校正后范围: [0, 676]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 677
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 677
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([677]), 最大索引: 528, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([677, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2295, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056, 1056], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2112，校正前最大索引=2111, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2295
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2295]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2295, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5865
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5865
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5865]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5865, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 2112], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2112
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4224，校正前最大索引=4223, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5865
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5865
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5865]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5865, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 4224], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4224
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8448], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8448
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8448]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8448, 64])
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] bb98_labeled.csv | 点数3931→4224（384的倍数）
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss172_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 9600], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 5760], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 9600], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 9600], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 5760], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 9600], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=2880
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas3/gh1 (77)_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4800], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2880], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4800], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7338
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7338
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7338]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7338, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4800], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2880], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4800], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7338
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7338
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7338]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7338, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1440], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3119]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3119, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1440], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3119]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3119, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1440], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3119]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3119, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1440], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3119]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3119, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1440], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3119]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3119, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1440], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3119]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3119, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1200], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 720], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=975，校正前pad范围: [0, 974]，校正后范围: [0, 974]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1200], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 975
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 975
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([975]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([975, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  480, 1200], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([480, 720], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=975，校正前pad范围: [0, 974]，校正后范围: [0, 974]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  480, 1200], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(480, device='cuda:0'), tensor(720, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数480，K=30
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数720，K=45
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 975
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 975
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([975]), 最大索引: 480, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([975, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1440], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3119]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3119, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 960, 1440], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2400，校正前最大索引=2399, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  960, 2400], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(960, device='cuda:0'), tensor(1440, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1440，K=180
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3119
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3119]), 最大索引: 960, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3119, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4800], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2880], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4800], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7338
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7338
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7338]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7338, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1920, 4800], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1920, 2880], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4800，校正前最大索引=4799, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1920, 4800], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1920, device='cuda:0'), tensor(2880, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2880，K=720
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7338
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7338
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7338]), 最大索引: 1920, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7338, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 9600], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 5760], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 9600], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] ss172_labeled.csv | 点数3512→3840（384的倍数）
2025-09-20 17:32:53 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:32:53 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 17:32:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:32:53 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3840, 9600], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3840, 5760], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3840, 9600], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3840, device='cuda:0'), tensor(5760, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3840，K=960
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数5760，K=1440
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 3840, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] gh1 (77)_labeled.csv | 点数4064→4224（384的倍数）
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230301/datas4/bbbbb(118)_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8832, unpad长度将设为=8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 32])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4416, unpad长度将设为=4416
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6695
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6695
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6695]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6695, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas1/aa175_labeled.csv
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6695
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6695
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6695]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6695, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2208, unpad长度将设为=2208
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:53 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1104, unpad长度将设为=1104
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=826，校正前pad范围: [0, 825]，校正后范围: [0, 825]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 826
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 826
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([826]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([826, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 480], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:53 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=826，校正前pad范围: [0, 825]，校正后范围: [0, 825]
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  624, 1104], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 826
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 826
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([826]), 最大索引: 624, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([826, 256])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  960], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2208，校正前最大索引=2207, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 2208], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2771
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2771]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2771, 128])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - wind_shear:161 - DEBUG - [补点] bbbbb(118)_labeled.csv | 点数3085→3456（384的倍数）
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:53 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:53 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7680
2025-09-20 17:32:53 - misc:366 - INFO -    各样本点数：[4224, 3456]（均为384的倍数）
2025-09-20 17:32:53 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7680, 3])，feat=torch.Size([7680, 9])，label=torch.Size([7680])
2025-09-20 17:32:53 - misc:368 - INFO -    Offset：[0, 4224, 7680]
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:53 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:53 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6695
2025-09-20 17:32:53 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6695
2025-09-20 17:32:53 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:53 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:53 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6695]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:53 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6695, 64])
2025-09-20 17:32:53 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:53 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:53 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496, 1920], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:53 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4416，校正前最大索引=4415, 最小索引=0
2025-09-20 17:32:53 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:53 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:53 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 4416], device='cuda:0')
2025-09-20 17:32:53 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6695
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6695
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6695]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6695, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 8832], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8832
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8832
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8832
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8832
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8832]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8832, 64])
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] aa175_labeled.csv | 点数3853→4224（384的倍数）
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230321/datas1/ss75_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=9600, unpad长度将设为=9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=2496
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v70_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4800, unpad长度将设为=4800
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4141，校正前pad范围: [0, 4140]，校正后范围: [0, 4140]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4141
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4141
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4141]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4141, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4141，校正前pad范围: [0, 4140]，校正后范围: [0, 4140]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4141
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4141
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4141]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4141, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2400, unpad长度将设为=2400
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1708，校正前pad范围: [0, 1707]，校正后范围: [0, 1707]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1708]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1708, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1708，校正前pad范围: [0, 1707]，校正后范围: [0, 1707]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1708]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1708, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1708，校正前pad范围: [0, 1707]，校正后范围: [0, 1707]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1708]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1708, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1708，校正前pad范围: [0, 1707]，校正后范围: [0, 1707]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1708]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1708, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1708，校正前pad范围: [0, 1707]，校正后范围: [0, 1707]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1708]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1708, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1708，校正前pad范围: [0, 1707]，校正后范围: [0, 1707]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1708]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1708, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1200, unpad长度将设为=1200
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=526，校正前pad范围: [0, 525]，校正后范围: [0, 525]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 526
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 526
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([526]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([526, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([576, 624], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=526，校正前pad范围: [0, 525]，校正后范围: [0, 525]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1200], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(624, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=36
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数624，K=39
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 526
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 526
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([526]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([526, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1708，校正前pad范围: [0, 1707]，校正后范围: [0, 1707]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1708]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1708, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 1248], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1708，校正前pad范围: [0, 1707]，校正后范围: [0, 1707]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 2400], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(1248, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=144
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1708
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1708]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1708, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4141，校正前pad范围: [0, 4140]，校正后范围: [0, 4140]
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] ss75_labeled.csv | 点数3000→3072（384的倍数）
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:54 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=7296
2025-09-20 17:32:54 - misc:366 - INFO -    各样本点数：[4224, 3072]（均为384的倍数）
2025-09-20 17:32:54 - misc:367 - INFO -    拼接后维度：coord=torch.Size([7296, 3])，feat=torch.Size([7296, 9])，label=torch.Size([7296])
2025-09-20 17:32:54 - misc:368 - INFO -    Offset：[0, 4224, 7296]
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4141
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4141
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4141]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4141, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 2496], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=4141，校正前pad范围: [0, 4140]，校正后范围: [0, 4140]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 4800], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(2496, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4141
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4141
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4141]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4141, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4608, 4992], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 4608
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4608, 9600], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4608, device='cuda:0'), tensor(4992, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4608，K=1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4992，K=1248
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 9600
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([9600]), 最大索引: 4608, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([9600, 64])
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] v70_labeled.csv | 点数3034→3072（384的倍数）
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas3/ii78_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=960
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=2496
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=960
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496,  960], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3219，校正前pad范围: [0, 3218]，校正后范围: [0, 3218]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 3456], device='cuda:0')
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230305/datas2/d204_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3219
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3219
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3219]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3219, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496,  960], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3219，校正前pad范围: [0, 3218]，校正后范围: [0, 3218]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3219
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3219
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3219]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3219, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  480], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1328，校正前pad范围: [0, 1327]，校正后范围: [0, 1327]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1328]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1328, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  480], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1328，校正前pad范围: [0, 1327]，校正后范围: [0, 1327]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1328]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1328, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  480], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1328，校正前pad范围: [0, 1327]，校正后范围: [0, 1327]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1328]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1328, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  480], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1328，校正前pad范围: [0, 1327]，校正后范围: [0, 1327]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1328]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1328, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  480], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1328，校正前pad范围: [0, 1327]，校正后范围: [0, 1327]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1328]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1328, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  480], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1328，校正前pad范围: [0, 1327]，校正后范围: [0, 1327]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1328]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1328, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 624, 864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 240], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=434，校正前pad范围: [0, 433]，校正后范围: [0, 433]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 624, 864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(240, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数240，K=15
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 434
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 434
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([434]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([434, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 624, 864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([624, 240], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 240
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=434，校正前pad范围: [0, 433]，校正后范围: [0, 433]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 624, 864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(624, device='cuda:0'), tensor(240, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数624，K=39
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数240，K=15
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 434
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 434
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([434]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([434, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  480], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1328，校正前pad范围: [0, 1327]，校正后范围: [0, 1327]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1328]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1328, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1248,  480], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1328，校正前pad范围: [0, 1327]，校正后范围: [0, 1327]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1248, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1248, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1248，K=156
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=60
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1328
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1328]), 最大索引: 1248, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1328, 128])
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] ii78_labeled.csv | 点数3752→3840（384的倍数）
2025-09-20 17:32:54 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:54 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=6912
2025-09-20 17:32:54 - misc:366 - INFO -    各样本点数：[3072, 3840]（均为384的倍数）
2025-09-20 17:32:54 - misc:367 - INFO -    拼接后维度：coord=torch.Size([6912, 3])，feat=torch.Size([6912, 9])，label=torch.Size([6912])
2025-09-20 17:32:54 - misc:368 - INFO -    Offset：[0, 3072, 6912]
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496,  960], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3219，校正前pad范围: [0, 3218]，校正后范围: [0, 3218]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3219
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3219
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3219]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3219, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2496, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2496,  960], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=3219，校正前pad范围: [0, 3218]，校正后范围: [0, 3218]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2496, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2496, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2496，K=624
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=240
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 3219
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 3219
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([3219]), 最大索引: 2496, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([3219, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4992, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4992, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4992, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4992, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4992，K=1248
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4992, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] d204_labeled.csv | 点数4158→4224（384的倍数）
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas2/hh48_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v101_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5467
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5467
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5467]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5467, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5467
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5467
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5467]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5467, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2068]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2068, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2068]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2068, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2068]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2068, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2068]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2068, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2068]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2068, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2068]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2068, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=609，校正前pad范围: [0, 608]，校正后范围: [0, 608]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 609
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 609
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([609]), 最大索引: 528, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([609, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=609，校正前pad范围: [0, 608]，校正后范围: [0, 608]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 609
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 609
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([609]), 最大索引: 528, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([609, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2068]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2068, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2068
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2068]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2068, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5467
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5467
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5467]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5467, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5467
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5467
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5467]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5467, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] hh48_labeled.csv | 点数3526→3840（384的倍数）
2025-09-20 17:32:54 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:54 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8064
2025-09-20 17:32:54 - misc:366 - INFO -    各样本点数：[4224, 3840]（均为384的倍数）
2025-09-20 17:32:54 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8064, 3])，feat=torch.Size([8064, 9])，label=torch.Size([8064])
2025-09-20 17:32:54 - misc:368 - INFO -    Offset：[0, 4224, 8064]
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] v101_labeled.csv | 点数3676→3840（384的倍数）
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v47_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2688], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2688], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=1344
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1344], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2786，校正前pad范围: [0, 2785]，校正后范围: [0, 2785]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1344], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2786，校正前pad范围: [0, 2785]，校正后范围: [0, 2785]
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230313/datas2/z197_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1119，校正前pad范围: [0, 1118]，校正后范围: [0, 1118]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1119]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1119, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1119，校正前pad范围: [0, 1118]，校正后范围: [0, 1118]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1119]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1119, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1119，校正前pad范围: [0, 1118]，校正后范围: [0, 1118]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1119]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1119, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1119，校正前pad范围: [0, 1118]，校正后范围: [0, 1118]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1119]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1119, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1119，校正前pad范围: [0, 1118]，校正后范围: [0, 1118]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1119]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1119, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1119，校正前pad范围: [0, 1118]，校正后范围: [0, 1118]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1119]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1119, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 336], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=352，校正前pad范围: [0, 351]，校正后范围: [0, 351]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 352
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 352
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([352]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([352, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 336], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 336
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=352，校正前pad范围: [0, 351]，校正后范围: [0, 351]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 864], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(336, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数336，K=21
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 352
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 352
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([352]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([352, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1119，校正前pad范围: [0, 1118]，校正后范围: [0, 1118]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1119]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1119, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  672], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 672
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1119，校正前pad范围: [0, 1118]，校正后范围: [0, 1118]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1728], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(672, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数672，K=84
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1119
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1119]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1119, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1344], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2786，校正前pad范围: [0, 2785]，校正后范围: [0, 2785]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1344], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1344
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2786，校正前pad范围: [0, 2785]，校正后范围: [0, 2785]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3456], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1344, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1344，K=336
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2786
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2786
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2786]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2786, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2688], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 2688], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2688
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 6912], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(2688, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2688，K=672
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] v47_labeled.csv | 点数4356→4608（384的倍数）
2025-09-20 17:32:54 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:54 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:32:54 - misc:366 - INFO -    各样本点数：[3840, 4608]（均为384的倍数）
2025-09-20 17:32:54 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:32:54 - misc:368 - INFO -    Offset：[0, 3840, 8448]
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 4224], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6528, unpad长度将设为=6528
2025-09-20 17:32:54 - wind_shear:161 - DEBUG - [补点] z197_labeled.csv | 点数4180→4224（384的倍数）
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 4224], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=2112
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 32])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 2112], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3264, unpad长度将设为=3264
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4433
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4433
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4433]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas1/s19_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4433, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 2112], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4433
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4433
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4433]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4433, 64])
2025-09-20 17:32:54 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230314/datas2/bb6_labeled.csv
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1632, unpad长度将设为=1632
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1610，校正前pad范围: [0, 1609]，校正后范围: [0, 1609]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1610, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1610，校正前pad范围: [0, 1609]，校正后范围: [0, 1609]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1610, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1610，校正前pad范围: [0, 1609]，校正后范围: [0, 1609]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1610, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1610，校正前pad范围: [0, 1609]，校正后范围: [0, 1609]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1610, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1610，校正前pad范围: [0, 1609]，校正后范围: [0, 1609]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1610, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1610，校正前pad范围: [0, 1609]，校正后范围: [0, 1609]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1610, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 288, 816], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([288, 528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:32:54 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=816, unpad长度将设为=816
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=462，校正前pad范围: [0, 461]，校正后范围: [0, 461]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 288, 816], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(288, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数288，K=18
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 462
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 462
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([462]), 最大索引: 288, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([462, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 288, 816], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([288, 528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 288
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=462，校正前pad范围: [0, 461]，校正后范围: [0, 461]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 288, 816], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(288, device='cuda:0'), tensor(528, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数288，K=18
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数528，K=33
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 462
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 462
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([462]), 最大索引: 288, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([462, 256])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1610，校正前pad范围: [0, 1609]，校正后范围: [0, 1609]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1610, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([ 576, 1056], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 576
2025-09-20 17:32:54 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1610，校正前pad范围: [0, 1609]，校正后范围: [0, 1609]
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  576, 1632], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(576, device='cuda:0'), tensor(1056, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数576，K=72
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1056，K=132
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1610
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1610]), 最大索引: 576, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1610, 128])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 2112], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4433
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4433
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4433]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4433, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1152, 2112], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1152
2025-09-20 17:32:54 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3264，校正前最大索引=3263, 最小索引=0
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1152, 3264], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1152, device='cuda:0'), tensor(2112, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1152，K=288
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数2112，K=528
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4433
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4433
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4433]), 最大索引: 1152, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4433, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 4224], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:32:54 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:54 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:54 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2304, 4224], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 2304
2025-09-20 17:32:54 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:54 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2304, 6528], device='cuda:0')
2025-09-20 17:32:54 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2304, device='cuda:0'), tensor(4224, device='cuda:0')]
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2304，K=576
2025-09-20 17:32:54 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数4224，K=1056
2025-09-20 17:32:54 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6528
2025-09-20 17:32:54 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6528]), 最大索引: 2304, 最小索引: 0
2025-09-20 17:32:54 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:54 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6528, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] s19_labeled.csv | 点数4831→4992（384的倍数）
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas3/q26_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5498
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5498
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5498]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5498, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] bb6_labeled.csv | 点数5102→5376（384的倍数）
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5498
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5498
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:55 - misc:366 - INFO -    各样本点数：[4224, 5376]（均为384的倍数）
2025-09-20 17:32:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:55 - misc:368 - INFO -    Offset：[0, 4224, 9600]
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5498]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5498, 64])
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230310/datas2/p44_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2061]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2061, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2061]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2061, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2061]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2061, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2061]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2061, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2061]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2061, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2061]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2061, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1008, unpad长度将设为=1008
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=599，校正前pad范围: [0, 598]，校正后范围: [0, 598]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 599
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 599
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([599]), 最大索引: 528, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([599, 256])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 480], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 480
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=599，校正前pad范围: [0, 598]，校正后范围: [0, 598]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  528, 1008], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 599
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 599
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([599]), 最大索引: 528, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([599, 256])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2061]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2061, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2061
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2061]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2061, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] q26_labeled.csv | 点数2789→3072（384的倍数）
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5498
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5498
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5498]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5498, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5498
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5498
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5498]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5498, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 64])
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230318/datas2/ll64_labeled.csv
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] p44_labeled.csv | 点数4299→4608（384的倍数）
2025-09-20 17:32:55 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9600
2025-09-20 17:32:55 - misc:366 - INFO -    各样本点数：[4992, 4608]（均为384的倍数）
2025-09-20 17:32:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9600, 3])，feat=torch.Size([9600, 9])，label=torch.Size([9600])
2025-09-20 17:32:55 - misc:368 - INFO -    Offset：[0, 4992, 9600]
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7680, unpad长度将设为=7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=1728
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230319/datas2/nn189_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3840, unpad长度将设为=3840
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5286
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5286
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5286]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5286, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5286
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5286
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5286]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5286, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1920, unpad长度将设为=1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2010]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2010, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2010]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2010, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2010]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2010, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2010]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2010, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2010]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2010, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2010]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2010, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=960, unpad长度将设为=960
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=581，校正前pad范围: [0, 580]，校正后范围: [0, 580]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 581
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 581
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([581]), 最大索引: 528, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([581, 256])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 432], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 432
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=581，校正前pad范围: [0, 580]，校正后范围: [0, 580]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(432, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数432，K=27
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 581
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 581
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([581]), 最大索引: 528, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([581, 256])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2010]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2010, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 864
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1920，校正前最大索引=1919, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(864, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数864，K=108
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2010
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2010]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2010, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5286
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5286
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5286]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5286, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1728
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3840，校正前最大索引=3839, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1728, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1728，K=432
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5286
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5286
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5286]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5286, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3456
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7680], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3456, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3456，K=864
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7680
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7680]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7680, 64])
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] ll64_labeled.csv | 点数5965→6144（384的倍数）
2025-09-20 17:32:55 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9216
2025-09-20 17:32:55 - misc:366 - INFO -    各样本点数：[3072, 6144]（均为384的倍数）
2025-09-20 17:32:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9216, 3])，feat=torch.Size([9216, 9])，label=torch.Size([9216])
2025-09-20 17:32:55 - misc:368 - INFO -    Offset：[0, 3072, 9216]
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] nn189_labeled.csv | 点数4949→4992（384的倍数）
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=7296, unpad长度将设为=7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 32])
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230312/datas1/w164_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3648, unpad长度将设为=3648
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2581，校正前pad范围: [0, 2580]，校正后范围: [0, 2580]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2581
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2581
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2581]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2581, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2581，校正前pad范围: [0, 2580]，校正后范围: [0, 2580]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2581
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2581
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2581]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2581, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1824, unpad长度将设为=1824
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1006，校正前pad范围: [0, 1005]，校正后范围: [0, 1005]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1006]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1006, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1006，校正前pad范围: [0, 1005]，校正后范围: [0, 1005]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1006]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1006, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1006，校正前pad范围: [0, 1005]，校正后范围: [0, 1005]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1006]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1006, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1006，校正前pad范围: [0, 1005]，校正后范围: [0, 1005]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1006]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1006, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1006，校正前pad范围: [0, 1005]，校正后范围: [0, 1005]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230302/datas2/gggg (147)_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1006]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1006, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1006，校正前pad范围: [0, 1005]，校正后范围: [0, 1005]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1006]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1006, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 384], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=912, unpad长度将设为=912
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=310，校正前pad范围: [0, 309]，校正后范围: [0, 309]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 310
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 310
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([310]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([310, 256])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([528, 384], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=310，校正前pad范围: [0, 309]，校正后范围: [0, 309]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 528, 912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(528, device='cuda:0'), tensor(384, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数528，K=33
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数384，K=24
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 310
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 310
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([310]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([310, 256])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1006，校正前pad范围: [0, 1005]，校正后范围: [0, 1005]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1006]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1006, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  768], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=1006，校正前pad范围: [0, 1005]，校正后范围: [0, 1005]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 1824], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(768, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1006
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1006]), 最大索引: 0, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1006, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2581，校正前pad范围: [0, 2580]，校正后范围: [0, 2580]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2581
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2581
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2581]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2581, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1536], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=2581，校正前pad范围: [0, 2580]，校正后范围: [0, 2580]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 3648], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1536, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1536，K=384
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2581
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2581
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2581]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2581, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3072], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 7296], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3072, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=1056
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3072，K=768
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 7296
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([7296]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([7296, 64])
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] w164_labeled.csv | 点数4230→4608（384的倍数）
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=6912, unpad长度将设为=6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas4/v120_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230311/datas3/u38_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=3456, unpad长度将设为=3456
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4752
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4752
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4752]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4752, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4752
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4752
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4752]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4752, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=1728, unpad长度将设为=1728
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1741]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1741, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1741]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1741, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1741]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1741, 128])
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] gggg (147)_labeled.csv | 点数4943→4992（384的倍数）
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=9984
2025-09-20 17:32:55 - misc:366 - INFO -    各样本点数：[4992, 4992]（均为384的倍数）
2025-09-20 17:32:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([9984, 3])，feat=torch.Size([9984, 9])，label=torch.Size([9984])
2025-09-20 17:32:55 - misc:368 - INFO -    Offset：[0, 4992, 9984]
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1741]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1741, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1741]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1741, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1741]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1741, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 480], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=864, unpad长度将设为=864
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=512，校正前pad范围: [0, 511]，校正后范围: [0, 511]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 512
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 512
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([512]), 最大索引: 384, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([512, 256])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([384, 480], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 384
2025-09-20 17:32:55 - point_transformer_v3m1_base:262 - DEBUG - pad索引超出serialized_order范围！serialized_order长度=512，校正前pad范围: [0, 511]，校正后范围: [0, 511]
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 16
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([  0, 384, 864], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(384, device='cuda:0'), tensor(480, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数384，K=24
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数480，K=30
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 512
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 512
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([512]), 最大索引: 384, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([512, 256])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1741]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1741, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([768, 960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 768
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=1728，校正前最大索引=1727, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0,  768, 1728], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(768, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数768，K=96
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 1741
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([1741]), 最大索引: 768, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([1741, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4752
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4752
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4752]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4752, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1536, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1536
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=3456，校正前最大索引=3455, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1536, 3456], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1536, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1536，K=384
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 4752
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 4752
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([4752]), 最大索引: 1536, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([4752, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([3072, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3072
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 3072, 6912], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(3072, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数3072，K=768
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=960
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 6912
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([6912]), 最大索引: 3072, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([6912, 64])
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] u38_labeled.csv | 点数3764→3840（384的倍数）
2025-09-20 17:32:55 - misc:355 - DEBUG - 当前batch样本grid_size不一致（已取第一个样本的tensor([122.6000, 118.0000,   5.4000])作为统一值）
各样本grid_size：[[122.6, 118.0, 5.4], [122.6, 118.0, 5.4]]
2025-09-20 17:32:55 - misc:365 - INFO - ✅ Batch生成成功：样本数=2，总点数=8448
2025-09-20 17:32:55 - misc:366 - INFO -    各样本点数：[4608, 3840]（均为384的倍数）
2025-09-20 17:32:55 - misc:367 - INFO -    拼接后维度：coord=torch.Size([8448, 3])，feat=torch.Size([8448, 9])，label=torch.Size([8448])
2025-09-20 17:32:55 - misc:368 - INFO -    Offset：[0, 4608, 8448]
2025-09-20 17:32:55 - wind_shear:161 - DEBUG - [补点] v120_labeled.csv | 点数3383→3456（384的倍数）
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230308/datas3/k3_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=8064, unpad长度将设为=8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['offset', 'coord', 'feat', 'label', 'beamaz', 'grid_size', 'batch', 'order', 'grid_coord', 'serialized_depth', 'serialized_code', 'serialized_order', 'serialized_inverse', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=True, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([4224, 3840], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 3840
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 2
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 4224, 8064], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(4224, device='cuda:0'), tensor(3840, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数4224，K=2112
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数3840，K=1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 8064
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([8064]), 最大索引: 4224, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([8064, 32])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - wind_shear:123 - DEBUG - 
CSV文件路径：/mnt/d/model/wind_datas/csv_labels/20230317/datas4/jj76_labeled.csv
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=4032, unpad长度将设为=4032
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5765
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5765
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5765]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5765, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([2112, 1920], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 1920
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=4032，校正前最大索引=4031, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 4
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 2112, 4032], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(2112, device='cuda:0'), tensor(1920, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数2112，K=528
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数1920，K=480
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 5765
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 5765
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([5765]), 最大索引: 2112, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([5765, 64])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:132 - DEBUG - 【get_padding】总点数=2016, unpad长度将设为=2016
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2230
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2230
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2230]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2230, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2230
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2230
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2230]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2230, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2230
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2230
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2230]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2230, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本0点数1056，K=132
2025-09-20 17:32:55 - point_transformer_v3m1_base:349 - DEBUG - ✅ 样本1点数960，K=120
2025-09-20 17:32:55 - point_transformer_v3m1_base:352 - DEBUG - coord点数: 2230
2025-09-20 17:32:55 - point_transformer_v3m1_base:353 - DEBUG - feat点数: 2230
2025-09-20 17:32:55 - point_transformer_v3m1_base:354 - DEBUG - label点数: {}
2025-09-20 17:32:55 - point_transformer_v3m1_base:355 - DEBUG - beamaz点数: 无
2025-09-20 17:32:55 - point_transformer_v3m1_base:356 - DEBUG - inverse形状: torch.Size([2230]), 最大索引: 1056, 最小索引: 0
2025-09-20 17:32:55 - point_transformer_v3m1_base:357 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:394 - DEBUG - SerializedAttention输出point.feat形状: torch.Size([2230, 128])
2025-09-20 17:32:55 - point_transformer_v3m1_base:492 - DEBUG - Block输入point类型: <class 'pointcept.models.utils.structure.Point'>
2025-09-20 17:32:55 - point_transformer_v3m1_base:225 - DEBUG - 【Point对象字段检查】keys=dict_keys(['feat', 'coord', 'grid_coord', 'serialized_code', 'serialized_order', 'serialized_inverse', 'serialized_depth', 'batch', 'offset', 'pooling_inverse', 'pooling_parent', 'sparse_shape', 'sparse_conv_feat', 'pad', 'unpad', 'cu_seqlens_key']), 包含grid_size=False, 包含coord=True
2025-09-20 17:32:55 - point_transformer_v3m1_base:230 - DEBUG - 
【调试日志】当前batch的offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:232 - DEBUG - 【调试日志】计算出的样本点数bincount: tensor([1056,  960], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:245 - DEBUG - 当前patch_size (K): 48, 配置patch_size_max: 48, 样本最小点数: 960
2025-09-20 17:32:55 - point_transformer_v3m1_base:281 - DEBUG - serialized_inverse索引超出unpad范围！unpad长度=2016，校正前最大索引=2015, 最小索引=0
2025-09-20 17:32:55 - point_transformer_v3m1_base:340 - DEBUG - ==================================================
2025-09-20 17:32:55 - point_transformer_v3m1_base:341 - DEBUG - 当前注意力头数H: 8
2025-09-20 17:32:55 - point_transformer_v3m1_base:342 - DEBUG - offset: tensor([   0, 1056, 2016], device='cuda:0')
2025-09-20 17:32:55 - point_transformer_v3m1_base:344 - DEBUG - 每个样本的点数: [tensor(1056, device='cuda:0'), tensor(960, device='cuda:0')]
